{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22edb44",
   "metadata": {},
   "source": [
    "PLOTTING PAC SOURCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f93a2f",
   "metadata": {},
   "source": [
    "Algorithm to plot sources:\n",
    "1. Iterate through subjects, for each:\n",
    "    - get PAC data\n",
    "    - transpose\n",
    "    - impute NaNs\n",
    "    - aggregate\n",
    "2. Stack PAC estimates along subjects axis\n",
    "3. Average across ph, amp and sub\n",
    "\n",
    "\n",
    "4. Load any morphed source file:\n",
    "    - average time domain to get 1 point\n",
    "    - replace data with PAC data\n",
    "    - rename subject to \"fsaverage_bem\"\n",
    "    - PLOT as regular source estimate\n",
    "    - (optional) add ROI, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d24369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import check_paths\n",
    "\n",
    "import mne\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import zscore\n",
    "from scipy.sparse import coo_matrix, save_npz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16034546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "-- number of adjacent vertices : 5124\n",
      "adjacency shape: (5124, 5124)\n"
     ]
    }
   ],
   "source": [
    "eeg_data_dir = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set'\n",
    "groups = ['Y']\n",
    "tasks = ['_BL', '_MAIN'] # ['_BL', '_MAIN']\n",
    "task_stages = ['_plan', '_go']\n",
    "# block_names = ['_baseline', '_adaptation']\n",
    "\n",
    "# Load adjacency matrix\n",
    "src_fname = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\mri_data\\\\fs_output\\\\freesurfer\\\\sub_dir\\\\Y\\\\fsaverage_bem\\\\bem\\\\fsaverage-ico4-src.fif'\n",
    "src = mne.read_source_spaces(src_fname)\n",
    "# src.plot(subjects_dir='D:\\\\BonoKat\\\\research project\\\\# study 1\\\\mri_data\\\\fs_output\\\\freesurfer\\\\sub_dir\\\\Y')\n",
    "source_adjacency = mne.spatial_src_adjacency(src)\n",
    "adj = source_adjacency.tocsr()  # Ensure adjacency is CSR format for fast indexing\n",
    "print('adjacency shape:', source_adjacency.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fef5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 5124 vertices, subject : fsaverage_bem, tmin : 1.0000000000000009 (ms), tmax : 1.0000000000000009 (ms), tstep : 1002.0 (ms), data shape : (5124, 1), ~60 KiB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load one stc file as a reference\n",
    "stc_path = os.path.join('''D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set\\\\Y\\\\s1_pac_sub01\\\\preproc\\\\analysis\\\\source\\\\morphed_stcs\\\\_MAIN\\\\_plan\\\\_baseline\\\\s1_pac_sub01_MAIN_plan_baseline-stc-lcmv_epoch_000_morphed-lh.stc''')\n",
    "stc_ref = mne.read_source_estimate(stc_path, subject='s1_pac_sub01') # any STC will serve as a template\n",
    "stc_ref_mean = stc_ref.copy().mean()\n",
    "stc_pac = stc_ref_mean.copy()\n",
    "stc_pac.subject = \"fsaverage_bem\"\n",
    "stc_pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc14dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Y group, _BL_plan...\n",
      "Processing Y group, _BL_go...\n",
      "Processing Y group, _MAIN_plan_baseline...\n",
      "Processing Y group, _MAIN_plan_adaptation...\n",
      "Processing Y group, _MAIN_go_baseline...\n",
      "Processing Y group, _MAIN_go_adaptation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.         0.         0.00012973]\n",
      "Using control points [0.        0.        0.0003008]\n"
     ]
    }
   ],
   "source": [
    "# Plot PAC MI values\n",
    "\n",
    "views = {'lateral': [\"lateral\", \"medial\"],\n",
    "        'dor-vent': [\"dorsal\", \"ventral\"]}\n",
    "\n",
    "for group in groups:\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "    figs_save_path = os.path.join(eeg_data_dir, f'{group} group', 'sources', 'figs')\n",
    "    check_paths(figs_save_path)\n",
    "\n",
    "    \n",
    "\n",
    "    for task in tasks:\n",
    "        if task == '_BL':\n",
    "            block_names = ['']\n",
    "        else:\n",
    "            block_names = ['_baseline', '_adaptation']\n",
    "\n",
    "        for task_stage in task_stages:\n",
    "            for block_name in block_names:\n",
    "                print(f'Processing {group} group, {task}{task_stage}{block_name}...')\n",
    "\n",
    "                pac_list = []\n",
    "                for sub_name in subs:\n",
    "                    analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "                    pac_save_path = os.path.join(analysis_dir, 'source', 'PAC')\n",
    "                    pac_data = np.load(os.path.join(pac_save_path, f\"PAC_MI_SOURCE_{sub_name[-5:]}{task}{task_stage}{block_name}.npy\"))\n",
    "                    pac_data_t = np.transpose(pac_data, (1, 0, 2))\n",
    "\n",
    "                    ### NAN Imputation for PAC Matrices ###\n",
    "                    pac_imputed = pac_data_t.copy()\n",
    "\n",
    "                    # Step 1: Detect vertices with any NaN in their 20×20 PAC\n",
    "                    nan_mask = np.isnan(pac_data_t).any(axis=(1, 2))  # shape (5124,)\n",
    "\n",
    "                    if nan_mask.any() == True:\n",
    "                        # print(f\"Found {nan_mask.sum()} vertices with NaN values.\")\n",
    "\n",
    "                        # Step 2: Impute NaNs from neighbors\n",
    "                        for vtx in np.where(nan_mask)[0]:\n",
    "                            neighbors = adj[[vtx]].indices\n",
    "                            valid_neighbors = [n for n in neighbors if not nan_mask[n]]\n",
    "                            # Average PAC matrices from neighbors\n",
    "                            pac_imputed[vtx] = np.nanmean(pac_data_t[valid_neighbors], axis=0)\n",
    "\n",
    "                    # pac_zscore = zscore(pac_imputed, axis=0, nan_policy='omit')\n",
    "                    pac_list.append(pac_imputed)\n",
    "\n",
    "                # Stack them along a new first axis (subject axis)\n",
    "                pac_all = np.stack(pac_list, axis=0)\n",
    "                # print('PAC array shape:', pac_all.shape)\n",
    "                pac_map = pac_all.mean(axis=(0, 2, 3))\n",
    "                # print('Averaged PAC map shape:', pac_map.shape)\n",
    "                stc_pac._data = pac_map[:, None]   # (n_vertices_total, 1)\n",
    "                # print('STC data shape:', stc_pac.data.shape)\n",
    "\n",
    "                clim = dict(\n",
    "                    kind=\"value\",\n",
    "                    lims=[\n",
    "                        np.nanmin(pac_map), \n",
    "                        (np.nanmax(pac_map) - np.nanmin(pac_map)) / 2 + np.nanmin(pac_map), \n",
    "                        np.nanmax(pac_map)\n",
    "                        ],   # [min, mid, max]\n",
    "                    )\n",
    "\n",
    "                for key, value in views.items():\n",
    "                    title = f\"ALL_SUBS_{group}{task}{task_stage}{block_name}_PAC_MI_{key}\"\n",
    "\n",
    "                    brain = stc_pac.plot(subject=\"fsaverage_bem\",\n",
    "                                initial_time=0.0,\n",
    "                                clim=clim,\n",
    "                                cortex=\"low_contrast\",\n",
    "                                colormap='plasma', # 'plasma' for raw MI, 'cool' for zscored MI\n",
    "                                hemi='both',\n",
    "                                views=value, # \"dorsal\", \"ventral\"\n",
    "                                background='white',\n",
    "                                title = title\n",
    "                                )\n",
    "\n",
    "                    brain.save_image(os.path.join(figs_save_path, title + '.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a817c77",
   "metadata": {},
   "source": [
    "PLOTTING STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288b04ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot significant PAC\n",
    "\n",
    "# Significant conditions:\n",
    "# FTT (BL) planning\n",
    "# De-CRAT (MAIN) planning baseline\n",
    "\n",
    "group_save_path = os.path.join(eeg_data_dir, f'{group} group')\n",
    "pac_stats_save_path = os.path.join(group_save_path, 'source_pac_stats')\n",
    "sig_conditions = ['Y_BL_plan', 'Y_MAIN_plan_baseline']\n",
    "p_thresh = 0.05\n",
    "\n",
    "for sig_cond in sig_conditions:\n",
    "\n",
    "    # Load stats data\n",
    "    T_obs = np.load(os.path.join(pac_stats_save_path, f\"PAC_MI_SOURCE_{sig_cond}_freqs_ave_T_obs.npy\"))\n",
    "    clusters = np.load(os.path.join(pac_stats_save_path, f\"PAC_MI_SOURCE_{sig_cond}_freqs_ave_clusters.npy\"), allow_pickle=True)\n",
    "    cluster_p_values = np.load(os.path.join(pac_stats_save_path, f\"PAC_MI_SOURCE_{sig_cond}_freqs_ave_cluster_p_values.npy\"))\n",
    "\n",
    "    # Combine significant cluster masks\n",
    "    sig_mask = np.zeros_like(T_obs, dtype=bool)\n",
    "    for cluster, p_val in zip(clusters, cluster_p_values):\n",
    "        if p_val <= p_thresh:\n",
    "            sig_mask |= cluster.astype(bool)\n",
    "    sig_mask = sig_mask[:, None]\n",
    "    title = f\"Significant PAC - {sig_cond}\"\n",
    "\n",
    "    sig_cond = [sig_cond + '_' if sig_cond == 'Y_BL_plan' else sig_cond][0]\n",
    "    group, task, task_stage, block_name = sig_cond.split('_')\n",
    "    block_name = ['_' + block_name if block_name != '' else block_name][0]\n",
    "\n",
    "    for sub_name in subs:\n",
    "\n",
    "        pac_list = []\n",
    "\n",
    "        analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "        pac_save_path = os.path.join(analysis_dir, 'source', 'PAC')\n",
    "        pac_data = np.load(os.path.join(pac_save_path, f\"PAC_MI_SOURCE_{sub_name[-5:]}{'_' + task}{'_' + task_stage}{block_name}.npy\"))\n",
    "        pac_data_t = np.transpose(pac_data, (1, 0, 2))\n",
    "\n",
    "        ### NAN Imputation for PAC Matrices ###\n",
    "        pac_imputed = pac_data_t.copy()\n",
    "\n",
    "        # Step 1: Detect vertices with any NaN in their 20×20 PAC\n",
    "        nan_mask = np.isnan(pac_data_t).any(axis=(1, 2))  # shape (5124,)\n",
    "\n",
    "        if nan_mask.any() == True:\n",
    "            # print(f\"Found {nan_mask.sum()} vertices with NaN values.\")\n",
    "\n",
    "            # Step 2: Impute NaNs from neighbors\n",
    "            for vtx in np.where(nan_mask)[0]:\n",
    "                neighbors = adj[[vtx]].indices\n",
    "                valid_neighbors = [n for n in neighbors if not nan_mask[n]]\n",
    "                # Average PAC matrices from neighbors\n",
    "                pac_imputed[vtx] = np.nanmean(pac_data_t[valid_neighbors], axis=0)\n",
    "\n",
    "        # pac_zscore = zscore(pac_imputed, axis=0, nan_policy='omit')\n",
    "        pac_list.append(pac_imputed)\n",
    "\n",
    "    # Stack them along a new first axis (subject axis)\n",
    "    pac_all = np.stack(pac_list, axis=0)\n",
    "    # print('PAC array shape:', pac_all.shape)\n",
    "    pac_map = pac_all.mean(axis=(0, 2, 3))\n",
    "    # print('Averaged PAC map shape:', pac_map.shape)\n",
    "    stc_pac._data = pac_map[:, None]   # (n_vertices_total, 1)\n",
    "    # print('STC data shape:', stc_pac.data.shape)\n",
    "    \n",
    "    # Copy the STC to avoid modifying the original\n",
    "    stc_sig = copy.deepcopy(stc_pac)\n",
    "    stc_sig.data[~sig_mask] = 0.0\n",
    "\n",
    "    clim = dict(\n",
    "        kind=\"value\",\n",
    "        lims=[\n",
    "            np.nanmin(pac_map), \n",
    "            (np.nanmax(pac_map) - np.nanmin(pac_map)) / 2 + np.nanmin(pac_map), \n",
    "            np.nanmax(pac_map)\n",
    "            ],   # [min, mid, max]\n",
    "        )\n",
    "    # view = [[\"dorsal\", \"lateral\"] if sig_cond == 'Y_BL_plan_' else [\"dorsal\", \"parietal\"]]\n",
    "    brain = stc_sig.plot(subject=\"fsaverage_bem\",\n",
    "                initial_time=0.0,\n",
    "                clim=clim,\n",
    "                cortex=\"low_contrast\",\n",
    "                colormap='hot', # 'plasma' for raw MI, 'cool' for zscored MI\n",
    "                hemi='both',\n",
    "                views=[[\"dorsal\", \"lateral\"] if sig_cond == 'Y_BL_plan_' else [\"dorsal\", \"parietal\"]][0],\n",
    "                background='white',\n",
    "                title = title,\n",
    "                )\n",
    "    brain.save_image(os.path.join(figs_save_path, title + '.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d1eb57",
   "metadata": {},
   "source": [
    "______\n",
    "Plotting drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80293cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 5124, 249)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eeg_data_dir = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set'\n",
    "group = 'Y'\n",
    "figs_save_path = os.path.join(eeg_data_dir, f'{group} group', 'sources', 'figs')\n",
    "check_paths(figs_save_path)\n",
    "\n",
    "\n",
    "sub_name = 's1_pac_sub07'\n",
    "analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "task = '_MAIN'\n",
    "task_stage = '_plan'\n",
    "block_name = '_baseline'\n",
    "\n",
    "stcs_path = os.path.join(analysis_dir, 'source', 'morphed_stcs', task, task_stage, block_name)\n",
    "\n",
    "stcs = []\n",
    "stcs_data = []\n",
    "\n",
    "tmin = 0.0\n",
    "tmax = 0.495\n",
    "\n",
    "for stc_file in os.listdir(stcs_path):\n",
    "    if stc_file.endswith('-rh.stc'): # MNE will load both hemispheres anyway\n",
    "        stc_path = os.path.join(stcs_path, stc_file)\n",
    "        stc = mne.read_source_estimate(stc_path, subject=sub_name)\n",
    "        stc.crop(tmin=tmin, tmax=tmax)\n",
    "        stcs.append(stc)\n",
    "        stcs_data.append(stc.data)\n",
    "\n",
    "source_array = np.stack(stcs_data, axis=0)\n",
    "source_array.shape # (epochs x vertices x time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d431aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 5124 vertices, subject : fsaverage_bem, tmin : 0.0 (ms), tmax : 496.0 (ms), tstep : 2.0 (ms), data shape : (5124, 249), ~4.9 MiB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mri_data_dir = f'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\mri_data\\\\fs_output\\\\freesurfer\\\\sub_dir\\\\Y'\n",
    "# fname_fsaverage_src = os.path.join(mri_data_dir, \"fsaverage_bem\", \"bem\", \"fsaverage-ico4-src.fif\")\n",
    "\n",
    "# eeg_data_dir = os.path.join('D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set', group)\n",
    "# src_to = mne.read_source_spaces(fname_fsaverage_src)\n",
    "\n",
    "# # Morph the source estimates to the fsaverage space\n",
    "# morph = mne.compute_source_morph(\n",
    "#     stc,\n",
    "#     subject_from=sub_name,\n",
    "#     subject_to=\"fsaverage_bem\",\n",
    "#     src_to=src_to,\n",
    "#     subjects_dir=mri_data_dir,\n",
    "#     smooth=5 # small smoothing to avoid artifacts in the morphed data\n",
    "# )\n",
    "\n",
    "# stc_fsaverage = morph.apply(stc)\n",
    "# stc.plot()\n",
    "# stc_fsaverage.plot()\n",
    "# stc_fsaverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7fef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 vertices with NaN values.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 5124 vertices, subject : fsaverage_bem, tmin : 249.0 (ms), tmax : 249.0 (ms), tstep : 498.0 (ms), data shape : (5124, 1), ~80 KiB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "pac_save_path = os.path.join(analysis_dir, 'source', 'PAC')\n",
    "pac_data = np.load(os.path.join(pac_save_path, f\"PAC_MI_SOURCE_{sub_name[-5:]}{task}{task_stage}{block_name}.npy\"))\n",
    "\n",
    "pac_data_t = np.transpose(pac_data, (1, 0, 2))\n",
    "\n",
    "### NAN Imputation for PAC Matrices ###\n",
    "pac_imputed = pac_data_t.copy()\n",
    "\n",
    "# Step 1: Detect vertices with any NaN in their 20×20 PAC\n",
    "nan_mask = np.isnan(pac_data_t).any(axis=(1, 2))  # shape (5124,)\n",
    "\n",
    "if nan_mask.any() == True:\n",
    "    print(f\"Found {nan_mask.sum()} vertices with NaN values.\")\n",
    "\n",
    "    # Step 2: Impute NaNs from neighbors\n",
    "    for vtx in np.where(nan_mask)[0]:\n",
    "        neighbors = adj[[vtx]].indices\n",
    "        valid_neighbors = [n for n in neighbors if not nan_mask[n]]\n",
    "        # Average PAC matrices from neighbors\n",
    "        pac_imputed[vtx] = np.nanmean(pac_data_t[valid_neighbors], axis=0)\n",
    "\n",
    "pac_zscore = zscore(pac_imputed, axis=0, nan_policy='omit')\n",
    "pac_map = pac_zscore.mean(axis=(1, 2))\n",
    "pac_map_clean = np.nan_to_num(pac_map, nan=1, posinf=0.0, neginf=0.0)\n",
    "stc_ref = stcs[0]  # any one of your loaded STCs\n",
    "stc_ref_mean = stc_ref.copy().mean()\n",
    "stc_pac = stc_ref_mean.copy()\n",
    "stc_pac._data = pac_map_clean[:, None]   # (n_vertices_total, 1)\n",
    "stc_pac.subject = \"fsaverage_bem\"\n",
    "stc_pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7970d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = dict(\n",
    "    kind=\"value\",\n",
    "    lims=[np.nanmin(pac_map), (np.nanmax(pac_map) - np.nanmin(pac_map)) / 2 + np.nanmin(pac_map), np.nanmax(pac_map)],   # [min, mid, max]\n",
    "    \n",
    ")\n",
    "\n",
    "views = {'lateral': [\"lateral\", \"medial\"],\n",
    "         'dor-vent': [\"dorsal\", \"ventral\"]}\n",
    "\n",
    "for key, value in views.items():\n",
    "    title = f\"{sub_name[-5:]}{task}{task_stage}{block_name}_z-score_PAC_{key}\"\n",
    "\n",
    "    brain = stc_pac.plot(subject=\"fsaverage_bem\",\n",
    "                initial_time=0.0,\n",
    "                clim=clim,\n",
    "                cortex=\"low_contrast\",\n",
    "                colormap='plasma', # 'plasma' for raw MI, 'cool' for zscored MI\n",
    "                hemi='both',\n",
    "                views=value, # \"dorsal\", \"ventral\"\n",
    "                background='white',\n",
    "                title = title\n",
    "                )\n",
    "\n",
    "    # brain.save_image(os.path.join(figs_save_path, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97efb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labels from parcellation...\n",
      "   read 35 labels from D:\\BonoKat\\research project\\# study 1\\mri_data\\Y\\fs\\fsaverage_bem\\label\\lh.aparc.annot\n",
      "   read 34 labels from D:\\BonoKat\\research project\\# study 1\\mri_data\\Y\\fs\\fsaverage_bem\\label\\rh.aparc.annot\n"
     ]
    }
   ],
   "source": [
    "## Plotting with ROI labels, if needed\n",
    "\n",
    "# Select a few ROIs (names depend on your parcellation)\n",
    "labels = mne.read_labels_from_annot('fsaverage_bem', parc='aparc')\n",
    "roi_names = [\"postcentral-lh\", \"precentral-lh\", \"superiorfrontal-lh\"]\n",
    "rois = [lab for lab in labels if lab.name in roi_names]\n",
    "\n",
    "brain = stc_pac.plot(\n",
    "    subject=\"fsaverage_bem\",\n",
    "    hemi=\"both\",\n",
    "    views=[\"lateral\", \"medial\"],\n",
    "    cortex=\"bone\",\n",
    "    clim=clim,\n",
    "    colormap=\"plasma\",\n",
    "    initial_time=0.0,\n",
    ")\n",
    "\n",
    "# Add them in different colors\n",
    "colors = [\"yellow\", \"cyan\", \"magenta\"]\n",
    "for roi, color in zip(rois, colors):\n",
    "    brain.add_label(roi, borders=True, color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bd31b",
   "metadata": {},
   "source": [
    "_____"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
