{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BL PAC stats within one condition and between conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from utils import check_paths\n",
    "\n",
    "import mne\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import zscore\n",
    "from scipy.sparse import coo_matrix, save_npz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretaion of z-scored PAC stats:**\n",
    "Negative z-scores don’t mean “negative PAC,” just “PAC lower than the group mean.”\n",
    "\n",
    "**Significant cluster interpretaition:**\n",
    "It is invalid to interpret the cluster p value as being spatially or temporally specific. A cluster with sufficiently low (for example < 0.05) p value at specific location does not allow you to say that the significant effect is at that particular location. The p value only tells you about the probability of obtaining similar or stronger/larger cluster anywhere in the data if there were no differences between the compared conditions. So it only allows you to draw conclusions about the differences in the data “in general”, not at specific locations.\n",
    "\n",
    "**How NOT to interpret results from a cluster-based permutation test:**\n",
    "https://www.fieldtriptoolbox.org/faq/stats/clusterstats_interpretation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rect_topo_from_epochs(data, epochs_info, cmap='YlGn', vmin=None, vmax=None, title=''):\n",
    "    \"\"\"\n",
    "    Plot a rectangular grid topomap from per-channel data using layout from epochs.info.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array, shape (n_channels,)\n",
    "        Scalar values per channel (e.g., PAC strength).\n",
    "    epochs_info : instance of mne.Info\n",
    "        Info object from Epochs to extract channel positions.\n",
    "    cmap : str or Colormap\n",
    "        Colormap to use for values.\n",
    "    vmin, vmax : float\n",
    "        Limits for color scaling.\n",
    "    title : str\n",
    "        Title for the plot.\n",
    "    \"\"\"\n",
    "    # Get rectangular layout from MNE\n",
    "    layout = mne.channels.make_eeg_layout(epochs_info)\n",
    "    ch_names = layout.names\n",
    "    pos_2d = layout.pos[:, :2]\n",
    "\n",
    "    # Normalize positions to grid indices\n",
    "    x_idx = np.round((pos_2d[:, 0] - np.min(pos_2d[:, 0])) / np.ptp(pos_2d[:, 0]) * 14).astype(int)\n",
    "    y_idx = np.round((pos_2d[:, 1] - np.min(pos_2d[:, 1])) / np.ptp(pos_2d[:, 1]) * 14).astype(int)\n",
    "    layout_grid = {ch: (y, x) for ch, x, y in zip(ch_names, x_idx, y_idx)}\n",
    "    # name, pos in zip(layout.names, layout.pos)\n",
    "\n",
    "    # Prepare grid size\n",
    "    nrows = y_idx.max() + 1\n",
    "    ncols = x_idx.max() + 1\n",
    "\n",
    "    # Start plotting\n",
    "    fig, ax = plt.subplots(figsize=(ncols, nrows))\n",
    "    ax.set_xlim(0, ncols)\n",
    "    ax.set_ylim(0, nrows)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    norm = plt.Normalize(vmin if vmin is not None else np.nanmin(data),\n",
    "                         vmax if vmax is not None else np.nanmax(data))\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        # if ch not in layout_grid:\n",
    "        #     continue\n",
    "        row, col = layout_grid[ch]\n",
    "        value = data[i].T\n",
    "        color = sm.to_rgba(value)\n",
    "        rect = patches.Rectangle((col, row), 1, 1, facecolor=color, edgecolor='black')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(col + 0.5, row + 0.5, ch, ha='center', va='center', fontsize=7)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.colorbar(sm, ax=ax, shrink=0.8, label='Value')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_topo_from_epochs(data, epochs_info, cmap='YlGn', vmin=None, vmax=None, title=''):\n",
    "    \"\"\"\n",
    "    Plot a topographic layout of 2D matrices (e.g., PAC) per channel using epochs.info.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (n_channels, height, width)\n",
    "        A 2D matrix per channel (e.g., PAC frequency x frequency).\n",
    "    epochs_info : instance of mne.Info\n",
    "        Info object to extract channel layout.\n",
    "    cmap : str or Colormap\n",
    "        Colormap to use.\n",
    "    vmin, vmax : float or None\n",
    "        Color scale limits.\n",
    "    title : str\n",
    "        Title for the entire plot.\n",
    "    \"\"\"\n",
    "    n_channels, h, w = data.shape\n",
    "\n",
    "    # Get layout info\n",
    "    layout = mne.channels.make_eeg_layout(epochs_info)\n",
    "    ch_names = layout.names\n",
    "    pos_2d = layout.pos[:, :2]\n",
    "\n",
    "    # Normalize positions to grid indices\n",
    "    x_idx = np.round((pos_2d[:, 0] - np.min(pos_2d[:, 0])) / np.ptp(pos_2d[:, 0]) * 14).astype(int)\n",
    "    y_idx = np.round((pos_2d[:, 1] - np.min(pos_2d[:, 1])) / np.ptp(pos_2d[:, 1]) * 14).astype(int)\n",
    "    layout_grid = {ch: (y, x) for ch, x, y in zip(ch_names, x_idx, y_idx)}\n",
    "\n",
    "    # Grid dimensions\n",
    "    nrows = y_idx.max() + 1\n",
    "    ncols = x_idx.max() + 1\n",
    "\n",
    "    # Set up figure\n",
    "    fig, ax = plt.subplots(figsize=(ncols, nrows))\n",
    "    ax.set_xlim(0, ncols)\n",
    "    ax.set_ylim(0, nrows)\n",
    "    # ax.invert_yaxis()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Color normalization\n",
    "    norm = plt.Normalize(vmin if vmin is not None else np.nanmin(data),\n",
    "                         vmax if vmax is not None else np.nanmax(data))\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        if ch not in layout_grid:\n",
    "            continue\n",
    "        row, col = layout_grid[ch]\n",
    "        matrix = data[i].T\n",
    "\n",
    "        # Plot small matrix inside rectangle\n",
    "        extent = (col, col + 1, row, row + 1)\n",
    "        ax.imshow(matrix, cmap=cmap, norm=norm, extent=extent, origin='lower', aspect='auto')\n",
    "\n",
    "        # Draw frame and label\n",
    "        rect = patches.Rectangle((col, row), 1, 1, fill=False, edgecolor='black', linewidth=0.5)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(col + 0.5, row + 0.5, ch, ha='center', va='center', fontsize=6, color='black')\n",
    "\n",
    "    plt.colorbar(sm, ax=ax, shrink=0.7, label='Matrix Value')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_significant_topomap(T_obs, clusters, cluster_p_values, info, p_thresh=0.05, vlim=(-4, 4),\n",
    "                             group=None, task=None, task_stage=None, block_name=''):\n",
    "    \"\"\"\n",
    "    Plots a topomap highlighting electrodes in significant clusters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T_obs : array, shape (n_channels,)\n",
    "        Observed T-values.\n",
    "    clusters : list of boolean arrays\n",
    "        Cluster masks (n_channels,).\n",
    "    cluster_p_values : array\n",
    "        P-values for each cluster.\n",
    "    info : instance of mne.Info\n",
    "        EEG info with channel locations.\n",
    "    p_thresh : float\n",
    "        Significance threshold.\n",
    "    title : str\n",
    "        Title for the plot.\n",
    "    \"\"\"\n",
    "    # Combine significant cluster masks\n",
    "    sig_mask = np.zeros_like(T_obs, dtype=bool)\n",
    "    for cluster, p_val in zip(clusters, cluster_p_values):\n",
    "        if p_val <= p_thresh:\n",
    "            sig_mask |= cluster\n",
    "\n",
    "    # Get color limits manually\n",
    "    if vlim is None:\n",
    "        vlim = np.nanmax(np.abs(T_obs))\n",
    "\n",
    "    title = f'{group}{task}{task_stage}{block_name}: Significant Electrodes'\n",
    "    # Start plotting\n",
    "    fig, ax = plt.subplots()\n",
    "    im, _ = mne.viz.plot_topomap(\n",
    "        T_obs,\n",
    "        info,\n",
    "        cmap='PiYG',\n",
    "        vlim=vlim,\n",
    "        show=False,\n",
    "        mask=sig_mask,\n",
    "        mask_params=dict(marker='h', markersize=15, \n",
    "                    markerfacecolor='y',\n",
    "                    markeredgecolor='k'),\n",
    "        contours=0,\n",
    "        axes=ax\n",
    "    )\n",
    "    plt.colorbar(im, ax=ax, shrink=0.6, label='T-value')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_dir = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set'\n",
    "\n",
    "groups = ['Y', 'O']\n",
    "tasks = ['_BL'] # ['_BL', '_MAIN']\n",
    "task_stages = ['_plan', '_go']\n",
    "\n",
    "theta_range = np.around(np.linspace(4, 8, 20), 1)  # Phase: 4-8 Hz\n",
    "gamma_range = np.around(np.linspace(30, 80, 20), 1)  # Amplitude: 30-80 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STATS FOR DATA AVERAGED ACROSS PHASE AND AMPLITUDE FREQUENCIES**\n",
    "\n",
    "**One condition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Y group, _BL task, _plan stage...\n",
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\Y\\s1_pac_sub01\\preproc\\analysis\\s1_pac_sub01_BL_epochs_plan-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 10 columns\n",
      "99 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "PAC array shape: (23, 60, 20, 20)\n",
      "z-scored PAC array shape: (23, 60, 20, 20)\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 60\n",
      "adjacency shape: (60, 60)\n",
      "stat_fun(H1): min=-3.695075676157254 max=4.256243632434543\n",
      "Running initial clustering …\n",
      "Found 5 clusters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de96706fb32c496e9acbb5954076826c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.818756060596369\n",
      "T_obs_mean = -0.3525254064871378\n",
      "cluster_p_values = [0.0032 0.0883 0.0279 0.144  0.0799]\n",
      "Found 2 significant clusters\n",
      "Processing Y group, _BL task, _go stage...\n",
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\Y\\s1_pac_sub01\\preproc\\analysis\\s1_pac_sub01_BL_epochs_go-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 10 columns\n",
      "84 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "PAC array shape: (23, 60, 20, 20)\n",
      "z-scored PAC array shape: (23, 60, 20, 20)\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 60\n",
      "adjacency shape: (60, 60)\n",
      "stat_fun(H1): min=-3.736325586209756 max=3.909253535412591\n",
      "Running initial clustering …\n",
      "Found 5 clusters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab9eb355333491bb65dd3bcb9048686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.818756060596369\n",
      "T_obs_mean = -0.5061788804929767\n",
      "cluster_p_values = [0.0554 0.0118 0.015  0.0108 0.1992]\n",
      "Found 3 significant clusters\n",
      "Processing O group, _BL task, _plan stage...\n",
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\O\\s1_pac_sub12\\preproc\\analysis\\s1_pac_sub12_BL_epochs_plan-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 10 columns\n",
      "102 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "PAC array shape: (24, 60, 20, 20)\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 60\n",
      "adjacency shape: (60, 60)\n",
      "stat_fun(H1): min=-3.83964792565848 max=2.1196897652630584\n",
      "Running initial clustering …\n",
      "Found 1 cluster\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01526401eacf4951b3400d8f419f0fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.8073356837675227\n",
      "T_obs_mean = -0.45341589460469495\n",
      "cluster_p_values = [0.0006]\n",
      "Found 1 significant clusters\n",
      "Processing O group, _BL task, _go stage...\n",
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\O\\s1_pac_sub12\\preproc\\analysis\\s1_pac_sub12_BL_epochs_go-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 10 columns\n",
      "97 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "PAC array shape: (24, 60, 20, 20)\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 60\n",
      "adjacency shape: (60, 60)\n",
      "stat_fun(H1): min=-7.286726559076422 max=2.3054957664818065\n",
      "Running initial clustering …\n",
      "Found 4 clusters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf69864a1ef4072a71a0c5e068a2bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.8073356837675227\n",
      "T_obs_mean = -0.4879753068690075\n",
      "cluster_p_values = [3.053e-01 1.000e-04 1.118e-01 6.300e-03]\n",
      "Found 2 significant clusters\n"
     ]
    }
   ],
   "source": [
    "# Main script to process PAC data and run cluster-based permutation tests\n",
    "for group in groups:\n",
    "    group_save_path = os.path.join(eeg_data_dir, f'{group} group')\n",
    "    pac_stats_save_path = os.path.join(group_save_path, 'pac_stats')\n",
    "    check_paths(pac_stats_save_path)\n",
    "    \n",
    "    # Create directories for saving figures\n",
    "    fig_group_path = os.path.join(pac_stats_save_path, 'figs')\n",
    "    fig_group_save_path = os.path.join(fig_group_path, group)\n",
    "\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "\n",
    "    for task in tasks:\n",
    "        fig_task_save_path = os.path.join(fig_group_path, group, task)\n",
    "\n",
    "        for task_stage in task_stages:\n",
    "\n",
    "            print(f'Processing {group} group, {task} task, {task_stage} stage...')\n",
    "\n",
    "            ############# STACK PAC DATA OF INDIVIDUAL PARTICIPANTS #############\n",
    "\n",
    "            # Create a list to store the PAC data for each subject\n",
    "            pac_list = []\n",
    "            pac_zscore_list = []\n",
    "\n",
    "            for sub_name in subs:\n",
    "\n",
    "                sub_dir = os.path.join(eeg_data_dir, group, sub_name)\n",
    "                pac_dir = os.path.join(sub_dir, 'pac_results')\n",
    "                \n",
    "                # Get info about chnnals from one participant for adjacency matrix\n",
    "                if sub_name == subs[0]: # read one epochs file to extract info\n",
    "                    # Load EEG data\n",
    "                    epochs_path = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "                    epochs = mne.read_epochs(os.path.join(epochs_path, f\"{sub_name}{task}_epochs{task_stage}-epo.fif\"), preload=True)\n",
    "                    eeg_channel_names = epochs.copy().pick(\"eeg\").ch_names\n",
    "                    epochs.pick(eeg_channel_names)\n",
    "\n",
    "                # Load PAC data\n",
    "                pac = np.load(os.path.join(pac_dir, f\"pac_mi_TOPO_{sub_name[-5:]}{task}{task_stage}.npy\"))\n",
    "                pac_t = np.transpose(pac, (1, 0, 2))\n",
    "                pac_list.append(pac_t)\n",
    "                pac_zscore_list.append(zscore(pac_t))\n",
    "\n",
    "            # Stack them along a new first axis (subject axis)\n",
    "            pac_all = np.stack(pac_list, axis=0)\n",
    "\n",
    "            # Z-score the PAC data across subjects\n",
    "            pac_zscore_all = np.stack(pac_zscore_list, axis=0)\n",
    "            print('PAC array shape:', pac_all.shape) # (24, 60, 20, 20) subs x electrodes x ph_freqs x amp_freqs\n",
    "            print('z-scored PAC array shape:', pac_zscore_all.shape)\n",
    "\n",
    "            # Averafe z-scored PAC over phase and amplitude frequencies\n",
    "            pac_zscore_all_ave = np.mean(pac_zscore_all, axis=(2, 3)) # (24, 60) subs x electrodes\n",
    "            # pac_zscore_all_med = np.median(pac_zscore_all, axis=(2, 3)) # produces more significant clusters\n",
    "\n",
    "            ############# PLOT AND SAVE Z-SCORED PAC AVERAGED ACROSS PARTICIPANTS #############\n",
    "            pac_plot, ax1 = plot_rect_topo_from_epochs(np.mean(pac_zscore_all_ave, axis=(0)), epochs.info,\n",
    "                                                    title=f'{group}{task}{task_stage}: Averaged z-scored PAC MI',\n",
    "                                                    cmap='PiYG', vmin=-0.5, vmax=0.5)\n",
    "            plt.savefig(os.path.join(fig_task_save_path, f\"pac_mi_{group}{task}{task_stage}_PAC_MI_AVE_TOPO.png\"), dpi=300)\n",
    "\n",
    "            pac_ave_plot, ax2 = plot_matrix_topo_from_epochs(np.mean(pac_zscore_all, axis=(0)), epochs.info,\n",
    "                                                            title=f'{group}{task}{task_stage}: z-scored PAC MI',\n",
    "                                                            cmap='PiYG', vmin=-0.5, vmax=0.5)\n",
    "            plt.savefig(os.path.join(fig_task_save_path, f\"pac_mi_{group}{task}{task_stage}_PAC_MI_TOPO.png\"), dpi=300)\n",
    "\n",
    "            # Save the PAC data\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_RAW.npy\"), pac_all)\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_ZSCORE.npy\"), pac_zscore_all)\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_ZSCORE_MEAN.npy\"), pac_zscore_all_ave)\n",
    "\n",
    "            ############### CREATE ADJACENCY MATRIX FOR STATISTICAL TEST #############\n",
    "            # find_ch_adjacency first attempts to find an existing \"neighbor\"\n",
    "            # (adjacency) file for given sensor layout.\n",
    "            # If such a file doesn't exist, an adjacency matrix is computed on the fly,\n",
    "            # using Delaunay triangulations.\n",
    "            sensor_adjacency, ch_names = mne.channels.find_ch_adjacency(epochs.info, \"eeg\")\n",
    "            print('adjacency shape:', sensor_adjacency.shape)\n",
    "\n",
    "\n",
    "            ############# RUN CLUSTER-BASED PERMUTATION TEST #############\n",
    "\n",
    "            tail = 0 # two-tailed test\n",
    "\n",
    "            # Set the threshold for including data bins in clusters with t-value corresponding to p=0.01\n",
    "            # Because we conduct a two-tailed test, we divide the p-value by 2 (which means we're making use of both tails of the distribution).\n",
    "            # As the degrees of freedom, we specify the number of observations (here: subjects) minus 1.\n",
    "            # Finally, we subtract 0.01 / 2 from 1, to get the critical t-value on the right tail\n",
    "            degrees_of_freedom = pac_all.shape[0] - 1\n",
    "            t_thresh = scipy.stats.t.ppf(1 - 0.01 / 2, df=degrees_of_freedom)\n",
    "\n",
    "            #!\n",
    "            # threshold_tfce = dict(start=0, step=0.2) # Threshold-free cluster enhancement (TFCE) - more conservative, similar results\n",
    "\n",
    "            # Set the number of permutations\n",
    "            n_permutations = 10000\n",
    "\n",
    "            # Run the analysis\n",
    "            T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(\n",
    "                pac_zscore_all_ave,\n",
    "                n_permutations=n_permutations,\n",
    "                threshold=t_thresh,\n",
    "                tail=tail,\n",
    "                adjacency=sensor_adjacency,\n",
    "                out_type=\"mask\",\n",
    "                max_step=1,\n",
    "                verbose=True,\n",
    "            )\n",
    "\n",
    "            # # Save the results\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_T_obs.npy\"), T_obs)\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_clusters.npy\"), np.array(clusters, dtype=object))\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_cluster_p_values.npy\"), cluster_p_values)\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_H0.npy\"), H0)\n",
    "\n",
    "            # SANITY CHECKS\n",
    "            print(f't_thresh = {t_thresh}')\n",
    "            print(f'T_obs_mean = {T_obs.mean()}')\n",
    "            print(f'cluster_p_values = {cluster_p_values}')\n",
    "\n",
    "            alpha = 0.05  # significance threshold\n",
    "            significant_clusters = [i for i, p in enumerate(cluster_p_values) if p < alpha]\n",
    "            print(f\"Found {len(significant_clusters)} significant clusters\")\n",
    "\n",
    "\n",
    "            ####### PLOT THE RESULTS #######\n",
    "            plot_significant_topomap(T_obs, clusters, cluster_p_values, epochs.info,\n",
    "                                    group=group, task=task, task_stage=task_stage, block_name='')\n",
    "            plt.savefig(os.path.join(fig_task_save_path, f\"pac_cluster_stats_{group}{task}{task_stage}_freq_ave_TOPO.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TWO CONDITIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_pac_condition(eeg_data_dir, group, task, task_stage, block_name=''):\n",
    "    \"\"\"\n",
    "    Append PAC data for a specific condition (group, task, task_stage, block_name) to the existing data.\n",
    "    \"\"\"\n",
    "\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "    print(f'Processing {group} group, {task} task, {task_stage} stage, {block_name} block...')\n",
    "\n",
    "    ############# STACK PAC DATA OF INDIVIDUAL PARTICIPANTS #############\n",
    "\n",
    "    # Create a list to store the PAC data for each subject\n",
    "    pac_list = []\n",
    "    pac_zscore_list = []\n",
    "\n",
    "    for sub_name in subs:\n",
    "\n",
    "        sub_dir = os.path.join(eeg_data_dir, group, sub_name)\n",
    "        pac_dir = os.path.join(sub_dir, 'pac_results')\n",
    "        \n",
    "        # Get info about chnnals from one participant for adjacency matrix\n",
    "        if sub_name == subs[0]: # read one epochs file to extract info\n",
    "            # Load EEG data\n",
    "            epochs_path = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "            epochs = mne.read_epochs(os.path.join(epochs_path, f\"{sub_name}{task}_epochs{task_stage}{block_name}-epo.fif\"), preload=True)\n",
    "            eeg_channel_names = epochs.copy().pick(\"eeg\").ch_names\n",
    "            epochs.pick(eeg_channel_names)\n",
    "\n",
    "        # Load PAC data\n",
    "        pac = np.load(os.path.join(pac_dir, f\"pac_mi_TOPO_{sub_name[-5:]}{task}{task_stage}{block_name}.npy\"))\n",
    "        pac_t = np.transpose(pac, (1, 0, 2))\n",
    "        pac_list.append(pac_t)\n",
    "        pac_zscore_list.append(zscore(pac_t))\n",
    "\n",
    "    # Stack them along a new first axis (subject axis)\n",
    "    pac_all = np.stack(pac_list, axis=0)\n",
    "\n",
    "    # Z-score the PAC data across subjects\n",
    "    pac_zscore_all = np.stack(pac_zscore_list, axis=0)\n",
    "    print('PAC array shape:', pac_all.shape) # (24, 60, 20, 20) subs x electrodes x ph_freqs x amp_freqs\n",
    "    print('z-scored PAC array shape:', pac_zscore_all.shape)\n",
    "\n",
    "        ############### CREATE ADJACENCY MATRIX FOR STATISTICAL TEST #############\n",
    "    # find_ch_adjacency first attempts to find an existing \"neighbor\"\n",
    "    # (adjacency) file for given sensor layout.\n",
    "    # If such a file doesn't exist, an adjacency matrix is computed on the fly,\n",
    "    # using Delaunay triangulations.\n",
    "    sensor_adjacency = mne.channels.find_ch_adjacency(epochs.info, \"eeg\")[0]\n",
    "    print('adjacency shape:', sensor_adjacency.shape)\n",
    "\n",
    "    return pac_zscore_all, sensor_adjacency, epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats test of difference EXECUTION vs PLANNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Y group, _BL task, _plan stage,  block...\n",
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\Y\\s1_pac_sub01\\preproc\\analysis\\s1_pac_sub01_BL_epochs_plan-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 10 columns\n",
      "99 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "PAC array shape: (23, 60, 20, 20)\n",
      "z-scored PAC array shape: (23, 60, 20, 20)\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 60\n",
      "adjacency shape: (60, 60)\n",
      "Processing Y group, _BL task, _go stage,  block...\n",
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\Y\\s1_pac_sub01\\preproc\\analysis\\s1_pac_sub01_BL_epochs_go-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 10 columns\n",
      "84 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "PAC array shape: (23, 60, 20, 20)\n",
      "z-scored PAC array shape: (23, 60, 20, 20)\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 60\n",
      "adjacency shape: (60, 60)\n",
      "z-scored diff PAC array shape: (23, 60, 20, 20)\n",
      "Adjacency matrix shape: (60, 60)\n",
      "stat_fun(H1): min=-1.9718746677943155 max=4.073190748102221\n",
      "Running initial clustering …\n",
      "Found 1 cluster\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c653c595b4a44cc3b56029af45160b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.818756060596369\n",
      "T_obs_mean = -0.1128458908976368\n",
      "cluster_p_values = [0.0023]\n",
      "Found 1 significant clusters\n",
      "Processing O group, _BL task, _plan stage,  block...\n",
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\O\\s1_pac_sub12\\preproc\\analysis\\s1_pac_sub12_BL_epochs_plan-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 10 columns\n",
      "102 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "PAC array shape: (24, 60, 20, 20)\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 60\n",
      "adjacency shape: (60, 60)\n",
      "Processing O group, _BL task, _go stage,  block...\n",
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\O\\s1_pac_sub12\\preproc\\analysis\\s1_pac_sub12_BL_epochs_go-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 10 columns\n",
      "97 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "PAC array shape: (24, 60, 20, 20)\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 60\n",
      "adjacency shape: (60, 60)\n",
      "z-scored diff PAC array shape: (24, 60, 20, 20)\n",
      "Adjacency matrix shape: (60, 60)\n",
      "stat_fun(H1): min=-3.3557483125625653 max=3.038159054736123\n",
      "Running initial clustering …\n",
      "Found 3 clusters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b727f07a03634919893d05add51bd529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.8073356837675227\n",
      "T_obs_mean = -0.09311410184643125\n",
      "cluster_p_values = [0.2146 0.0045 0.1268]\n",
      "Found 1 significant clusters\n"
     ]
    }
   ],
   "source": [
    "# Main script to process PAC data and run cluster-based permutation tests\n",
    "for group in groups:\n",
    "    group_save_path = os.path.join(eeg_data_dir, f'{group} group')\n",
    "    pac_stats_save_path = os.path.join(group_save_path, 'pac_stats')\n",
    "    check_paths(pac_stats_save_path)\n",
    "    \n",
    "    # Create directories for saving figures\n",
    "    fig_group_path = os.path.join(pac_stats_save_path, 'figs')\n",
    "    fig_group_save_path = os.path.join(fig_group_path, group)\n",
    "\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "    for task in tasks:\n",
    "        fig_task_save_path = os.path.join(fig_group_path, group, task)\n",
    "\n",
    "        # Stack z-scored PAC along a new first axis (subject axis)\n",
    "        plan_pac_zscore_all, sensor_adjacency, epochs = append_pac_condition(eeg_data_dir=eeg_data_dir, group=group,\n",
    "                                                                        task=task, task_stage='_plan')\n",
    "        go_pac_zscore_all = append_pac_condition(eeg_data_dir=eeg_data_dir, group=group,\n",
    "                                                                        task=task, task_stage='_go')[0]\n",
    "        pac_zscore_diff = go_pac_zscore_all - plan_pac_zscore_all\n",
    "        print('z-scored diff PAC array shape:', pac_zscore_diff.shape) # (24, 60, 20, 20) subs x electrodes x ph_freqs x amp_freqs\n",
    "\n",
    "        # Averafe z-scored PAC over phase and amplitude frequencies\n",
    "        pac_zscore_diff_ave = np.mean(pac_zscore_diff, axis=(2, 3)) # (24, 60) subs x electrodes\n",
    "\n",
    "        # # Save the PAC data\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}_GO-PLAN_ZSCORE_freqs_ave.npy\"), pac_zscore_diff_ave)\n",
    "\n",
    "        # ############# PLOT AND SAVE Z-SCORED PAC AVERAGED ACROSS PARTICIPANTS #############\n",
    "        pac_plot, ax1 = plot_rect_topo_from_epochs(np.mean(pac_zscore_diff_ave, axis=(0)), epochs.info,\n",
    "                                                title=f'{group}{task} GO-PLAN: Averaged z-scored PAC MI',\n",
    "                                                cmap='PiYG', vmin=-0.5, vmax=0.5)\n",
    "        plt.savefig(os.path.join(fig_task_save_path, f\"pac_mi_{group}{task}_GO-PLAN_PAC_MI_AVE_TOPO.png\"), dpi=300)\n",
    "\n",
    "        pac_ave_plot, ax2 = plot_matrix_topo_from_epochs(np.mean(pac_zscore_diff, axis=(0)), epochs.info,\n",
    "                                                        title=f'{group}{task} GO-PLAN: z-scored PAC MI',\n",
    "                                                        cmap='PiYG', vmin=-0.5, vmax=0.5)\n",
    "        plt.savefig(os.path.join(fig_task_save_path, f\"pac_mi_{group}{task}_GO-PLAN_PAC_MI_TOPO.png\"), dpi=300)\n",
    "\n",
    "\n",
    "        ############# RUN CLUSTER-BASED PERMUTATION TEST #############\n",
    "        print(f'Adjacency matrix shape: {sensor_adjacency.shape}')\n",
    "        \n",
    "        tail = 0 # two-tailed test\n",
    "\n",
    "        # Set the threshold for including data bins in clusters with t-value corresponding to p=0.01\n",
    "        # Because we conduct a two-tailed test, we divide the p-value by 2 (which means we're making use of both tails of the distribution).\n",
    "        # As the degrees of freedom, we specify the number of observations (here: subjects) minus 1.\n",
    "        # Finally, we subtract 0.01 / 2 from 1, to get the critical t-value on the right tail\n",
    "        degrees_of_freedom = pac_zscore_diff.shape[0] - 1\n",
    "        t_thresh = scipy.stats.t.ppf(1 - 0.01 / 2, df=degrees_of_freedom)\n",
    "\n",
    "        #!\n",
    "        # threshold_tfce = dict(start=0, step=0.2) # Threshold-free cluster enhancement (TFCE) - more conservative, similar results\n",
    "\n",
    "        # Set the number of permutations\n",
    "        n_permutations = 10000\n",
    "\n",
    "        # Run the analysis\n",
    "        T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(\n",
    "            pac_zscore_diff_ave,\n",
    "            n_permutations=n_permutations,\n",
    "            threshold=t_thresh,\n",
    "            tail=tail,\n",
    "            adjacency=sensor_adjacency,\n",
    "            out_type=\"mask\",\n",
    "            max_step=1,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # # Save the results\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}_GO-PLAN_freqs_ave_T_obs.npy\"), T_obs)\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}_GO-PLAN_freqs_ave_clusters.npy\"), np.array(clusters, dtype=object))\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}_GO-PLAN_freqs_ave_cluster_p_values.npy\"), cluster_p_values)\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}_GO-PLAN_freqs_ave_H0.npy\"), H0)\n",
    "\n",
    "        # SANITY CHECKS\n",
    "        print(f't_thresh = {t_thresh}')\n",
    "        print(f'T_obs_mean = {T_obs.mean()}')\n",
    "        print(f'cluster_p_values = {cluster_p_values}')\n",
    "\n",
    "        alpha = 0.05  # significance threshold\n",
    "        significant_clusters = [i for i, p in enumerate(cluster_p_values) if p < alpha]\n",
    "        print(f\"Found {len(significant_clusters)} significant clusters\")\n",
    "\n",
    "\n",
    "        ####### PLOT THE RESULTS #######\n",
    "        plot_significant_topomap(T_obs, clusters, cluster_p_values, epochs.info, group=group, task=task, task_stage='_GO-PLAN')\n",
    "        plt.savefig(os.path.join(fig_task_save_path, f\"pac_cluster_stats_{group}{task}_GO-PLAN_freq_ave_TOPO.png\"), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
