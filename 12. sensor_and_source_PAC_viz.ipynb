{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22edb44",
   "metadata": {},
   "source": [
    "## PLOTTING PAC SOURCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f93a2f",
   "metadata": {},
   "source": [
    "Algorithm to plot sources:\n",
    "1. Iterate through subjects, for each:\n",
    "    - get PAC data\n",
    "    - transpose\n",
    "    - impute NaNs\n",
    "    - aggregate\n",
    "2. Stack PAC estimates along subjects axis\n",
    "3. Average across ph, amp and sub\n",
    "\n",
    "\n",
    "4. Load any morphed source file:\n",
    "    - average time domain to get 1 point\n",
    "    - replace data with PAC data\n",
    "    - rename subject to \"fsaverage_bem\"\n",
    "    - PLOT as regular source estimate\n",
    "    - (optional) add ROI, if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faeef61",
   "metadata": {},
   "source": [
    "ADDITIONAL:\n",
    "- sensor-level PAC\n",
    "- sensor- and source-level TFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d24369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import check_paths\n",
    "\n",
    "import mne\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import zscore\n",
    "from scipy.sparse import coo_matrix, save_npz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16034546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "-- number of adjacent vertices : 5124\n",
      "adjacency shape: (5124, 5124)\n"
     ]
    }
   ],
   "source": [
    "eeg_data_dir = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set'\n",
    "groups = ['Y']\n",
    "tasks = ['_BL', '_MAIN'] # ['_BL', '_MAIN']\n",
    "task_stages = ['_plan', '_go']\n",
    "# block_names = ['_baseline', '_adaptation']\n",
    "\n",
    "# Load adjacency matrix\n",
    "src_fname = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\mri_data\\\\fs_output\\\\freesurfer\\\\sub_dir\\\\Y\\\\fsaverage_bem\\\\bem\\\\fsaverage-ico4-src.fif'\n",
    "src = mne.read_source_spaces(src_fname)\n",
    "# src.plot(subjects_dir='D:\\\\BonoKat\\\\research project\\\\# study 1\\\\mri_data\\\\fs_output\\\\freesurfer\\\\sub_dir\\\\Y')\n",
    "source_adjacency = mne.spatial_src_adjacency(src)\n",
    "adj = source_adjacency.tocsr()  # Ensure adjacency is CSR format for fast indexing\n",
    "print('adjacency shape:', source_adjacency.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fef5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 5124 vertices, subject : fsaverage_bem, tmin : 1.0000000000000009 (ms), tmax : 1.0000000000000009 (ms), tstep : 1002.0 (ms), data shape : (5124, 1), ~60 KiB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load one stc file as a reference\n",
    "stc_path = os.path.join('''D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set\\\\Y\\\\s1_pac_sub01\\\\preproc\\\\analysis\\\\source\\\\morphed_stcs\\\\_MAIN\\\\_plan\\\\_baseline\\\\s1_pac_sub01_MAIN_plan_baseline-stc-lcmv_epoch_000_morphed-lh.stc''')\n",
    "stc_ref = mne.read_source_estimate(stc_path, subject='s1_pac_sub01') # any STC will serve as a template\n",
    "stc_ref_mean = stc_ref.copy().mean()\n",
    "stc_pac = stc_ref_mean.copy()\n",
    "stc_pac.subject = \"fsaverage_bem\"\n",
    "stc_pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc14dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Y group, _BL_plan...\n",
      "Processing Y group, _BL_go...\n",
      "Processing Y group, _MAIN_plan_baseline...\n",
      "Processing Y group, _MAIN_plan_adaptation...\n",
      "Processing Y group, _MAIN_go_baseline...\n",
      "Processing Y group, _MAIN_go_adaptation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using control points [0.         0.         0.00012973]\n",
      "Using control points [0.        0.        0.0003008]\n"
     ]
    }
   ],
   "source": [
    "# Plot PAC MI values\n",
    "\n",
    "views = {'lateral': [\"lateral\", \"medial\"],\n",
    "        'dor-vent': [\"dorsal\", \"ventral\"]}\n",
    "\n",
    "for group in groups:\n",
    "    source_group_dir = os.path.join(eeg_data_dir, f'{group} group', 'sources')\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "    figs_save_path = os.path.join(eeg_data_dir, f'{group} group', 'sources', 'figs')\n",
    "    check_paths(figs_save_path)\n",
    "\n",
    "    \n",
    "\n",
    "    for task in tasks:\n",
    "        if task == '_BL':\n",
    "            block_names = ['']\n",
    "        else:\n",
    "            block_names = ['_baseline', '_adaptation']\n",
    "\n",
    "        for task_stage in task_stages:\n",
    "            for block_name in block_names:\n",
    "                print(f'Processing {group} group, {task}{task_stage}{block_name}...')\n",
    "\n",
    "                pac_list = []\n",
    "                for sub_name in subs:\n",
    "                    analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "                    pac_save_path = os.path.join(analysis_dir, 'source', 'PAC')\n",
    "                    pac_data = np.load(os.path.join(pac_save_path, f\"PAC_MI_SOURCE_{sub_name[-5:]}{task}{task_stage}{block_name}.npy\"))\n",
    "                    pac_data_t = np.transpose(pac_data, (1, 0, 2))\n",
    "\n",
    "                    ### NAN Imputation for PAC Matrices ###\n",
    "                    pac_imputed = pac_data_t.copy()\n",
    "\n",
    "                    # Step 1: Detect vertices with any NaN in their 20Ã—20 PAC\n",
    "                    nan_mask = np.isnan(pac_data_t).any(axis=(1, 2))  # shape (5124,)\n",
    "\n",
    "                    if nan_mask.any() == True:\n",
    "                        # print(f\"Found {nan_mask.sum()} vertices with NaN values.\")\n",
    "\n",
    "                        # Step 2: Impute NaNs from neighbors\n",
    "                        for vtx in np.where(nan_mask)[0]:\n",
    "                            neighbors = adj[[vtx]].indices\n",
    "                            valid_neighbors = [n for n in neighbors if not nan_mask[n]]\n",
    "                            # Average PAC matrices from neighbors\n",
    "                            pac_imputed[vtx] = np.nanmean(pac_data_t[valid_neighbors], axis=0)\n",
    "\n",
    "                    # pac_zscore = zscore(pac_imputed, axis=0, nan_policy='omit')\n",
    "                    pac_list.append(pac_imputed)\n",
    "\n",
    "                # Stack them along a new first axis (subject axis)\n",
    "                pac_all = np.stack(pac_list, axis=0)\n",
    "                # print('PAC array shape:', pac_all.shape)\n",
    "                pac_map = pac_all.mean(axis=(0, 2, 3))\n",
    "                # print('Averaged PAC map shape:', pac_map.shape)\n",
    "                stc_pac._data = pac_map[:, None]   # (n_vertices_total, 1)\n",
    "                # print('STC data shape:', stc_pac.data.shape)\n",
    "                # Save morphed stc\n",
    "                stc_pac.save(os.path.join(source_group_dir, f\"PAC_for_STATS_{group}{task}{task_stage}{block_name}_fsaverage\"), overwrite=True)\n",
    "\n",
    "                clim = dict(\n",
    "                    kind=\"value\",\n",
    "                    lims=[\n",
    "                        np.nanmin(pac_map), \n",
    "                        (np.nanmax(pac_map) - np.nanmin(pac_map)) / 2 + np.nanmin(pac_map), \n",
    "                        np.nanmax(pac_map)\n",
    "                        ],   # [min, mid, max]\n",
    "                    )\n",
    "\n",
    "                for key, value in views.items():\n",
    "                    title = f\"ALL_SUBS_{group}{task}{task_stage}{block_name}_PAC_MI_{key}\"\n",
    "\n",
    "                    brain = stc_pac.plot(subject=\"fsaverage_bem\",\n",
    "                                initial_time=0.0,\n",
    "                                clim=clim,\n",
    "                                cortex=\"low_contrast\",\n",
    "                                colormap='plasma', # 'plasma' for raw MI, 'cool' for zscored MI\n",
    "                                hemi='both',\n",
    "                                views=value, # \"dorsal\", \"ventral\"\n",
    "                                background='white',\n",
    "                                title = title\n",
    "                                )\n",
    "\n",
    "                    brain.save_image(os.path.join(figs_save_path, title + '.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a817c77",
   "metadata": {},
   "source": [
    "PLOTTING STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288b04ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot significant PAC\n",
    "\n",
    "# Significant conditions:\n",
    "# FTT (BL) planning\n",
    "# De-CRAT (MAIN) planning baseline\n",
    "\n",
    "group_save_path = os.path.join(eeg_data_dir, f'{group} group')\n",
    "pac_stats_save_path = os.path.join(group_save_path, 'source_pac_stats')\n",
    "sig_conditions = ['Y_BL_plan', 'Y_MAIN_plan_baseline']\n",
    "p_thresh = 0.05\n",
    "\n",
    "for sig_cond in sig_conditions:\n",
    "\n",
    "    # Load stats data\n",
    "    T_obs = np.load(os.path.join(pac_stats_save_path, f\"PAC_MI_SOURCE_{sig_cond}_freqs_ave_T_obs.npy\"))\n",
    "    clusters = np.load(os.path.join(pac_stats_save_path, f\"PAC_MI_SOURCE_{sig_cond}_freqs_ave_clusters.npy\"), allow_pickle=True)\n",
    "    cluster_p_values = np.load(os.path.join(pac_stats_save_path, f\"PAC_MI_SOURCE_{sig_cond}_freqs_ave_cluster_p_values.npy\"))\n",
    "\n",
    "    # Combine significant cluster masks\n",
    "    sig_mask = np.zeros_like(T_obs, dtype=bool)\n",
    "    for cluster, p_val in zip(clusters, cluster_p_values):\n",
    "        if p_val <= p_thresh:\n",
    "            sig_mask |= cluster.astype(bool)\n",
    "    sig_mask = sig_mask[:, None]\n",
    "    title = f\"Significant PAC - {sig_cond}\"\n",
    "\n",
    "    sig_cond = [sig_cond + '_' if sig_cond == 'Y_BL_plan' else sig_cond][0]\n",
    "    group, task, task_stage, block_name = sig_cond.split('_')\n",
    "    block_name = ['_' + block_name if block_name != '' else block_name][0]\n",
    "\n",
    "    for sub_name in subs:\n",
    "\n",
    "        pac_list = []\n",
    "\n",
    "        analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "        pac_save_path = os.path.join(analysis_dir, 'source', 'PAC')\n",
    "        pac_data = np.load(os.path.join(pac_save_path, f\"PAC_MI_SOURCE_{sub_name[-5:]}{'_' + task}{'_' + task_stage}{block_name}.npy\"))\n",
    "        pac_data_t = np.transpose(pac_data, (1, 0, 2))\n",
    "\n",
    "        ### NAN Imputation for PAC Matrices ###\n",
    "        pac_imputed = pac_data_t.copy()\n",
    "\n",
    "        # Step 1: Detect vertices with any NaN in their 20Ã—20 PAC\n",
    "        nan_mask = np.isnan(pac_data_t).any(axis=(1, 2))  # shape (5124,)\n",
    "\n",
    "        if nan_mask.any() == True:\n",
    "            # print(f\"Found {nan_mask.sum()} vertices with NaN values.\")\n",
    "\n",
    "            # Step 2: Impute NaNs from neighbors\n",
    "            for vtx in np.where(nan_mask)[0]:\n",
    "                neighbors = adj[[vtx]].indices\n",
    "                valid_neighbors = [n for n in neighbors if not nan_mask[n]]\n",
    "                # Average PAC matrices from neighbors\n",
    "                pac_imputed[vtx] = np.nanmean(pac_data_t[valid_neighbors], axis=0)\n",
    "\n",
    "        # pac_zscore = zscore(pac_imputed, axis=0, nan_policy='omit')\n",
    "        pac_list.append(pac_imputed)\n",
    "\n",
    "    # Stack them along a new first axis (subject axis)\n",
    "    pac_all = np.stack(pac_list, axis=0)\n",
    "    # print('PAC array shape:', pac_all.shape)\n",
    "    pac_map = pac_all.mean(axis=(0, 2, 3))\n",
    "    # print('Averaged PAC map shape:', pac_map.shape)\n",
    "    stc_pac._data = pac_map[:, None]   # (n_vertices_total, 1)\n",
    "    # print('STC data shape:', stc_pac.data.shape)\n",
    "    \n",
    "    # Copy the STC to avoid modifying the original\n",
    "    stc_sig = copy.deepcopy(stc_pac)\n",
    "    stc_sig.data[~sig_mask] = 0.0\n",
    "\n",
    "    clim = dict(\n",
    "        kind=\"value\",\n",
    "        lims=[\n",
    "            np.nanmin(pac_map), \n",
    "            (np.nanmax(pac_map) - np.nanmin(pac_map)) / 2 + np.nanmin(pac_map), \n",
    "            np.nanmax(pac_map)\n",
    "            ],   # [min, mid, max]\n",
    "        )\n",
    "    # view = [[\"dorsal\", \"lateral\"] if sig_cond == 'Y_BL_plan_' else [\"dorsal\", \"parietal\"]]\n",
    "    brain = stc_sig.plot(subject=\"fsaverage_bem\",\n",
    "                initial_time=0.0,\n",
    "                clim=clim,\n",
    "                cortex=\"low_contrast\",\n",
    "                colormap='hot', # 'plasma' for raw MI, 'cool' for zscored MI\n",
    "                hemi='both',\n",
    "                views=[[\"dorsal\", \"lateral\"] if sig_cond == 'Y_BL_plan_' else [\"dorsal\", \"parietal\"]][0],\n",
    "                background='white',\n",
    "                title = title,\n",
    "                )\n",
    "    brain.save_image(os.path.join(figs_save_path, title + '.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec199051",
   "metadata": {},
   "source": [
    "____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e8931",
   "metadata": {},
   "source": [
    "PLOTTING PAC MI ON SENSOR LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3fc9e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\Y\\s1_pac_sub01\\preproc\\analysis\\s1_pac_sub01_BL_epochs_go-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 10 columns\n",
      "84 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60, 501)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_data_dir = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set'\n",
    "groups = ['Y']\n",
    "tasks = ['_BL', '_MAIN'] # ['_BL', '_MAIN']\n",
    "task_stages = ['_plan', '_go']\n",
    "# block_names = ['_baseline', '_adaptation']\n",
    "\n",
    "epochs_path = os.path.join(eeg_data_dir, group, 's1_pac_sub01', 'preproc', 'analysis', 's1_pac_sub01_BL_epochs_go-epo.fif')\n",
    "epochs = mne.read_epochs(epochs_path, preload=True)\n",
    "evoked = epochs.average()\n",
    "evoked.data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83ab7672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Y group, _BL_plan...\n",
      "(60,)\n",
      "Processing Y group, _BL_go...\n",
      "(60,)\n",
      "Processing Y group, _MAIN_plan_baseline...\n",
      "(60,)\n",
      "Processing Y group, _MAIN_plan_adaptation...\n",
      "(60,)\n",
      "Processing Y group, _MAIN_go_baseline...\n",
      "(60,)\n",
      "Processing Y group, _MAIN_go_adaptation...\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "    sensor_figs_path = os.path.join(eeg_data_dir, f'{group} group', 'sensors')\n",
    "    check_paths(sensor_figs_path)\n",
    "    figs_save_path = os.path.join(sensor_figs_path, 'figs', 'PAC')\n",
    "    check_paths(figs_save_path)\n",
    "    \n",
    "\n",
    "    for task in tasks:\n",
    "        if task == '_BL':\n",
    "            block_names = ['']\n",
    "        else:\n",
    "            block_names = ['_baseline', '_adaptation']\n",
    "\n",
    "        for task_stage in task_stages:\n",
    "            for block_name in block_names:\n",
    "                print(f'Processing {group} group, {task}{task_stage}{block_name}...')\n",
    "\n",
    "                pac_list = []\n",
    "                for sub_name in subs:\n",
    "\n",
    "                    analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'pac_results')\n",
    "                    pac_data = np.load(os.path.join(analysis_dir, f\"pac_mi_TOPO_{sub_name[-5:]}{task}{task_stage}{block_name}.npy\"))\n",
    "                    pac_data_t = np.transpose(pac_data, (1, 0, 2))\n",
    "                    pac_list.append(pac_data_t)\n",
    "\n",
    "                # Stack them along a new first axis (subject axis)\n",
    "                pac_all = np.stack(pac_list, axis=0)\n",
    "                pac_all_ave = np.mean(pac_all, axis=(0, 2, 3))\n",
    "                print(pac_all_ave.shape)\n",
    "                evoked.data = pac_all_ave\n",
    "\n",
    "\n",
    "                fig, ax = plt.subplots(figsize=(6, 6))  # increase figure size here\n",
    "                im, cn = mne.viz.plot_topomap(\n",
    "                    evoked.data,\n",
    "                    evoked.info,\n",
    "                    ch_type=\"eeg\",\n",
    "                    sensors=True,\n",
    "                    names=evoked.ch_names,\n",
    "                    cmap=\"plasma\",\n",
    "                    vlim=(evoked.data.min(), evoked.data.max()),\n",
    "                    axes=ax,\n",
    "                    show=False\n",
    "                )\n",
    "\n",
    "                # add colorbar\n",
    "                plt.colorbar(im, ax=ax)\n",
    "                plt.title(f\"PAC MI: {group}{task}{task_stage}{block_name}\")\n",
    "                plt.show()\n",
    "                plt.savefig(os.path.join(figs_save_path, f\"PAC_MI_topo{task}{task_stage}{block_name}.png\"))\n",
    "                plt.close()\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885b48b",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3063c2",
   "metadata": {},
   "source": [
    "Sensor-level TF and PSD by bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7d5ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_dir = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set'\n",
    "groups = ['Y']\n",
    "tasks = ['_BL', '_MAIN'] # ['_BL', '_MAIN']\n",
    "task_stages = ['_plan', '_go']\n",
    "sub_name = 'ALL_subs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf954d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "\n",
    "    group_save_path = f'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set\\\\{group} group'\n",
    "\n",
    "    subs_dir = os.path.join(eeg_data_dir, group)\n",
    "    subs = os.listdir(subs_dir)\n",
    "    sensor_figs_path = os.path.join(eeg_data_dir, f'{group} group', 'sensors')\n",
    "    tfr_figs_save_path = os.path.join(sensor_figs_path, 'figs', 'TF')\n",
    "    psd_figs_save_path = os.path.join(sensor_figs_path, 'figs', 'PSD_bands')\n",
    "    check_paths(tfr_figs_save_path, psd_figs_save_path)\n",
    "\n",
    "    for task in tasks:\n",
    "        if task == '_BL':\n",
    "            block_names = ['']\n",
    "        else:\n",
    "            block_names = ['_baseline', '_adaptation']\n",
    "\n",
    "        for task_stage in task_stages:\n",
    "            for block_name in block_names:\n",
    "                print(f'Processing {group} group, {task}{task_stage}{block_name}...')\n",
    "\n",
    "\n",
    "                epochs_all_subs = mne.read_epochs(os.path.join(\n",
    "                    group_save_path, f\"{group}_{sub_name}{task}_epochs{task_stage}{block_name}_ALL-epo.fif\"\n",
    "                    ), preload=True)\n",
    "                #! Change baseline for prestim period (if not applied yet)\n",
    "                epochs_all_subs.apply_baseline(baseline=(-0.5, -0.001))\n",
    " \n",
    "                freqs = np.logspace(*np.log10([4.0, epochs_all_subs.info['lowpass']]), num=40)\n",
    "                n_cycles = freqs / 2.0  # different number of cycle per frequency\n",
    "                baseline_tf = (epochs_all_subs.times.min(), -0.01)\n",
    "\n",
    "                ### COMPUTE POWER TFR AND ITC ###\n",
    "                power, itc = epochs_all_subs.compute_tfr(\n",
    "                    method=\"morlet\",\n",
    "                    freqs=freqs,\n",
    "                    n_cycles=n_cycles,\n",
    "                    average=True,\n",
    "                    return_itc=True,\n",
    "                    decim=3,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "                power.apply_baseline(baseline=baseline_tf, mode=\"zscore\")\n",
    "\n",
    "                # plot ITC and Power\n",
    "                itc_fig = itc.plot(combine='mean',\n",
    "                                    title=f'ITC: {group}{task}{task_stage}{block_name}',\n",
    "                                    cmap='autumn')[0]\n",
    "                power_all_fig = power.plot(mode=\"zscore\",\n",
    "                                            title=f'Averaged Power: {task}{task_stage}{block_name}',\n",
    "                                            combine='mean', cmap='summer')[0]\n",
    "\n",
    "                ax1, ax2 = itc_fig.axes[0], power_all_fig.axes[0]   # main TFR axis\n",
    "\n",
    "                quadmesh_itc = ax1.collections[0]  # the heatmap\n",
    "                quadmesh_itc.set_clim(vmin=-0.15, vmax=0.15)\n",
    "\n",
    "                quadmesh_power = ax2.collections[0]  # the heatmap\n",
    "                quadmesh_power.set_clim(vmin=-4, vmax=4)\n",
    "\n",
    "                ### COMPUTE POWER SPECTRAL DENSITY BY BAND ###\n",
    "                spectrum = epochs_all_subs.compute_psd()\n",
    "                bands = {'Theta (4-8 Hz)': (4, 8),\n",
    "                        'Alpha (8-12 Hz)': (8, 12),\n",
    "                        'Beta (12-30 Hz)': (12, 30),\n",
    "                        'Gamma (30-50 Hz)': (30, 50),\n",
    "                        'High gamma (50-80 Hz)': (50, 80)}\n",
    "\n",
    "                fig_psd = spectrum.plot_topomap(bands=bands,\n",
    "                                                vlim=\"joint\",\n",
    "                                                normalize=True,\n",
    "                                                cmap='summer')\n",
    "                fig_psd.suptitle(f'PSD Topomap: {group}{task}{task_stage}{block_name}')\n",
    "\n",
    "\n",
    "                # save ITC and Power plots\n",
    "                itc_fig.savefig(os.path.join(tfr_figs_save_path,\n",
    "                                             f\"{group}_{sub_name}{task}{task_stage}{block_name}_itc.png\"),\n",
    "                                             dpi=300)\n",
    "                power_all_fig.savefig(os.path.join(tfr_figs_save_path,\n",
    "                                                   f\"{group}_{sub_name}{task}{task_stage}{block_name}_power_all.png\"),\n",
    "                                                   dpi=300)\n",
    "                fig_psd.savefig(os.path.join(psd_figs_save_path, f\"{group}_{sub_name}{task}{task_stage}{block_name}_psd_topomap.png\"), dpi=300)\n",
    "\n",
    "# plt.close('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61973d13",
   "metadata": {},
   "source": [
    "________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dcfa00",
   "metadata": {},
   "source": [
    "Source-level TF modulations by bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d537740",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = {'theta': (4, 8),\n",
    "        'alpha': (8, 12),\n",
    "        'beta': (12, 30),\n",
    "        'gamma': (30, 80)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f23d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_dir = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set'\n",
    "sub_name = 's1_pac_sub64'\n",
    "group = 'Y'\n",
    "task = '_MAIN' # ['_BL', '_MAIN']\n",
    "task_stage = '_go'\n",
    "block_name = '_adaptation'\n",
    "band = 'theta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "stcs_path = os.path.join(analysis_dir, 'source', 'morphed_stcs', task, task_stage, block_name) \n",
    "\n",
    "for stc_file in os.listdir(stcs_path):\n",
    "    if stc_file.endswith('-rh.stc'): # MNE will load both hemispheres anyway\n",
    "        stc_path = os.path.join(stcs_path, stc_file)\n",
    "        stc = mne.read_source_estimate(stc_path, subject=sub_name)\n",
    "        stc.crop(tmin=0, tmax=None)\n",
    "\n",
    "\n",
    "        stcs_bands_path = os.path.join(stcs_path, band)\n",
    "        check_paths(stcs_bands_path)\n",
    "        l_freq, h_freq = bands[band]\n",
    "        stc._data = stc.data.astype(float)\n",
    "        stc.filter(l_freq, h_freq, n_jobs=-1, method='fir', fir_window='hamming')\n",
    "        stc.save(os.path.join(stcs_bands_path, stc_file[:-4] + f'_{band}-stc'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85127530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter source estimates by frequency bands and save\n",
    "# DONE\n",
    "\n",
    "for group in groups:\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))    \n",
    "\n",
    "    for task in tasks:\n",
    "        if task == '_BL':\n",
    "            block_names = ['']\n",
    "        else:\n",
    "            block_names = ['_baseline', '_adaptation']\n",
    "\n",
    "        for task_stage in task_stages:\n",
    "            for block_name in block_names:\n",
    "                print(f'Filtering sources: {group}{task}{task_stage}{block_name}...')\n",
    "\n",
    "                for sub_name in subs:                    \n",
    "                    analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "                    stcs_path = os.path.join(analysis_dir, 'source', 'morphed_stcs', task, task_stage, block_name) \n",
    "\n",
    "                    for stc_file in os.listdir(stcs_path):\n",
    "                        if stc_file.endswith('-rh.stc'): # MNE will load both hemispheres anyway\n",
    "                            stc_path = os.path.join(stcs_path, stc_file)\n",
    "                            stc = mne.read_source_estimate(stc_path, subject=sub_name)\n",
    "                            stc.crop(tmin=0, tmax=None)\n",
    "\n",
    "                            for band in bands.keys():\n",
    "                                stcs_bands_path = os.path.join(stcs_path, band)\n",
    "                                check_paths(stcs_bands_path)\n",
    "                                l_freq, h_freq = bands[band]\n",
    "                                stc._data = stc.data.astype(float)\n",
    "                                stc.filter(l_freq, h_freq, n_jobs=-1, method='fir', fir_window='hamming')\n",
    "                                stc.save(os.path.join(stcs_bands_path, stc_file[:-4] + f'_{band}-stc'), overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize band-specific storage: Average and visualize stcs per band, then remove single epochs\n",
    "# - Save sub's STCs in .npy format\n",
    "# - Remove original .stc files\n",
    "# - save averaged STC\n",
    "# - save movies\n",
    "\n",
    "\n",
    "for group in groups:\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "    figs_save_path = os.path.join(f'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set\\\\figures\\\\{group}', 'stc_movies')\n",
    "    check_paths(figs_save_path)\n",
    "\n",
    "    for sub_name in subs:\n",
    "        analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "\n",
    "        for task in tasks:\n",
    "            if task == '_BL':\n",
    "                block_names = ['']\n",
    "            else:\n",
    "                block_names = ['_baseline', '_adaptation']\n",
    "\n",
    "            for task_stage in task_stages:\n",
    "                for block_name in block_names:\n",
    "                    for band in bands.keys():\n",
    "                        stcs_path = os.path.join(analysis_dir, 'source', 'morphed_stcs', task, task_stage, block_name, band)\n",
    "                        \n",
    "                        print(f'Filtering sources: {group}{task}{task_stage}{block_name}_{band}...')\n",
    "\n",
    "                        stcs = []\n",
    "                        stcs_data = []\n",
    "\n",
    "                        for stc_file in os.listdir(stcs_path):\n",
    "                            if stc_file.endswith('-rh.stc'): # MNE will load both hemispheres anyway\n",
    "                                stc_path = os.path.join(stcs_path, stc_file)\n",
    "                                stc = mne.read_source_estimate(stc_path, subject=sub_name)\n",
    "                                stcs.append(stc)\n",
    "                                stcs_data.append(stc.data)\n",
    "                                #!!!!!!!!!!! removing the files !!!!!!!!!!\n",
    "                                os.remove(stc_path) # remove -rh file\n",
    "                                os.remove(os.path.join(stc_path[:-7] + '-lh.stc')) # remove -lh file\n",
    "\n",
    "                        stc_ave = stc.copy()\n",
    "                        stcs_data = np.array(stcs_data)\n",
    "                        stc_ave.data = np.mean(stcs_data, axis=0)\n",
    "                        stc_ave.subject = \"fsaverage_bem\"\n",
    "\n",
    "                        clim = dict(\n",
    "                            kind=\"value\",\n",
    "                            lims=[\n",
    "                                np.nanmin(stc_ave.data), \n",
    "                                (np.nanmax(stc_ave.data) - np.nanmin(stc_ave.data)) / 2 + np.nanmin(stc_ave.data), \n",
    "                                np.nanmax(stc_ave.data)\n",
    "                                ],   # [min, mid, max]\n",
    "                            )\n",
    "                        fig_title = f'{sub_name}_average STC for {task[1:]}{task_stage}{block_name}, {band} band'\n",
    "                        file_name = f'{sub_name}_STCs{task}{task_stage}{block_name}_{band}'\n",
    "\n",
    "                        brain = stc_ave.plot(subject=\"fsaverage_bem\",\n",
    "                                    initial_time=0.0,\n",
    "                                    clim=clim,\n",
    "                                    cortex=\"low_contrast\",\n",
    "                                    colormap='seismic',\n",
    "                                    hemi='both',\n",
    "                                    views=[\"dorsal\", \"lateral\", \"medial\"],\n",
    "                                    background='white',\n",
    "                                    title = fig_title,\n",
    "                                    )\n",
    "\n",
    "                        brain.save_movie(os.path.join(figs_save_path, file_name + '_AVE.mp4'), time_dilation=10.0)\n",
    "                        stc_ave.save(os.path.join(stcs_path, file_name + '_AVE'))\n",
    "                        np.save(os.path.join(stcs_path, file_name + '-epo-data.npy'), stc_ave.data)\n",
    "                        brain.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_dir = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set'\n",
    "groups = ['Y']\n",
    "tasks = ['_BL', '_MAIN']\n",
    "task_stages = ['_plan', '_go']\n",
    "bands = {\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 12),\n",
    "    'beta': (12, 30),\n",
    "    'gamma': (30, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average STCs per band across all participants\n",
    "\n",
    "for group in groups:\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "    figs_save_path = os.path.join(f'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set\\\\{group} group\\\\sources\\\\figs', 'stc_movies')\n",
    "    stc_save_path = os.path.join(f'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set\\\\{group} group\\\\sources', 'stcs_by_bands')\n",
    "    check_paths(figs_save_path)\n",
    "    check_paths(stc_save_path)\n",
    "\n",
    "    for task in tasks:\n",
    "        if task == '_BL':\n",
    "            block_names = ['']\n",
    "        else:\n",
    "            block_names = ['_baseline', '_adaptation']\n",
    "\n",
    "        for task_stage in task_stages:\n",
    "            for block_name in block_names:\n",
    "\n",
    "                for band in bands.keys():\n",
    "                    print(f'Analysing sources: {group}{task}{task_stage}{block_name}_{band}...')\n",
    "                    ave_stcs = []\n",
    "                    ave_stcs_data = []\n",
    "\n",
    "                    for sub_name in subs:\n",
    "\n",
    "                        analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "                        stcs_path = os.path.join(analysis_dir, 'source', 'morphed_stcs', task, task_stage, block_name, band)\n",
    "                        stc_file = f'{sub_name}_STCs{task}{task_stage}{block_name}_{band}_AVE-rh.stc'\n",
    "                        stc = mne.read_source_estimate(os.path.join(stcs_path, stc_file), subject=sub_name)\n",
    "                        ave_stcs.append(stc)\n",
    "                        ave_stcs_data.append(stc.data)\n",
    "\n",
    "                    ave_stcs_all = stc.copy()\n",
    "                    ave_stcs_data = np.array(ave_stcs_data)\n",
    "                    ave_stcs_all.data = np.mean(ave_stcs_data, axis=0)\n",
    "                    ave_stcs_all.subject = \"fsaverage_bem\"\n",
    "\n",
    "                    clim = dict(\n",
    "                        kind=\"value\",\n",
    "                        lims=[\n",
    "                            np.nanmin(ave_stcs_all.data), \n",
    "                            (np.nanmax(ave_stcs_all.data) - np.nanmin(ave_stcs_all.data)) / 2 + np.nanmin(ave_stcs_all.data), \n",
    "                            np.nanmax(ave_stcs_all.data)\n",
    "                            ],   # [min, mid, max]\n",
    "                        )\n",
    "                    fig_title = f'{group}_average STC for {task[1:]}{task_stage}{block_name}, {band} band'\n",
    "                    file_name = f'{group}_STCs{task}{task_stage}{block_name}_{band}'\n",
    "\n",
    "                    brain = ave_stcs_all.plot(subject=\"fsaverage_bem\",\n",
    "                                initial_time=0.0,\n",
    "                                clim=clim,\n",
    "                                cortex=\"low_contrast\",\n",
    "                                colormap='seismic',\n",
    "                                hemi='both',\n",
    "                                views=[\"dorsal\", \"lateral\", \"medial\"],\n",
    "                                background='white',\n",
    "                                title = fig_title,\n",
    "                                )\n",
    "\n",
    "                    brain.save_movie(os.path.join(figs_save_path, file_name + '_GRAND_AVE.mp4'), time_dilation=10.0)\n",
    "                    ave_stcs_all.save(os.path.join(stc_save_path, file_name + '_GRAND_AVE'), overwrite=True)\n",
    "                    brain.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ed5a0",
   "metadata": {},
   "source": [
    "STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d1eb57",
   "metadata": {},
   "source": [
    "______\n",
    "Plotting drafts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e274ddd",
   "metadata": {},
   "source": [
    "Check for zeros and nans in averaged scts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1225b26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 5124 vertices, subject : fsaverage_bem, tmin : 0.0 (ms), tmax : 500.0 (ms), tstep : 2.0 (ms), data shape : (5124, 251), ~4.9 MiB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stcs_path = os.path.join('D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set\\\\Y group\\\\sources\\\\stcs_by_bands\\\\Y_STCs_MAIN_plan_baseline_beta_GRAND_AVE-rh.stc')\n",
    "stcs = mne.read_source_estimate(stcs_path, subject='fsaverage_bem')\n",
    "stcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8286b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = dict(\n",
    "    kind=\"value\",\n",
    "    lims=[\n",
    "        np.nanmin(stcs.data), \n",
    "        (np.nanmax(stcs.data) - np.nanmin(stcs.data)) / 2 + np.nanmin(stcs.data), \n",
    "        np.nanmax(stcs.data)\n",
    "        ],   # [min, mid, max]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b510b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mne.viz._brain._brain.Brain at 0x2dee360f7a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stcs.plot(subject=\"fsaverage_bem\", clim=clim, hemi='both', views=[\"dorsal\", \"lateral\", \"medial\"], background='white', colormap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c2c608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00027706206 0.0002722347\n"
     ]
    }
   ],
   "source": [
    "print(np.nanmin(stcs.data[:, 100]), np.nanmax(stcs.data[:, 100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95e951af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([649]), array([46]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(stcs.data == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4d5f1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stcs.data[649][46]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a312aed",
   "metadata": {},
   "source": [
    "___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80293cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 5124, 249)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eeg_data_dir = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set'\n",
    "group = 'Y'\n",
    "figs_save_path = os.path.join(eeg_data_dir, f'{group} group', 'sources', 'figs')\n",
    "check_paths(figs_save_path)\n",
    "\n",
    "\n",
    "sub_name = 's1_pac_sub07'\n",
    "analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "task = '_MAIN'\n",
    "task_stage = '_plan'\n",
    "block_name = '_baseline'\n",
    "\n",
    "stcs_path = os.path.join(analysis_dir, 'source', 'morphed_stcs', task, task_stage, block_name)\n",
    "\n",
    "stcs = []\n",
    "stcs_data = []\n",
    "\n",
    "tmin = 0.0\n",
    "tmax = 0.495\n",
    "\n",
    "for stc_file in os.listdir(stcs_path):\n",
    "    if stc_file.endswith('-rh.stc'): # MNE will load both hemispheres anyway\n",
    "        stc_path = os.path.join(stcs_path, stc_file)\n",
    "        stc = mne.read_source_estimate(stc_path, subject=sub_name)\n",
    "        stc.crop(tmin=tmin, tmax=tmax)\n",
    "        stcs.append(stc)\n",
    "        stcs_data.append(stc.data)\n",
    "\n",
    "source_array = np.stack(stcs_data, axis=0)\n",
    "source_array.shape # (epochs x vertices x time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d431aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 5124 vertices, subject : fsaverage_bem, tmin : 0.0 (ms), tmax : 496.0 (ms), tstep : 2.0 (ms), data shape : (5124, 249), ~4.9 MiB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mri_data_dir = f'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\mri_data\\\\fs_output\\\\freesurfer\\\\sub_dir\\\\Y'\n",
    "# fname_fsaverage_src = os.path.join(mri_data_dir, \"fsaverage_bem\", \"bem\", \"fsaverage-ico4-src.fif\")\n",
    "\n",
    "# eeg_data_dir = os.path.join('D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set', group)\n",
    "# src_to = mne.read_source_spaces(fname_fsaverage_src)\n",
    "\n",
    "# # Morph the source estimates to the fsaverage space\n",
    "# morph = mne.compute_source_morph(\n",
    "#     stc,\n",
    "#     subject_from=sub_name,\n",
    "#     subject_to=\"fsaverage_bem\",\n",
    "#     src_to=src_to,\n",
    "#     subjects_dir=mri_data_dir,\n",
    "#     smooth=5 # small smoothing to avoid artifacts in the morphed data\n",
    "# )\n",
    "\n",
    "# stc_fsaverage = morph.apply(stc)\n",
    "# stc.plot()\n",
    "# stc_fsaverage.plot()\n",
    "# stc_fsaverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7fef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 vertices with NaN values.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<SourceEstimate | 5124 vertices, subject : fsaverage_bem, tmin : 249.0 (ms), tmax : 249.0 (ms), tstep : 498.0 (ms), data shape : (5124, 1), ~80 KiB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis_dir = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "pac_save_path = os.path.join(analysis_dir, 'source', 'PAC')\n",
    "pac_data = np.load(os.path.join(pac_save_path, f\"PAC_MI_SOURCE_{sub_name[-5:]}{task}{task_stage}{block_name}.npy\"))\n",
    "\n",
    "pac_data_t = np.transpose(pac_data, (1, 0, 2))\n",
    "\n",
    "### NAN Imputation for PAC Matrices ###\n",
    "pac_imputed = pac_data_t.copy()\n",
    "\n",
    "# Step 1: Detect vertices with any NaN in their 20Ã—20 PAC\n",
    "nan_mask = np.isnan(pac_data_t).any(axis=(1, 2))  # shape (5124,)\n",
    "\n",
    "if nan_mask.any() == True:\n",
    "    print(f\"Found {nan_mask.sum()} vertices with NaN values.\")\n",
    "\n",
    "    # Step 2: Impute NaNs from neighbors\n",
    "    for vtx in np.where(nan_mask)[0]:\n",
    "        neighbors = adj[[vtx]].indices\n",
    "        valid_neighbors = [n for n in neighbors if not nan_mask[n]]\n",
    "        # Average PAC matrices from neighbors\n",
    "        pac_imputed[vtx] = np.nanmean(pac_data_t[valid_neighbors], axis=0)\n",
    "\n",
    "pac_zscore = zscore(pac_imputed, axis=0, nan_policy='omit')\n",
    "pac_map = pac_zscore.mean(axis=(1, 2))\n",
    "pac_map_clean = np.nan_to_num(pac_map, nan=1, posinf=0.0, neginf=0.0)\n",
    "stc_ref = stcs[0]  # any one of your loaded STCs\n",
    "stc_ref_mean = stc_ref.copy().mean()\n",
    "stc_pac = stc_ref_mean.copy()\n",
    "stc_pac._data = pac_map_clean[:, None]   # (n_vertices_total, 1)\n",
    "stc_pac.subject = \"fsaverage_bem\"\n",
    "stc_pac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7970d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = dict(\n",
    "    kind=\"value\",\n",
    "    lims=[np.nanmin(pac_map), (np.nanmax(pac_map) - np.nanmin(pac_map)) / 2 + np.nanmin(pac_map), np.nanmax(pac_map)],   # [min, mid, max]\n",
    "    \n",
    ")\n",
    "\n",
    "views = {'lateral': [\"lateral\", \"medial\"],\n",
    "         'dor-vent': [\"dorsal\", \"ventral\"]}\n",
    "\n",
    "for key, value in views.items():\n",
    "    title = f\"{sub_name[-5:]}{task}{task_stage}{block_name}_z-score_PAC_{key}\"\n",
    "\n",
    "    brain = stc_pac.plot(subject=\"fsaverage_bem\",\n",
    "                initial_time=0.0,\n",
    "                clim=clim,\n",
    "                cortex=\"low_contrast\",\n",
    "                colormap='plasma', # 'plasma' for raw MI, 'cool' for zscored MI\n",
    "                hemi='both',\n",
    "                views=value, # \"dorsal\", \"ventral\"\n",
    "                background='white',\n",
    "                title = title\n",
    "                )\n",
    "\n",
    "    # brain.save_image(os.path.join(figs_save_path, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97efb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labels from parcellation...\n",
      "   read 35 labels from D:\\BonoKat\\research project\\# study 1\\mri_data\\Y\\fs\\fsaverage_bem\\label\\lh.aparc.annot\n",
      "   read 34 labels from D:\\BonoKat\\research project\\# study 1\\mri_data\\Y\\fs\\fsaverage_bem\\label\\rh.aparc.annot\n"
     ]
    }
   ],
   "source": [
    "## Plotting with ROI labels, if needed\n",
    "\n",
    "# Select a few ROIs (names depend on your parcellation)\n",
    "labels = mne.read_labels_from_annot('fsaverage_bem', parc='aparc')\n",
    "roi_names = [\"postcentral-lh\", \"precentral-lh\", \"superiorfrontal-lh\"]\n",
    "rois = [lab for lab in labels if lab.name in roi_names]\n",
    "\n",
    "brain = stc_pac.plot(\n",
    "    subject=\"fsaverage_bem\",\n",
    "    hemi=\"both\",\n",
    "    views=[\"lateral\", \"medial\"],\n",
    "    cortex=\"bone\",\n",
    "    clim=clim,\n",
    "    colormap=\"plasma\",\n",
    "    initial_time=0.0,\n",
    ")\n",
    "\n",
    "# Add them in different colors\n",
    "colors = [\"yellow\", \"cyan\", \"magenta\"]\n",
    "for roi, color in zip(rois, colors):\n",
    "    brain.add_label(roi, borders=True, color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3bd31b",
   "metadata": {},
   "source": [
    "_____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
