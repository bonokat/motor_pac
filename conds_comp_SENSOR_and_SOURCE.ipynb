{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2e4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from utils import check_paths\n",
    "\n",
    "import mne\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import zscore\n",
    "from scipy.sparse import coo_matrix, save_npz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a01c684",
   "metadata": {},
   "source": [
    "**PLOTTING FUNCS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3b6d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rect_topo_from_epochs(data, epochs_info, cmap='YlGn', vmin=None, vmax=None, title=''):\n",
    "    \"\"\"\n",
    "    Plot a rectangular grid topomap from per-channel data using layout from epochs.info.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array, shape (n_channels,)\n",
    "        Scalar values per channel (e.g., PAC strength).\n",
    "    epochs_info : instance of mne.Info\n",
    "        Info object from Epochs to extract channel positions.\n",
    "    cmap : str or Colormap\n",
    "        Colormap to use for values.\n",
    "    vmin, vmax : float\n",
    "        Limits for color scaling.\n",
    "    title : str\n",
    "        Title for the plot.\n",
    "    \"\"\"\n",
    "    # Get rectangular layout from MNE\n",
    "    layout = mne.channels.make_eeg_layout(epochs_info)\n",
    "    ch_names = layout.names\n",
    "    pos_2d = layout.pos[:, :2]\n",
    "\n",
    "    # Normalize positions to grid indices\n",
    "    x_idx = np.round((pos_2d[:, 0] - np.min(pos_2d[:, 0])) / np.ptp(pos_2d[:, 0]) * 14).astype(int)\n",
    "    y_idx = np.round((pos_2d[:, 1] - np.min(pos_2d[:, 1])) / np.ptp(pos_2d[:, 1]) * 14).astype(int)\n",
    "    layout_grid = {ch: (y, x) for ch, x, y in zip(ch_names, x_idx, y_idx)}\n",
    "    # name, pos in zip(layout.names, layout.pos)\n",
    "\n",
    "    # Prepare grid size\n",
    "    nrows = y_idx.max() + 1\n",
    "    ncols = x_idx.max() + 1\n",
    "\n",
    "    # Start plotting\n",
    "    fig, ax = plt.subplots(figsize=(ncols, nrows))\n",
    "    ax.set_xlim(0, ncols)\n",
    "    ax.set_ylim(0, nrows)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    norm = plt.Normalize(vmin if vmin is not None else np.nanmin(data),\n",
    "                         vmax if vmax is not None else np.nanmax(data))\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        # if ch not in layout_grid:\n",
    "        #     continue\n",
    "        row, col = layout_grid[ch]\n",
    "        value = data[i].T\n",
    "        color = sm.to_rgba(value)\n",
    "        rect = patches.Rectangle((col, row), 1, 1, facecolor=color, edgecolor='black')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(col + 0.5, row + 0.5, ch, ha='center', va='center', fontsize=7)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.colorbar(sm, ax=ax, shrink=0.8, label='Value')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be3a7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_topo_from_epochs(data, epochs_info, cmap='YlGn', vmin=None, vmax=None, title=''):\n",
    "    \"\"\"\n",
    "    Plot a topographic layout of 2D matrices (e.g., PAC) per channel using epochs.info.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (n_channels, height, width)\n",
    "        A 2D matrix per channel (e.g., PAC frequency x frequency).\n",
    "    epochs_info : instance of mne.Info\n",
    "        Info object to extract channel layout.\n",
    "    cmap : str or Colormap\n",
    "        Colormap to use.\n",
    "    vmin, vmax : float or None\n",
    "        Color scale limits.\n",
    "    title : str\n",
    "        Title for the entire plot.\n",
    "    \"\"\"\n",
    "    n_channels, h, w = data.shape\n",
    "\n",
    "    # Get layout info\n",
    "    layout = mne.channels.make_eeg_layout(epochs_info)\n",
    "    ch_names = layout.names\n",
    "    pos_2d = layout.pos[:, :2]\n",
    "\n",
    "    # Normalize positions to grid indices\n",
    "    x_idx = np.round((pos_2d[:, 0] - np.min(pos_2d[:, 0])) / np.ptp(pos_2d[:, 0]) * 14).astype(int)\n",
    "    y_idx = np.round((pos_2d[:, 1] - np.min(pos_2d[:, 1])) / np.ptp(pos_2d[:, 1]) * 14).astype(int)\n",
    "    layout_grid = {ch: (y, x) for ch, x, y in zip(ch_names, x_idx, y_idx)}\n",
    "\n",
    "    # Grid dimensions\n",
    "    nrows = y_idx.max() + 1\n",
    "    ncols = x_idx.max() + 1\n",
    "\n",
    "    # Set up figure\n",
    "    fig, ax = plt.subplots(figsize=(ncols, nrows))\n",
    "    ax.set_xlim(0, ncols)\n",
    "    ax.set_ylim(0, nrows)\n",
    "    # ax.invert_yaxis()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Color normalization\n",
    "    norm = plt.Normalize(vmin if vmin is not None else np.nanmin(data),\n",
    "                         vmax if vmax is not None else np.nanmax(data))\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        if ch not in layout_grid:\n",
    "            continue\n",
    "        row, col = layout_grid[ch]\n",
    "        matrix = data[i].T\n",
    "\n",
    "        # Plot small matrix inside rectangle\n",
    "        extent = (col, col + 1, row, row + 1)\n",
    "        ax.imshow(matrix, cmap=cmap, norm=norm, extent=extent, origin='lower', aspect='auto')\n",
    "\n",
    "        # Draw frame and label\n",
    "        rect = patches.Rectangle((col, row), 1, 1, fill=False, edgecolor='black', linewidth=0.5)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(col + 0.5, row + 0.5, ch, ha='center', va='center', fontsize=6, color='black')\n",
    "\n",
    "    plt.colorbar(sm, ax=ax, shrink=0.7, label='Matrix Value')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d962ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_significant_topomap(T_obs, clusters, cluster_p_values, info, p_thresh=0.05, vlim=(-4, 4),\n",
    "                             group=None, task=None, task_stage=None, block_name=None):\n",
    "    \"\"\"\n",
    "    Plots a topomap highlighting electrodes in significant clusters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T_obs : array, shape (n_channels,)\n",
    "        Observed T-values.\n",
    "    clusters : list of boolean arrays\n",
    "        Cluster masks (n_channels,).\n",
    "    cluster_p_values : array\n",
    "        P-values for each cluster.\n",
    "    info : instance of mne.Info\n",
    "        EEG info with channel locations.\n",
    "    p_thresh : float\n",
    "        Significance threshold.\n",
    "    title : str\n",
    "        Title for the plot.\n",
    "    \"\"\"\n",
    "\n",
    "    task  = ['' if task==None else task][0]\n",
    "    task_stage = ['' if task_stage==None else task_stage][0]\n",
    "    block_name = ['' if block_name==None else block_name][0]\n",
    "\n",
    "    # Combine significant cluster masks\n",
    "    sig_mask = np.zeros_like(T_obs, dtype=bool)\n",
    "    for cluster, p_val in zip(clusters, cluster_p_values):\n",
    "        if p_val <= p_thresh:\n",
    "            sig_mask |= cluster\n",
    "\n",
    "    # Get color limits manually\n",
    "    if vlim is None:\n",
    "        vlim = np.nanmax(np.abs(T_obs))\n",
    "\n",
    "    title = f'{group}_{task}{task_stage}{block_name}: Significant Electrodes'\n",
    "    # Start plotting\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot topomap with significant electrodes highlighted\n",
    "    im, _ = mne.viz.plot_topomap(\n",
    "        T_obs,\n",
    "        info,\n",
    "        cmap='PiYG',\n",
    "        vlim=vlim,\n",
    "        show=False,\n",
    "        mask=sig_mask,\n",
    "        mask_params=dict(marker='h', markersize=15, \n",
    "                         markerfacecolor='y',\n",
    "                         markeredgecolor='k'),\n",
    "        contours=0,\n",
    "        axes=ax,\n",
    "        sensors=False # Hide insignificant sensors\n",
    "    )\n",
    "\n",
    "    plt.colorbar(im, ax=ax, shrink=0.6, label='T-value')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff53dd",
   "metadata": {},
   "source": [
    "**TWO CONDITIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13b50311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditions definition: name -> (task, stage, block)\n",
    "conditions = {\n",
    "    \"BL_go\": (\"_BL\", \"_go\", None),\n",
    "    \"BL_plan\": (\"_BL\", \"_plan\", None),\n",
    "\n",
    "    \"MAIN_go_baseline\": (\"_MAIN\", \"_go\", \"_baseline\"),\n",
    "    \"MAIN_plan_baseline\": (\"_MAIN\", \"_plan\", \"_baseline\"),\n",
    "\n",
    "    \"MAIN_go_adaptation\": (\"_MAIN\", \"_go\", \"_adaptation\"),\n",
    "    \"MAIN_plan_adaptation\": (\"_MAIN\", \"_plan\", \"_adaptation\"),\n",
    "\n",
    "    \"MAIN_go_combined\": (\"_MAIN\", \"_go\", None),     # both blocks\n",
    "    \"MAIN_plan_combined\": (\"_MAIN\", \"_plan\", None)  # both blocks\n",
    "}\n",
    "\n",
    "comparisons = [\n",
    "    (\"BL_go\", \"BL_plan\"),\n",
    "    (\"MAIN_go_baseline\", \"MAIN_plan_baseline\"),\n",
    "    (\"MAIN_go_adaptation\", \"MAIN_plan_adaptation\"),\n",
    "    (\"MAIN_go_combined\", \"MAIN_plan_combined\"),\n",
    "    (\"MAIN_go_combined\", \"BL_go\"),\n",
    "    (\"MAIN_plan_combined\", \"BL_plan\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5d43c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_condition_data(eeg_data_dir, subjects, condition_key, conditions):\n",
    "    \"\"\"Load PAC data for one condition, given subject-specific pac_dirs.\"\"\"\n",
    "    task, stage, block = conditions[condition_key]\n",
    "    pac_list = []\n",
    "    pac_zscore_list = []\n",
    "\n",
    "    for sub_name in subjects:\n",
    "        # print(f'Loading {sub_name} data for {task, stage, block}...')\n",
    "        sub_dir = os.path.join(eeg_data_dir, sub_name)\n",
    "        pac_dir = os.path.join(sub_dir, \"pac_results\")\n",
    "\n",
    "        if block is None and task == \"_MAIN\":\n",
    "            # Combine both blocks for MAIN\n",
    "            blocks = [\"_baseline\", \"_adaptation\"]\n",
    "            block_data = []\n",
    "            for b in blocks:\n",
    "                pac = np.load(os.path.join(pac_dir, f\"pac_mi_TOPO_{sub_name[-5:]}{task}{stage}{b}.npy\"))\n",
    "                pac_t = np.transpose(pac, (1, 0, 2))\n",
    "                block_data.append(pac_t)\n",
    "            blocks_arr = np.stack(block_data, axis=0)\n",
    "            blocks_arr_ch_ave = np.mean(blocks_arr, axis=0) # average across blocks for each channel to keep data shape consistent\n",
    "            # print(f'Blocks stacked shape: {blocks_arr_ch_ave.shape}')\n",
    "            pac_list.append(blocks_arr_ch_ave)\n",
    "            pac_zscore_list.append(zscore(blocks_arr_ch_ave))\n",
    "        else:\n",
    "            # Single block or BL task\n",
    "            bname = \"\" if block is None else block\n",
    "            pac = np.load(os.path.join(pac_dir, f\"pac_mi_TOPO_{sub_name[-5:]}{task}{stage}{bname}.npy\"))\n",
    "            pac_t = np.transpose(pac, (1, 0, 2))\n",
    "            pac_list.append(pac_t)\n",
    "            pac_zscore_list.append(zscore(pac_t))\n",
    "\n",
    "    # Stack them along a new first axis (subject axis)\n",
    "    pac_all = np.stack(pac_list, axis=0)\n",
    "\n",
    "    # Z-score the PAC data across subjects\n",
    "    pac_zscore_all = np.stack(pac_zscore_list, axis=0)\n",
    "    # print('PAC array shape:', pac_all.shape) # (24, 60, 20, 20) subs x electrodes x ph_freqs x amp_freqs\n",
    "    print('z-scored PAC array shape:', pac_zscore_all.shape)\n",
    "\n",
    "    return pac_zscore_all\n",
    "\n",
    "def load_two_conditions(eeg_data_dir, subjects, cond1, cond2, conditions):\n",
    "    \"\"\"Load data for two conditions for all participants.\"\"\"\n",
    "    # print(f'Loading {cond1} vs {cond2}...')\n",
    "    data1 = load_condition_data(eeg_data_dir, subjects, cond1, conditions)\n",
    "    data2 = load_condition_data(eeg_data_dir, subjects, cond2, conditions)\n",
    "    # print(data1.shape, data2.shape)\n",
    "    return data1, data2\n",
    "\n",
    "def iterate_comparisons(eeg_data_dir, subjects, conditions, comparisons):\n",
    "    \"\"\"Iterate through comparisons and yield loaded data.\"\"\"\n",
    "    for cond1, cond2 in comparisons:\n",
    "        data1, data2 = load_two_conditions(eeg_data_dir, subjects, cond1, cond2, conditions)\n",
    "        yield cond1, cond2, data1, data2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805351f",
   "metadata": {},
   "source": [
    "# SENSORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "075a77d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\O\\s1_pac_sub12\\preproc\\analysis\\s1_pac_sub12_BL_epochs_plan-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 10 columns\n",
      "102 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 60\n",
      "Adjacency matrix shape: (60, 60)\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "Running stats for BL_go vs BL_plan...\n",
      "z-scored diff PAC array shape: (24, 60, 20, 20)\n",
      "(24, 60)\n",
      "stat_fun(H1): min=-3.3557483125625653 max=3.038159054736123\n",
      "Running initial clustering …\n",
      "Found 3 clusters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86b6ea9382142e4a35a4cea270cd777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.8073356837675227\n",
      "T_obs_mean = -0.09311410184643125\n",
      "cluster_p_values = [0.2111 0.0037 0.1216]\n",
      "Found 1 significant clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1902989\\AppData\\Local\\Temp\\ipykernel_23472\\980455925.py:38: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "Running stats for MAIN_go_baseline vs MAIN_plan_baseline...\n",
      "z-scored diff PAC array shape: (24, 60, 20, 20)\n",
      "(24, 60)\n",
      "stat_fun(H1): min=-3.763331328120345 max=2.191138401812913\n",
      "Running initial clustering …\n",
      "Found 1 cluster\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e49a6fbfb584c4389ba1de7eeef2eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.8073356837675227\n",
      "T_obs_mean = -0.12808056339509985\n",
      "cluster_p_values = [0.0003]\n",
      "Found 1 significant clusters\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "Running stats for MAIN_go_adaptation vs MAIN_plan_adaptation...\n",
      "z-scored diff PAC array shape: (24, 60, 20, 20)\n",
      "(24, 60)\n",
      "stat_fun(H1): min=-3.909610482642881 max=2.9049820564453404\n",
      "Running initial clustering …\n",
      "Found 3 clusters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dadfed4593b4924847a98f8684b6c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.8073356837675227\n",
      "T_obs_mean = -0.34243597901827283\n",
      "cluster_p_values = [0.0007 0.0024 0.2267]\n",
      "Found 2 significant clusters\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "Running stats for MAIN_go_combined vs MAIN_plan_combined...\n",
      "z-scored diff PAC array shape: (24, 60, 20, 20)\n",
      "(24, 60)\n",
      "stat_fun(H1): min=-4.3429072117575425 max=3.103761879630875\n",
      "Running initial clustering …\n",
      "Found 2 clusters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee095c18cdde4813b252c6577b9033c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.8073356837675227\n",
      "T_obs_mean = -0.24811695135131515\n",
      "cluster_p_values = [2.139e-01 1.000e-04]\n",
      "Found 1 significant clusters\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "Running stats for MAIN_go_combined vs BL_go...\n",
      "z-scored diff PAC array shape: (24, 60, 20, 20)\n",
      "(24, 60)\n",
      "stat_fun(H1): min=-3.9138399866958875 max=2.815817050403034\n",
      "Running initial clustering …\n",
      "Found 3 clusters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96794a754b264b3783236ef0a5e15ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.8073356837675227\n",
      "T_obs_mean = -0.1402274597676461\n",
      "cluster_p_values = [0.3235 0.0052 0.2743]\n",
      "Found 1 significant clusters\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "z-scored PAC array shape: (24, 60, 20, 20)\n",
      "Running stats for MAIN_plan_combined vs BL_plan...\n",
      "z-scored diff PAC array shape: (24, 60, 20, 20)\n",
      "(24, 60)\n",
      "stat_fun(H1): min=-2.1100181369024886 max=3.60430421220729\n",
      "Running initial clustering …\n",
      "Found 1 cluster\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7487101c75c145a7b926ac2a7e61f28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | Permuting : 0/9999 [00:00<?,       ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.8073356837675227\n",
      "T_obs_mean = -0.04830961938546022\n",
      "cluster_p_values = [0.0059]\n",
      "Found 1 significant clusters\n"
     ]
    }
   ],
   "source": [
    "group = 'O'\n",
    "eeg_data_dir = f'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set\\\\{group}'\n",
    "group_data_dir = f'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set\\\\{group}'\n",
    "subjects = os.listdir(eeg_data_dir)\n",
    "\n",
    "# Create directories for saving stats\n",
    "group_save_path = f'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set\\\\{group} group'\n",
    "pac_stats_save_path = os.path.join(group_save_path, 'pac_stats', 'conditions')\n",
    "check_paths(pac_stats_save_path)\n",
    "\n",
    "# Create directories for saving figures\n",
    "fig_group_path = os.path.join(group_save_path, 'pac_stats', 'figs')\n",
    "fig_group_save_path = os.path.join(fig_group_path, group)\n",
    "fig_task_save_path = os.path.join(fig_group_path, 'conditions')\n",
    "check_paths(fig_task_save_path)\n",
    "\n",
    "############### CREATE ADJACENCY MATRIX FOR STATISTICAL TEST #############\n",
    "# find_ch_adjacency first attempts to find an existing \"neighbor\"\n",
    "# (adjacency) file for given sensor layout.\n",
    "# If such a file doesn't exist, an adjacency matrix is computed on the fly,\n",
    "# using Delaunay triangulations.\n",
    "\n",
    "# Load one epoch file to get info\n",
    "epochs_path = os.path.join(eeg_data_dir, subjects[0], 'preproc', 'analysis')\n",
    "epochs = mne.read_epochs(os.path.join(epochs_path, f\"{subjects[0]}_BL_epochs_plan-epo.fif\"), preload=True)\n",
    "eeg_channel_names = epochs.copy().pick(\"eeg\").ch_names\n",
    "epochs.pick(eeg_channel_names)\n",
    "\n",
    "# Create channel adjacency matrix\n",
    "sensor_adjacency, ch_names = mne.channels.find_ch_adjacency(epochs.info, \"eeg\")\n",
    "print(f'Adjacency matrix shape: {sensor_adjacency.shape}')\n",
    "\n",
    "############### RUN STATISTICAL COMPARISON #############\n",
    "for cond1, cond2, data1, data2 in iterate_comparisons(eeg_data_dir, subjects, conditions, comparisons):\n",
    "    print(f\"Running stats for {cond1} vs {cond2}...\")\n",
    "\n",
    "    pac_zscore_diff = data1 - data2\n",
    "    print('z-scored diff PAC array shape:', pac_zscore_diff.shape) # (24, 60, 20, 20) subs x electrodes x ph_freqs x amp_freqs\n",
    "\n",
    "    # Averafe z-scored PAC over phase and amplitude frequencies\n",
    "    pac_zscore_diff_ave = np.mean(pac_zscore_diff, axis=(2, 3)) # (24, 60) subs x electrodes\n",
    "    print(pac_zscore_diff_ave.shape)\n",
    "\n",
    "    # # Save the PAC data\n",
    "    np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}_{cond1}_vs_{cond2}_ZSCORE_freqs_ave.npy\"), pac_zscore_diff_ave)\n",
    "\n",
    "    ############# PLOT AND SAVE Z-SCORED PAC AVERAGED ACROSS PARTICIPANTS #############\n",
    "    pac_plot, ax1 = plot_rect_topo_from_epochs(np.mean(pac_zscore_diff_ave, axis=(0)), epochs.info,\n",
    "                                            title=f'{group}_{cond1}_vs_{cond2}: Averaged z-scored PAC MI',\n",
    "                                            cmap='PiYG', vmin=-0.5, vmax=0.5)\n",
    "    plt.savefig(os.path.join(fig_task_save_path, f\"pac_mi_{group}_{cond1}_vs_{cond2}_PAC_MI_AVE_TOPO.png\"), dpi=300)\n",
    "\n",
    "    pac_ave_plot, ax2 = plot_matrix_topo_from_epochs(np.mean(pac_zscore_diff, axis=(0)), epochs.info,\n",
    "                                                    title=f'{group}_{cond1}_vs_{cond2}: z-scored PAC MI',\n",
    "                                                    cmap='PiYG', vmin=-0.5, vmax=0.5)\n",
    "    plt.savefig(os.path.join(fig_task_save_path, f\"pac_mi_{group}_{cond1}_vs_{cond2}_PAC_MI_TOPO.png\"), dpi=300)\n",
    "\n",
    "\n",
    "    ############# RUN CLUSTER-BASED PERMUTATION TEST #############\n",
    "    tail = 0 # two-tailed test\n",
    "\n",
    "    # Set the threshold for including data bins in clusters with t-value corresponding to p=0.01\n",
    "    # Because we conduct a two-tailed test, we divide the p-value by 2 (which means we're making use of both tails of the distribution).\n",
    "    # As the degrees of freedom, we specify the number of observations (here: subjects) minus 1.\n",
    "    # Finally, we subtract 0.01 / 2 from 1, to get the critical t-value on the right tail\n",
    "    degrees_of_freedom = pac_zscore_diff.shape[0] - 1\n",
    "    t_thresh = scipy.stats.t.ppf(1 - 0.01 / 2, df=degrees_of_freedom)\n",
    "\n",
    "    #!\n",
    "    # threshold_tfce = dict(start=0, step=0.2) # Threshold-free cluster enhancement (TFCE) - more conservative, similar results\n",
    "\n",
    "    # Set the number of permutations\n",
    "    n_permutations = 10000\n",
    "\n",
    "    # Run the analysis\n",
    "    T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(\n",
    "        pac_zscore_diff_ave,\n",
    "        n_permutations=n_permutations,\n",
    "        threshold=t_thresh,\n",
    "        tail=tail,\n",
    "        adjacency=sensor_adjacency,\n",
    "        out_type=\"mask\",\n",
    "        max_step=1,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # # Save the results\n",
    "    np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}_{cond1}_vs_{cond2}_freqs_ave_T_obs.npy\"), T_obs)\n",
    "    np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}_{cond1}_vs_{cond2}_freqs_ave_clusters.npy\"), np.array(clusters, dtype=object))\n",
    "    np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}_{cond1}_vs_{cond2}_freqs_ave_cluster_p_values.npy\"), cluster_p_values)\n",
    "    np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}_{cond1}_vs_{cond2}_freqs_ave_H0.npy\"), H0)\n",
    "\n",
    "    # SANITY CHECKS\n",
    "    print(f't_thresh = {t_thresh}')\n",
    "    print(f'T_obs_mean = {T_obs.mean()}')\n",
    "    print(f'cluster_p_values = {cluster_p_values}')\n",
    "\n",
    "    alpha = 0.05  # significance threshold\n",
    "    significant_clusters = [i for i, p in enumerate(cluster_p_values) if p < alpha]\n",
    "    print(f\"Found {len(significant_clusters)} significant clusters\")\n",
    "\n",
    "\n",
    "    ####### PLOT THE RESULTS #######\n",
    "    plot_significant_topomap(T_obs, clusters, cluster_p_values, epochs.info, group=group, task=f'{cond1}_vs_{cond2}')\n",
    "    plt.savefig(os.path.join(fig_task_save_path, f\"pac_cluster_stats_{group}_{cond1}_vs_{cond2}_freq_ave_TOPO.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d338068",
   "metadata": {},
   "source": [
    "_________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520abf38",
   "metadata": {},
   "source": [
    "# SOURCES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
