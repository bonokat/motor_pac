{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from utils import check_paths\n",
    "\n",
    "import mne\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import zscore\n",
    "from scipy.sparse import coo_matrix, save_npz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretaion of z-scored PAC stats:**\n",
    "Negative z-scores don’t mean “negative PAC,” just “PAC lower than the group mean.”\n",
    "\n",
    "**Significant cluster interpretaition:**\n",
    "It is invalid to interpret the cluster p value as being spatially or temporally specific. A cluster with sufficiently low (for example < 0.05) p value at specific location does not allow you to say that the significant effect is at that particular location. The p value only tells you about the probability of obtaining similar or stronger/larger cluster anywhere in the data if there were no differences between the compared conditions. So it only allows you to draw conclusions about the differences in the data “in general”, not at specific locations.\n",
    "\n",
    "**How NOT to interpret results from a cluster-based permutation test:**\n",
    "https://www.fieldtriptoolbox.org/faq/stats/clusterstats_interpretation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rect_topo_from_epochs(data, epochs_info, cmap='YlGn', vmin=None, vmax=None, title=''):\n",
    "    \"\"\"\n",
    "    Plot a rectangular grid topomap from per-channel data using layout from epochs.info.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array, shape (n_channels,)\n",
    "        Scalar values per channel (e.g., PAC strength).\n",
    "    epochs_info : instance of mne.Info\n",
    "        Info object from Epochs to extract channel positions.\n",
    "    cmap : str or Colormap\n",
    "        Colormap to use for values.\n",
    "    vmin, vmax : float\n",
    "        Limits for color scaling.\n",
    "    title : str\n",
    "        Title for the plot.\n",
    "    \"\"\"\n",
    "    # Get rectangular layout from MNE\n",
    "    layout = mne.channels.make_eeg_layout(epochs_info)\n",
    "    ch_names = layout.names\n",
    "    pos_2d = layout.pos[:, :2]\n",
    "\n",
    "    # Normalize positions to grid indices\n",
    "    x_idx = np.round((pos_2d[:, 0] - np.min(pos_2d[:, 0])) / np.ptp(pos_2d[:, 0]) * 14).astype(int)\n",
    "    y_idx = np.round((pos_2d[:, 1] - np.min(pos_2d[:, 1])) / np.ptp(pos_2d[:, 1]) * 14).astype(int)\n",
    "    layout_grid = {ch: (y, x) for ch, x, y in zip(ch_names, x_idx, y_idx)}\n",
    "    # name, pos in zip(layout.names, layout.pos)\n",
    "\n",
    "    # Prepare grid size\n",
    "    nrows = y_idx.max() + 1\n",
    "    ncols = x_idx.max() + 1\n",
    "\n",
    "    # Start plotting\n",
    "    fig, ax = plt.subplots(figsize=(ncols, nrows))\n",
    "    ax.set_xlim(0, ncols)\n",
    "    ax.set_ylim(0, nrows)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    norm = plt.Normalize(vmin if vmin is not None else np.nanmin(data),\n",
    "                         vmax if vmax is not None else np.nanmax(data))\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        # if ch not in layout_grid:\n",
    "        #     continue\n",
    "        row, col = layout_grid[ch]\n",
    "        value = data[i].T\n",
    "        color = sm.to_rgba(value)\n",
    "        rect = patches.Rectangle((col, row), 1, 1, facecolor=color, edgecolor='black')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(col + 0.5, row + 0.5, ch, ha='center', va='center', fontsize=7)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.colorbar(sm, ax=ax, shrink=0.8, label='Value')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_topo_from_epochs(data, epochs_info, cmap='YlGn', vmin=None, vmax=None, title=''):\n",
    "    \"\"\"\n",
    "    Plot a topographic layout of 2D matrices (e.g., PAC) per channel using epochs.info.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (n_channels, height, width)\n",
    "        A 2D matrix per channel (e.g., PAC frequency x frequency).\n",
    "    epochs_info : instance of mne.Info\n",
    "        Info object to extract channel layout.\n",
    "    cmap : str or Colormap\n",
    "        Colormap to use.\n",
    "    vmin, vmax : float or None\n",
    "        Color scale limits.\n",
    "    title : str\n",
    "        Title for the entire plot.\n",
    "    \"\"\"\n",
    "    n_channels, h, w = data.shape\n",
    "\n",
    "    # Get layout info\n",
    "    layout = mne.channels.make_eeg_layout(epochs_info)\n",
    "    ch_names = layout.names\n",
    "    pos_2d = layout.pos[:, :2]\n",
    "\n",
    "    # Normalize positions to grid indices\n",
    "    x_idx = np.round((pos_2d[:, 0] - np.min(pos_2d[:, 0])) / np.ptp(pos_2d[:, 0]) * 14).astype(int)\n",
    "    y_idx = np.round((pos_2d[:, 1] - np.min(pos_2d[:, 1])) / np.ptp(pos_2d[:, 1]) * 14).astype(int)\n",
    "    layout_grid = {ch: (y, x) for ch, x, y in zip(ch_names, x_idx, y_idx)}\n",
    "\n",
    "    # Grid dimensions\n",
    "    nrows = y_idx.max() + 1\n",
    "    ncols = x_idx.max() + 1\n",
    "\n",
    "    # Set up figure\n",
    "    fig, ax = plt.subplots(figsize=(ncols, nrows))\n",
    "    ax.set_xlim(0, ncols)\n",
    "    ax.set_ylim(0, nrows)\n",
    "    # ax.invert_yaxis()\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Color normalization\n",
    "    norm = plt.Normalize(vmin if vmin is not None else np.nanmin(data),\n",
    "                         vmax if vmax is not None else np.nanmax(data))\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        if ch not in layout_grid:\n",
    "            continue\n",
    "        row, col = layout_grid[ch]\n",
    "        matrix = data[i].T\n",
    "\n",
    "        # Plot small matrix inside rectangle\n",
    "        extent = (col, col + 1, row, row + 1)\n",
    "        ax.imshow(matrix, cmap=cmap, norm=norm, extent=extent, origin='lower', aspect='auto')\n",
    "\n",
    "        # Draw frame and label\n",
    "        rect = patches.Rectangle((col, row), 1, 1, fill=False, edgecolor='black', linewidth=0.5)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(col + 0.5, row + 0.5, ch, ha='center', va='center', fontsize=6, color='black')\n",
    "\n",
    "    plt.colorbar(sm, ax=ax, shrink=0.7, label='Matrix Value')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_significant_topomap(T_obs, clusters, cluster_p_values, info, p_thresh=0.05, vlim=(-4, 4),\n",
    "                             group=None, task=None, task_stage=None, block_name=None):\n",
    "    \"\"\"\n",
    "    Plots a topomap highlighting electrodes in significant clusters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T_obs : array, shape (n_channels,)\n",
    "        Observed T-values.\n",
    "    clusters : list of boolean arrays\n",
    "        Cluster masks (n_channels,).\n",
    "    cluster_p_values : array\n",
    "        P-values for each cluster.\n",
    "    info : instance of mne.Info\n",
    "        EEG info with channel locations.\n",
    "    p_thresh : float\n",
    "        Significance threshold.\n",
    "    title : str\n",
    "        Title for the plot.\n",
    "    \"\"\"\n",
    "    # Combine significant cluster masks\n",
    "    sig_mask = np.zeros_like(T_obs, dtype=bool)\n",
    "    for cluster, p_val in zip(clusters, cluster_p_values):\n",
    "        if p_val <= p_thresh:\n",
    "            sig_mask |= cluster\n",
    "\n",
    "    # Get color limits manually\n",
    "    if vlim is None:\n",
    "        vlim = np.nanmax(np.abs(T_obs))\n",
    "\n",
    "    title = f'{group}{task}{task_stage}{block_name}: Significant Electrodes'\n",
    "    # Start plotting\n",
    "    fig, ax = plt.subplots()\n",
    "    im, _ = mne.viz.plot_topomap(\n",
    "        T_obs,\n",
    "        info,\n",
    "        cmap='PiYG',\n",
    "        vlim=vlim,\n",
    "        show=False,\n",
    "        mask=sig_mask,\n",
    "        mask_params=dict(marker='x', markersize=10, markerfacecolor='k'),\n",
    "        contours=0,\n",
    "        axes=ax\n",
    "    )\n",
    "    plt.colorbar(im, ax=ax, shrink=0.6, label='T-value')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_dir = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set'\n",
    "\n",
    "groups = ['Y', 'O']\n",
    "task = '_BL' # ['_BL', '_MAIN']\n",
    "task_stages = ['_plan', '_go']\n",
    "\n",
    "theta_range = np.around(np.linspace(4, 8, 20), 1)  # Phase: 4-8 Hz\n",
    "gamma_range = np.around(np.linspace(30, 80, 20), 1)  # Amplitude: 30-80 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    group_save_path = os.path.join(eeg_data_dir, f'{group} group')\n",
    "    pac_stats_save_path = os.path.join(group_save_path, 'pac_stats')\n",
    "    check_paths(pac_stats_save_path)\n",
    "\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "\n",
    "    for task_stage in task_stages:\n",
    "\n",
    "        print(f'Processing {group} group, {task} task, {task_stage} stage...')\n",
    "\n",
    "        ############# STACK PAC DATA OF INDIVIDUAL PARTICIPANTS #############\n",
    "\n",
    "        # Create a list to store the PAC data for each subject\n",
    "        pac_list = []\n",
    "        pac_zscore_list = []\n",
    "\n",
    "        for sub_name in subs:\n",
    "\n",
    "            sub_dir = os.path.join(eeg_data_dir, group, sub_name)\n",
    "            pac_dir = os.path.join(sub_dir, 'pac_results')\n",
    "            \n",
    "            # Get info about chnnals from one participant for adjacency matrix\n",
    "            if sub_name == subs[0]: # read one epochs file to extract info\n",
    "                # Load EEG data\n",
    "                epochs_path = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "                epochs = mne.read_epochs(os.path.join(epochs_path, f\"{sub_name}{task}_epochs{task_stage}-epo.fif\"), preload=True)\n",
    "                eeg_channel_names = epochs.copy().pick(\"eeg\").ch_names\n",
    "                epochs.pick(eeg_channel_names)\n",
    "                # info = epochs.info\n",
    "                # epochs.pick(choi)\n",
    "\n",
    "            # Load PAC data\n",
    "            pac = np.load(os.path.join(pac_dir, f\"pac_mi_TOPO_{sub_name[-5:]}{task}{task_stage}.npy\"))\n",
    "            pac_t = np.transpose(pac, (1, 0, 2))\n",
    "            pac_list.append(pac_t)\n",
    "            pac_zscore_list.append(zscore(pac_t))\n",
    "        \n",
    "        # Stack them along a new first axis (subject axis)\n",
    "        pac_all = np.stack(pac_list, axis=0)\n",
    "\n",
    "        # Z-score the PAC data across subjects\n",
    "        pac_zscore_all = np.stack(pac_zscore_list, axis=0)\n",
    "        print(pac_all.shape) # (24, 60, 20, 20) subs x electrodes x ph_freqs x amp_freqs\n",
    "        print(pac_zscore_all.shape)\n",
    "\n",
    "        # Average z-scored PAC over subjects\n",
    "        pac_zscore_mean = pac_zscore_all.mean(axis=0)  # shape: (60, 20, 20)\n",
    "\n",
    "        # Save the PAC data\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_RAW.npy\"), pac_all)\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_ZSCORE.npy\"), pac_zscore_all)\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_ZSCORE_MEAN.npy\"), pac_zscore_mean)\n",
    "\n",
    "        ############### CREATE ADJACENCY MATRIX FOR STATISTICAL TEST #############\n",
    "        # find_ch_adjacency first attempts to find an existing \"neighbor\"\n",
    "        # (adjacency) file for given sensor layout.\n",
    "        # If such a file doesn't exist, an adjacency matrix is computed on the fly,\n",
    "        # using Delaunay triangulations.\n",
    "        sensor_adjacency, ch_names = mne.channels.find_ch_adjacency(epochs.info, \"eeg\")\n",
    "        adjacency = mne.stats.combine_adjacency(\n",
    "                                                sensor_adjacency,\n",
    "                                                pac_zscore_all.shape[2],\n",
    "                                                pac_zscore_all.shape[3]\n",
    "                                                )\n",
    "        print(adjacency.shape)\n",
    "\n",
    "        # Save adjacency matrix\n",
    "        adjacency_matrix = coo_matrix(adjacency)\n",
    "        save_npz(f\"{group}{task}{task_stage}_adjacency_matrix.npz\", adjacency_matrix)\n",
    "\n",
    "        ############# RUN CLUSTER-BASED PERMUTATION TEST #############\n",
    "\n",
    "        tail = 0 # two-tailed test\n",
    "\n",
    "        # Set the threshold for including data bins in clusters with t-value corresponding to p=0.01\n",
    "        # Because we conduct a two-tailed test, we divide the p-value by 2 (which means we're making use of both tails of the distribution).\n",
    "        # As the degrees of freedom, we specify the number of observations (here: subjects) minus 1.\n",
    "        # Finally, we subtract 0.01 / 2 from 1, to get the critical t-value on the right tail\n",
    "        degrees_of_freedom = pac_all.shape[0] - 1\n",
    "        t_thresh = scipy.stats.t.ppf(1 - 0.01 / 2, df=degrees_of_freedom)\n",
    "\n",
    "        # Set the number of permutations\n",
    "        n_permutations = 10000\n",
    "\n",
    "        # Run the analysis\n",
    "        T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(\n",
    "            pac_zscore_all,\n",
    "            n_permutations=n_permutations,\n",
    "            threshold=t_thresh,\n",
    "            tail=tail,\n",
    "            adjacency=adjacency,\n",
    "            out_type=\"mask\",\n",
    "            max_step=1,\n",
    "            n_jobs=-1,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # Save the results\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_T_obs.npy\"), T_obs)\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_clusters.npy\"), np.array(clusters, dtype=object))\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_cluster_p_values.npy\"), cluster_p_values)\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_H0.npy\"), H0)\n",
    "\n",
    "        # SANITY CHECKS\n",
    "        print(f't_thresh = {t_thresh}')\n",
    "        print(f'T_obs_mean = {T_obs.mean()}')\n",
    "        print(f'cluster_p_values = {cluster_p_values}')\n",
    "\n",
    "        alpha = 0.05  # significance threshold\n",
    "        significant_clusters = [i for i, p in enumerate(cluster_p_values) if p < alpha]\n",
    "        print(f\"Found {len(significant_clusters)} significant clusters\")\n",
    "\n",
    "\n",
    "        ####### PLOT THE RESULTS #######\n",
    "        # Create directories for saving figures\n",
    "        fig_group_path = os.path.join(pac_stats_save_path, 'figs')\n",
    "        fig_group_save_path = os.path.join(fig_group_path, group)\n",
    "        fig_task_save_path = os.path.join(fig_group_path, group, task)\n",
    "        check_paths(fig_group_path, fig_group_save_path, fig_task_save_path)\n",
    "\n",
    "        # Reshape the stats results\n",
    "        sig_mask = np.zeros_like(T_obs, dtype=bool)\n",
    "\n",
    "        for i in significant_clusters:\n",
    "            sig_mask[clusters[i].reshape(pac_zscore_all.shape[1:])] = True\n",
    "\n",
    "\n",
    "        for elec_idx in range(pac_zscore_mean.shape[0]):\n",
    "            # Create masked array: T-values where significant, NaN elsewhere\n",
    "            masked_T = np.where(sig_mask[elec_idx], T_obs[elec_idx], np.nan)\n",
    "\n",
    "            # # Build a colormap with gray for NaNs\n",
    "            cmap = plt.cm.PiYG.copy()  # try 'RdYlBu' or 'PRGn' (purple-green)\n",
    "            cmap.set_bad(color='lightgray')  # this sets the NaNs to gray\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            im = plt.imshow(\n",
    "                masked_T.T,\n",
    "                origin='lower',\n",
    "                aspect='equal',\n",
    "                cmap=cmap,\n",
    "                interpolation='none',\n",
    "                vmin=-10,\n",
    "                vmax=10\n",
    "            )\n",
    "            plt.colorbar(im, label='T-value')\n",
    "            plt.title(f'{group}{task}{task_stage}: PAC Cluster stats - {eeg_channel_names[elec_idx]}')\n",
    "            plt.xticks(np.arange(len(theta_range)), theta_range, rotation='vertical')\n",
    "            plt.yticks(np.arange(len(gamma_range)), gamma_range)\n",
    "            plt.xlabel('Phase Freq Index')\n",
    "            plt.ylabel('Amp Freq Index')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            plt.savefig(os.path.join(fig_task_save_path, f\"pac_cluster_stats_{group}{task}{task_stage}_{eeg_channel_names[elec_idx]}.png\"), dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STATS FOR DATA AVERAGED ACROSS PHASE AND AMPLITUDE FREQUENCIES**\n",
    "\n",
    "One condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script to process PAC data and run cluster-based permutation tests\n",
    "for group in groups:\n",
    "    group_save_path = os.path.join(eeg_data_dir, f'{group} group')\n",
    "    pac_stats_save_path = os.path.join(group_save_path, 'pac_stats')\n",
    "    check_paths(pac_stats_save_path)\n",
    "    \n",
    "    # Create directories for saving figures\n",
    "    fig_group_path = os.path.join(pac_stats_save_path, 'figs')\n",
    "    fig_group_save_path = os.path.join(fig_group_path, group)\n",
    "    fig_task_save_path = os.path.join(fig_group_path, group, task)\n",
    "\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "\n",
    "    for task_stage in task_stages:\n",
    "\n",
    "        print(f'Processing {group} group, {task} task, {task_stage} stage,  block...')\n",
    "\n",
    "        ############# STACK PAC DATA OF INDIVIDUAL PARTICIPANTS #############\n",
    "\n",
    "        # Create a list to store the PAC data for each subject\n",
    "        pac_list = []\n",
    "        pac_zscore_list = []\n",
    "\n",
    "        for sub_name in subs:\n",
    "\n",
    "            sub_dir = os.path.join(eeg_data_dir, group, sub_name)\n",
    "            pac_dir = os.path.join(sub_dir, 'pac_results')\n",
    "            \n",
    "            # Get info about chnnals from one participant for adjacency matrix\n",
    "            if sub_name == subs[0]: # read one epochs file to extract info\n",
    "                # Load EEG data\n",
    "                epochs_path = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "                epochs = mne.read_epochs(os.path.join(epochs_path, f\"{sub_name}{task}_epochs{task_stage}-epo.fif\"), preload=True)\n",
    "                eeg_channel_names = epochs.copy().pick(\"eeg\").ch_names\n",
    "                epochs.pick(eeg_channel_names)\n",
    "\n",
    "            # Load PAC data\n",
    "            pac = np.load(os.path.join(pac_dir, f\"pac_mi_TOPO_{sub_name[-5:]}{task}{task_stage}.npy\"))\n",
    "            pac_t = np.transpose(pac, (1, 0, 2))\n",
    "            pac_list.append(pac_t)\n",
    "            pac_zscore_list.append(zscore(pac_t))\n",
    "\n",
    "        # Stack them along a new first axis (subject axis)\n",
    "        pac_all = np.stack(pac_list, axis=0)\n",
    "\n",
    "        # Z-score the PAC data across subjects\n",
    "        pac_zscore_all = np.stack(pac_zscore_list, axis=0)\n",
    "        print('PAC array shape:', pac_all.shape) # (24, 60, 20, 20) subs x electrodes x ph_freqs x amp_freqs\n",
    "        print('z-scored PAC array shape:', pac_zscore_all.shape)\n",
    "\n",
    "        # Averafe z-scored PAC over phase and amplitude frequencies\n",
    "        pac_zscore_all_ave = np.mean(pac_zscore_all, axis=(2, 3)) # (24, 60) subs x electrodes\n",
    "        # pac_zscore_all_med = np.median(pac_zscore_all, axis=(2, 3)) # produces more significant clusters\n",
    "\n",
    "        # # Save the PAC data\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_ZSCORE_freqs_ave.npy\"), pac_zscore_all_ave)\n",
    "\n",
    "        # ############# PLOT AND SAVE Z-SCORED PAC AVERAGED ACROSS PARTICIPANTS #############\n",
    "        pac_plot, ax1 = plot_rect_topo_from_epochs(np.mean(pac_zscore_all_ave, axis=(0)), epochs.info,\n",
    "                                                title=f'{group}{task}{task_stage}: Averaged z-scored PAC MI',\n",
    "                                                cmap='PiYG', vmin=-0.5, vmax=0.5)\n",
    "        plt.savefig(os.path.join(fig_task_save_path, f\"pac_mi_{group}{task}{task_stage}_PAC_MI_AVE_TOPO.png\"), dpi=300)\n",
    "\n",
    "        pac_ave_plot, ax2 = plot_matrix_topo_from_epochs(np.mean(pac_zscore_all, axis=(0)), epochs.info,\n",
    "                                                        title=f'{group}{task}{task_stage}: z-scored PAC MI',\n",
    "                                                        cmap='PiYG', vmin=-0.5, vmax=0.5)\n",
    "        plt.savefig(os.path.join(fig_task_save_path, f\"pac_mi_{group}{task}{task_stage}_PAC_MI_TOPO.png\"), dpi=300)\n",
    "\n",
    "        ############### CREATE ADJACENCY MATRIX FOR STATISTICAL TEST #############\n",
    "        # find_ch_adjacency first attempts to find an existing \"neighbor\"\n",
    "        # (adjacency) file for given sensor layout.\n",
    "        # If such a file doesn't exist, an adjacency matrix is computed on the fly,\n",
    "        # using Delaunay triangulations.\n",
    "        sensor_adjacency, ch_names = mne.channels.find_ch_adjacency(epochs.info, \"eeg\")\n",
    "        print('adjacency shape:', sensor_adjacency.shape)\n",
    "\n",
    "\n",
    "        ############# RUN CLUSTER-BASED PERMUTATION TEST #############\n",
    "\n",
    "        tail = 0 # two-tailed test\n",
    "\n",
    "        # Set the threshold for including data bins in clusters with t-value corresponding to p=0.01\n",
    "        # Because we conduct a two-tailed test, we divide the p-value by 2 (which means we're making use of both tails of the distribution).\n",
    "        # As the degrees of freedom, we specify the number of observations (here: subjects) minus 1.\n",
    "        # Finally, we subtract 0.01 / 2 from 1, to get the critical t-value on the right tail\n",
    "        degrees_of_freedom = pac_all.shape[0] - 1\n",
    "        t_thresh = scipy.stats.t.ppf(1 - 0.01 / 2, df=degrees_of_freedom)\n",
    "\n",
    "        #!\n",
    "        # threshold_tfce = dict(start=0, step=0.2) # Threshold-free cluster enhancement (TFCE) - more conservative, similar results\n",
    "\n",
    "        # Set the number of permutations\n",
    "        n_permutations = 10000\n",
    "\n",
    "        # Run the analysis\n",
    "        T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(\n",
    "            pac_zscore_all_ave,\n",
    "            n_permutations=n_permutations,\n",
    "            threshold=t_thresh,\n",
    "            tail=tail,\n",
    "            adjacency=sensor_adjacency,\n",
    "            out_type=\"mask\",\n",
    "            max_step=1,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # # Save the results\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_T_obs.npy\"), T_obs)\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_clusters.npy\"), np.array(clusters, dtype=object))\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_cluster_p_values.npy\"), cluster_p_values)\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_H0.npy\"), H0)\n",
    "\n",
    "        # SANITY CHECKS\n",
    "        print(f't_thresh = {t_thresh}')\n",
    "        print(f'T_obs_mean = {T_obs.mean()}')\n",
    "        print(f'cluster_p_values = {cluster_p_values}')\n",
    "\n",
    "        alpha = 0.05  # significance threshold\n",
    "        significant_clusters = [i for i, p in enumerate(cluster_p_values) if p < alpha]\n",
    "        print(f\"Found {len(significant_clusters)} significant clusters\")\n",
    "\n",
    "\n",
    "        ####### PLOT THE RESULTS #######\n",
    "        plot_significant_topomap(T_obs, clusters, cluster_p_values, epochs.info,\n",
    "                                 group=group, task=task, task_stage=task_stage, block_name='')\n",
    "        plt.savefig(os.path.join(fig_task_save_path, f\"pac_cluster_stats_{group}{task}{task_stage}_freq_ave_TOPO.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STOPPED HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD COMPARISON ACROSS CONDITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script to process PAC data and run cluster-based permutation tests\n",
    "for group in groups:\n",
    "    group_save_path = os.path.join(eeg_data_dir, f'{group} group')\n",
    "    pac_stats_save_path = os.path.join(group_save_path, 'pac_stats')\n",
    "    check_paths(pac_stats_save_path)\n",
    "    \n",
    "    # Create directories for saving figures\n",
    "    fig_group_path = os.path.join(pac_stats_save_path, 'figs')\n",
    "    fig_group_save_path = os.path.join(fig_group_path, group)\n",
    "    fig_task_save_path = os.path.join(fig_group_path, group, task)\n",
    "\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "\n",
    "    for task_stage in task_stages:\n",
    "\n",
    "        print(f'Processing {group} group, {task} task, {task_stage} stage,  block...')\n",
    "\n",
    "        ############# STACK PAC DATA OF INDIVIDUAL PARTICIPANTS #############\n",
    "\n",
    "        # Create a list to store the PAC data for each subject\n",
    "        pac_list = []\n",
    "        pac_zscore_list = []\n",
    "\n",
    "        for sub_name in subs:\n",
    "\n",
    "            sub_dir = os.path.join(eeg_data_dir, group, sub_name)\n",
    "            pac_dir = os.path.join(sub_dir, 'pac_results')\n",
    "            \n",
    "            # Get info about chnnals from one participant for adjacency matrix\n",
    "            if sub_name == subs[0]: # read one epochs file to extract info\n",
    "                # Load EEG data\n",
    "                epochs_path = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis')\n",
    "                epochs = mne.read_epochs(os.path.join(epochs_path, f\"{sub_name}{task}_epochs{task_stage}-epo.fif\"), preload=True)\n",
    "                eeg_channel_names = epochs.copy().pick(\"eeg\").ch_names\n",
    "                epochs.pick(eeg_channel_names)\n",
    "\n",
    "            # Load PAC data\n",
    "            pac = np.load(os.path.join(pac_dir, f\"pac_mi_TOPO_{sub_name[-5:]}{task}{task_stage}.npy\"))\n",
    "            pac_t = np.transpose(pac, (1, 0, 2))\n",
    "            pac_list.append(pac_t)\n",
    "            pac_zscore_list.append(zscore(pac_t))\n",
    "\n",
    "        # Stack them along a new first axis (subject axis)\n",
    "        pac_all = np.stack(pac_list, axis=0)\n",
    "\n",
    "        # Z-score the PAC data across subjects\n",
    "        pac_zscore_all = np.stack(pac_zscore_list, axis=0)\n",
    "        print('PAC array shape:', pac_all.shape) # (24, 60, 20, 20) subs x electrodes x ph_freqs x amp_freqs\n",
    "        print('z-scored PAC array shape:', pac_zscore_all.shape)\n",
    "\n",
    "        # Averafe z-scored PAC over phase and amplitude frequencies\n",
    "        pac_zscore_all_ave = np.mean(pac_zscore_all, axis=(2, 3)) # (24, 60) subs x electrodes\n",
    "        # pac_zscore_all_med = np.median(pac_zscore_all, axis=(2, 3)) # produces more significant clusters\n",
    "\n",
    "        # # Save the PAC data\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_ZSCORE_freqs_ave.npy\"), pac_zscore_all_ave)\n",
    "\n",
    "        # ############# PLOT AND SAVE Z-SCORED PAC AVERAGED ACROSS PARTICIPANTS #############\n",
    "        pac_plot, ax1 = plot_rect_topo_from_epochs(np.mean(pac_zscore_all_ave, axis=(0)), epochs.info,\n",
    "                                                title=f'{group}{task}{task_stage}: Averaged z-scored PAC MI',\n",
    "                                                cmap='PiYG', vmin=-0.5, vmax=0.5)\n",
    "        plt.savefig(os.path.join(fig_task_save_path, f\"pac_mi_{group}{task}{task_stage}_PAC_MI_AVE_TOPO.png\"), dpi=300)\n",
    "\n",
    "        pac_ave_plot, ax2 = plot_matrix_topo_from_epochs(np.mean(pac_zscore_all, axis=(0)), epochs.info,\n",
    "                                                        title=f'{group}{task}{task_stage}: z-scored PAC MI',\n",
    "                                                        cmap='PiYG', vmin=-0.5, vmax=0.5)\n",
    "        plt.savefig(os.path.join(fig_task_save_path, f\"pac_mi_{group}{task}{task_stage}_PAC_MI_TOPO.png\"), dpi=300)\n",
    "\n",
    "        ############### CREATE ADJACENCY MATRIX FOR STATISTICAL TEST #############\n",
    "        # find_ch_adjacency first attempts to find an existing \"neighbor\"\n",
    "        # (adjacency) file for given sensor layout.\n",
    "        # If such a file doesn't exist, an adjacency matrix is computed on the fly,\n",
    "        # using Delaunay triangulations.\n",
    "        sensor_adjacency, ch_names = mne.channels.find_ch_adjacency(epochs.info, \"eeg\")\n",
    "        print('adjacency shape:', sensor_adjacency.shape)\n",
    "\n",
    "\n",
    "        ############# RUN CLUSTER-BASED PERMUTATION TEST #############\n",
    "\n",
    "        tail = 0 # two-tailed test\n",
    "\n",
    "        # Set the threshold for including data bins in clusters with t-value corresponding to p=0.01\n",
    "        # Because we conduct a two-tailed test, we divide the p-value by 2 (which means we're making use of both tails of the distribution).\n",
    "        # As the degrees of freedom, we specify the number of observations (here: subjects) minus 1.\n",
    "        # Finally, we subtract 0.01 / 2 from 1, to get the critical t-value on the right tail\n",
    "        degrees_of_freedom = pac_all.shape[0] - 1\n",
    "        t_thresh = scipy.stats.t.ppf(1 - 0.01 / 2, df=degrees_of_freedom)\n",
    "\n",
    "        #!\n",
    "        # threshold_tfce = dict(start=0, step=0.2) # Threshold-free cluster enhancement (TFCE) - more conservative, similar results\n",
    "\n",
    "        # Set the number of permutations\n",
    "        n_permutations = 10000\n",
    "\n",
    "        # Run the analysis\n",
    "        T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(\n",
    "            pac_zscore_all_ave,\n",
    "            n_permutations=n_permutations,\n",
    "            threshold=t_thresh,\n",
    "            tail=tail,\n",
    "            adjacency=sensor_adjacency,\n",
    "            out_type=\"mask\",\n",
    "            max_step=1,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # # Save the results\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_T_obs.npy\"), T_obs)\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_clusters.npy\"), np.array(clusters, dtype=object))\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_cluster_p_values.npy\"), cluster_p_values)\n",
    "        np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}_freqs_ave_H0.npy\"), H0)\n",
    "\n",
    "        # SANITY CHECKS\n",
    "        print(f't_thresh = {t_thresh}')\n",
    "        print(f'T_obs_mean = {T_obs.mean()}')\n",
    "        print(f'cluster_p_values = {cluster_p_values}')\n",
    "\n",
    "        alpha = 0.05  # significance threshold\n",
    "        significant_clusters = [i for i, p in enumerate(cluster_p_values) if p < alpha]\n",
    "        print(f\"Found {len(significant_clusters)} significant clusters\")\n",
    "\n",
    "\n",
    "        ####### PLOT THE RESULTS #######\n",
    "        plot_significant_topomap(T_obs, clusters, cluster_p_values, epochs.info,\n",
    "                                 group=group, task=task, task_stage=task_stage, block_name='')\n",
    "        plt.savefig(os.path.join(fig_task_save_path, f\"pac_cluster_stats_{group}{task}{task_stage}_freq_ave_TOPO.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
