{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7d4547a",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "\n",
    "To get the idea of the distribution (for the model):\n",
    "- Very technical approach: Run random effects model > generate residuals > check distribution of the residuals > choose the model accordingly\n",
    "- Empirical approach: run the model based on either gaussian distribution (identity link function) or gamma distribution (log link function) and compare which of them fits better\n",
    "\n",
    "Steps for running stats using GLMM:\n",
    "- Get the fixed effects table\n",
    "- Get estimated means of conditions and difference between the means\n",
    "- Run t-test based on the estmated means\n",
    "\n",
    "What I want to compare?\n",
    "\n",
    "1. BL_plan vs MAIN_plan_baseline vs MAIN_plan_adaptation\n",
    "2. BL_go vs MAIN_go_baseline vs MAIN_go_adaptation\n",
    "3. MAIN_plan_baseline vs MAIN_plan_adaptation\n",
    "4. MAIN_go_baseline vs MAIN_go_adaptation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c49d5",
   "metadata": {},
   "source": [
    "# IMPORTANT NOTES ON CODE\n",
    "\n",
    "Here’s a compact, step-by-step way to read what you’ve got and what it means.\n",
    "\n",
    "# 1) What the MixedLM table tells you\n",
    "\n",
    "* **Model**: `pac_value ~ condition` with a **random intercept per subject** (`groups=sub`).\n",
    "* **Coding**: The intercept is the mean of the reference level of `condition` (likely `_BL_N/A`). The two listed coefficients are **differences** from that reference.\n",
    "* **Coefficients**\n",
    "\n",
    "  * `Intercept`: mean pac_value at `_BL_N/A`.\n",
    "  * `condition[T._MAIN__adaptation]`: mean difference vs `_BL_N/A` (negative here).\n",
    "  * `condition[T._MAIN__baseline]`: mean difference vs `_BL_N/A` (positive here).\n",
    "* **z and p**: Wald tests for whether each coefficient differs from 0. All three fixed-effect lines are highly significant (tiny p’s).\n",
    "* **CIs**: All tight around the estimates—consistent with strong effects.\n",
    "* **Random Effect Variance (Group Var ≈ 3.68e-10)**: Between-subject variability (after accounting for `condition`) is extremely small relative to your outcome scale. That can be real or just a scaling/rounding artifact, but it means subjects don’t differ much in baseline levels in this model.\n",
    "\n",
    "# 2) What the EMM pairwise table adds\n",
    "\n",
    "You computed **estimated marginal means (EMMs)** and **pairwise contrasts** with **Tukey adjustment** (good for all pairwise comparisons among groups).\n",
    "\n",
    "Each row compares two conditions:\n",
    "\n",
    "* **estimate_link**: the **difference in means** on the model’s link scale. Here the link is identity (linear mixed model), so this is a **raw difference in pac_value**.\n",
    "* **SE**: standard error of that difference.\n",
    "* **t.ratio**: test statistic for the difference.\n",
    "* **p.value.adj**: Tukey-adjusted p-value (controls family-wise error across all pairs).\n",
    "\n",
    "Your results:\n",
    "\n",
    "* `_BL_N/A – _MAIN__baseline = −0.000149`, **adj p < 1e-6** → `_MAIN__baseline` is **higher** than `_BL_N/A` by ~1.49×10⁻⁴.\n",
    "* `_BL_N/A – _MAIN__adaptation = +0.000020`, **adj p = 0.0018** → `_BL_N/A` is **slightly higher** than `_MAIN__adaptation` by ~2×10⁻⁵.\n",
    "* `_MAIN__baseline – _MAIN__adaptation = +0.000170`, **adj p < 1e-6** → `_MAIN__baseline` is **higher** than `_MAIN__adaptation` by ~1.70×10⁻⁴.\n",
    "\n",
    "So the **ordering of means** is:\n",
    "\n",
    "```\n",
    "MAIN__baseline  >  BL_N/A  >  MAIN__adaptation\n",
    "```\n",
    "\n",
    "and **all three pairwise differences are statistically significant** after Tukey correction.\n",
    "\n",
    "# 3) Are these differences big or small?\n",
    "\n",
    "You said earlier pac_value has **mean ≈ 1×10⁻⁴** and **SD ≈ 5×10⁻⁵**. Using that scale:\n",
    "\n",
    "* The largest contrast (baseline vs adaptation) ≈ **1.7×10⁻⁴**, which is about **3.4 SDs** (1.7e-4 / 5e-5). That’s **very large** relative to your outcome variability.\n",
    "* The small contrast (BL_N/A vs adaptation) ≈ **2×10⁻⁵**, ~**0.4 SD**, still meaningful and significant.\n",
    "\n",
    "(If those summary stats came from a subset, re-check with your actual sample SDs per condition.)\n",
    "\n",
    "# 4) How to report this\n",
    "\n",
    "* **Model**: “We fitted a linear mixed-effects model with condition as a fixed effect and random intercepts for subjects.”\n",
    "* **Main effect**: “Condition had a significant effect on pac_value (all pairwise Tukey-adjusted p’s ≤ 0.0018).”\n",
    "* **EMM contrasts** (report the three differences with CIs if you also computed EMM CIs):\n",
    "\n",
    "  * `MAIN__baseline` vs `MAIN__adaptation`: Δ = 0.000170 (Tukey-adj p < 0.001)\n",
    "  * `MAIN__baseline` vs `BL_N/A`: Δ = 0.000149 (Tukey-adj p < 0.001)\n",
    "  * `BL_N/A` vs `MAIN__adaptation`: Δ = 0.000020 (Tukey-adj p = 0.0018)\n",
    "* **Direction/ordering**: “pac_value is highest in MAIN__baseline, intermediate at BL_N/A, lowest in MAIN__adaptation.”\n",
    "* **Random effects**: “Between-subject variance was near zero on this scale, suggesting limited subject-level heterogeneity after accounting for condition.”\n",
    "\n",
    "# 5) Practical tips\n",
    "\n",
    "\n",
    "* **Rescale for readability**: Because values are ~1e-4, consider reporting in **micro-units** (e.g., multiply by 10⁶). Then the big contrast becomes **+170 μ-units** with the same statistics. This improves interpretability without changing inference.\n",
    "* **Check model diagnostics**: residual plots, influential points, and whether random-effect variance being ~0 is reasonable for your data.\n",
    "* **Include EMMs**: It’s useful to also print the per-condition EMMs (not just contrasts) with 95% CIs, so readers see the absolute levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "454a8722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import os\n",
    "# Load the dataframe\n",
    "group = 'Y'\n",
    "roi_dir = f'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set\\\\{group} group\\\\roi_source_analysis'\n",
    "df_pac_roi = pd.read_csv(os.path.join(roi_dir, f'PAC_MI_SOURCE_{group}_ROI.csv'))\n",
    "df_pac_roi['block'] = df_pac_roi['block'].fillna('N/A')\n",
    "df_pac_roi[\"condition\"] = df_pac_roi[\"task\"] + \"_\" + df_pac_roi[\"block\"]\n",
    "roi = 'G_precentral-lh'  # Example ROI name\n",
    "df_roi = df_pac_roi.query(\"roi == @roi\")\n",
    "\n",
    "df_plan = df_roi.query(\"task_stage == '_plan'\") # for model_1\n",
    "df_go = df_roi.query(\"task_stage == '_go'\") # for model_2\n",
    "df_plan_main = df_plan.query(\"task == '_MAIN'\") # for model_3\n",
    "df_go_main = df_go.query(\"task == '_MAIN'\") # for model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a6f36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROI: G_precentral-lh\n",
      "\n",
      "======================================================================\n",
      "MODEL 1: Planning Stage (BL vs MAIN baseline vs MAIN adaptation)\n",
      "======================================================================\n",
      "                  Mixed Linear Model Regression Results\n",
      "=========================================================================\n",
      "Model:                  MixedLM       Dependent Variable:       pac_value\n",
      "No. Observations:       69            Method:                   REML     \n",
      "No. Groups:             23            Scale:                    0.0000   \n",
      "Min. group size:        3             Log-Likelihood:           598.5126 \n",
      "Max. group size:        3             Converged:                Yes      \n",
      "Mean group size:        3.0                                              \n",
      "-------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------------\n",
      "Intercept                       0.000    0.000 22.546 0.000  0.000  0.000\n",
      "condition[T._MAIN__adaptation] -0.000    0.000 -3.250 0.001 -0.000 -0.000\n",
      "condition[T._MAIN__baseline]    0.000    0.000 24.023 0.000  0.000  0.000\n",
      "Group Var                       0.000    0.000                           \n",
      "=========================================================================\n",
      "\n",
      "Random Effect Variance: 3.68e-10\n",
      "\n",
      "======================================================================\n",
      "MODEL 2: Go Stage (BL vs MAIN baseline vs MAIN adaptation)\n",
      "======================================================================\n",
      "                  Mixed Linear Model Regression Results\n",
      "==========================================================================\n",
      "Model:                   MixedLM       Dependent Variable:       pac_value\n",
      "No. Observations:        69            Method:                   REML     \n",
      "No. Groups:              23            Scale:                    0.0000   \n",
      "Min. group size:         3             Log-Likelihood:           612.4956 \n",
      "Max. group size:         3             Converged:                Yes      \n",
      "Mean group size:         3.0                                              \n",
      "--------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------------------------\n",
      "Intercept                       0.000    0.000  33.875 0.000  0.000  0.000\n",
      "condition[T._MAIN__adaptation] -0.000    0.000 -17.066 0.000 -0.000 -0.000\n",
      "condition[T._MAIN__baseline]    0.000    0.000   2.883 0.004  0.000  0.000\n",
      "Group Var                       0.000    0.000                            \n",
      "==========================================================================\n",
      "\n",
      "Random Effect Variance: 1.45e-10\n",
      "\n",
      "======================================================================\n",
      "MODEL 3: Planning Stage MAIN only (baseline vs adaptation)\n",
      "======================================================================\n",
      "           Mixed Linear Model Regression Results\n",
      "============================================================\n",
      "Model:               MixedLM  Dependent Variable:  pac_value\n",
      "No. Observations:    46       Method:              REML     \n",
      "No. Groups:          23       Scale:               0.0000   \n",
      "Min. group size:     2        Log-Likelihood:      394.3574 \n",
      "Max. group size:     2        Converged:           Yes      \n",
      "Mean group size:     2.0                                    \n",
      "------------------------------------------------------------\n",
      "                   Coef. Std.Err.   z    P>|z| [0.025 0.975]\n",
      "------------------------------------------------------------\n",
      "Intercept          0.000    0.000 17.026 0.000  0.000  0.000\n",
      "block[T._baseline] 0.000    0.000 27.878 0.000  0.000  0.000\n",
      "Group Var          0.000    0.000                           \n",
      "============================================================\n",
      "\n",
      "Random Effect Variance: 6.02e-10\n",
      "\n",
      "======================================================================\n",
      "MODEL 4: Go Stage MAIN only (baseline vs adaptation)\n",
      "======================================================================\n",
      "           Mixed Linear Model Regression Results\n",
      "============================================================\n",
      "Model:               MixedLM  Dependent Variable:  pac_value\n",
      "No. Observations:    46       Method:              REML     \n",
      "No. Groups:          23       Scale:               0.0000   \n",
      "Min. group size:     2        Log-Likelihood:      418.8444 \n",
      "Max. group size:     2        Converged:           Yes      \n",
      "Mean group size:     2.0                                    \n",
      "------------------------------------------------------------\n",
      "                   Coef. Std.Err.   z    P>|z| [0.025 0.975]\n",
      "------------------------------------------------------------\n",
      "Intercept          0.000    0.000 17.722 0.000  0.000  0.000\n",
      "block[T._baseline] 0.000    0.000 25.774 0.000  0.000  0.000\n",
      "Group Var          0.000    0.000                           \n",
      "============================================================\n",
      "\n",
      "Random Effect Variance: 8.69e-11\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# Suppress convergence warnings for mixed models with zero random effects\n",
    "# (These warnings indicate minimal between-subject variance, which is OK)\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Model templates\n",
    "print(f\"\\nROI: {roi}\")\n",
    "\n",
    "# 1 - BL_plan vs MAIN_plan_baseline vs MAIN_plan_adaptation\n",
    "model_1 = smf.mixedlm(\n",
    "    \"pac_value ~ condition\",\n",
    "    data=df_plan,\n",
    "    groups=df_plan[\"sub\"]\n",
    ").fit(reml=True)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 1: Planning Stage (BL vs MAIN baseline vs MAIN adaptation)\")\n",
    "print(\"=\"*70)\n",
    "print(model_1.summary().as_text())\n",
    "print(f\"Random Effect Variance: {model_1.cov_re.iloc[0, 0]:.2e}\")\n",
    "\n",
    "# 2 - BL_go vs MAIN_go_baseline vs MAIN_go_adaptation\n",
    "model_2 = smf.mixedlm(\n",
    "    \"pac_value ~ condition\",\n",
    "    data=df_go,\n",
    "    groups=df_go[\"sub\"]\n",
    ").fit(reml=True)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 2: Go Stage (BL vs MAIN baseline vs MAIN adaptation)\")\n",
    "print(\"=\"*70)\n",
    "print(model_2.summary().as_text())\n",
    "print(f\"Random Effect Variance: {model_2.cov_re.iloc[0, 0]:.2e}\")\n",
    "\n",
    "# 3 - MAIN_plan_baseline vs MAIN_plan_adaptation\n",
    "model_3 = smf.mixedlm(\n",
    "    \"pac_value ~ block\",\n",
    "    data=df_plan_main,\n",
    "    groups=df_plan_main[\"sub\"]\n",
    ").fit(reml=True)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 3: Planning Stage MAIN only (baseline vs adaptation)\")\n",
    "print(\"=\"*70)\n",
    "print(model_3.summary().as_text())\n",
    "print(f\"Random Effect Variance: {model_3.cov_re.iloc[0, 0]:.2e}\")\n",
    "\n",
    "# 4 - MAIN_go_baseline vs MAIN_go_adaptation\n",
    "model_4 = smf.mixedlm(\n",
    "    \"pac_value ~ block\",\n",
    "    data=df_go_main,\n",
    "    groups=df_go_main[\"sub\"]\n",
    ").fit(reml=True)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 4: Go Stage MAIN only (baseline vs adaptation)\")\n",
    "print(\"=\"*70)\n",
    "print(model_4.summary().as_text())\n",
    "print(f\"Random Effect Variance: {model_4.cov_re.iloc[0, 0]:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15930408",
   "metadata": {},
   "source": [
    "### Diagnostic: Should We Use OLS Instead?\n",
    "\n",
    "If random effect variances are near zero (< 1e-10), consider using regular OLS models with clustered standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c34deb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM EFFECT VARIANCE DIAGNOSTICS\n",
      "======================================================================\n",
      "Model 1 (Planning)        | Random Var: 3.68e-10 | ⚠️  Near zero - consider OLS\n",
      "Model 2 (Go)              | Random Var: 1.45e-10 | ⚠️  Near zero - consider OLS\n",
      "Model 3 (MAIN Planning)   | Random Var: 6.02e-10 | ⚠️  Near zero - consider OLS\n",
      "Model 4 (MAIN Go)         | Random Var: 8.69e-11 | ⚠️  Near zero - consider OLS\n",
      "\n",
      "======================================================================\n",
      "RECOMMENDATION: Consider using OLS for models with near-zero random effects.\n",
      "This would avoid convergence warnings and provide more interpretable results.\n",
      "\n",
      "Alternatively, the current mixed models are still valid - the warnings\n",
      "simply indicate that subject-level random intercepts add little variance.\n"
     ]
    }
   ],
   "source": [
    "# Check if we should use OLS models instead\n",
    "models = {\n",
    "    'Model 1 (Planning)': model_1,\n",
    "    'Model 2 (Go)': model_2,\n",
    "    'Model 3 (MAIN Planning)': model_3,\n",
    "    'Model 4 (MAIN Go)': model_4\n",
    "}\n",
    "\n",
    "print(\"RANDOM EFFECT VARIANCE DIAGNOSTICS\")\n",
    "print(\"=\"*70)\n",
    "threshold = 1e-8\n",
    "use_ols_recommendation = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    var_re = model.cov_re.iloc[0, 0]\n",
    "    print(f\"{name:25s} | Random Var: {var_re:.2e} | \", end=\"\")\n",
    "    \n",
    "    if var_re < threshold:\n",
    "        print(\"⚠️  Near zero - consider OLS\")\n",
    "        use_ols_recommendation.append(name)\n",
    "    else:\n",
    "        print(\"✓ Mixed model appropriate\")\n",
    "\n",
    "if use_ols_recommendation:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RECOMMENDATION: Consider using OLS for models with near-zero random effects.\")\n",
    "    print(\"This would avoid convergence warnings and provide more interpretable results.\")\n",
    "    print(\"\\nAlternatively, the current mixed models are still valid - the warnings\")\n",
    "    print(\"simply indicate that subject-level random intercepts add little variance.\")\n",
    "else:\n",
    "    print(\"\\n✓ All models have meaningful random effects - mixed models appropriate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4108d00",
   "metadata": {},
   "source": [
    "## Model Fitting\n",
    "\n",
    "The convergence warnings below indicate that random effect variances are estimated at or near zero. This suggests minimal between-subject variability, and we may consider:\n",
    "1. Using regular OLS models instead\n",
    "2. Suppressing the warnings if mixed models are theoretically justified\n",
    "3. Adding diagnostic output to check variance components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a4281",
   "metadata": {},
   "source": [
    "## Estimated Marginal Means (EMMs) Implementation\n",
    "\n",
    "This section implements a comprehensive `emmeans` function for post-hoc testing of mixed linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0919397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMM dependencies imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Core imports for emmeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product, combinations\n",
    "from typing import Dict, List, Optional, Union, Tuple\n",
    "import patsy\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import norm, t as tdist\n",
    "\n",
    "# Try to import psturng for proper Tukey adjustment\n",
    "try:\n",
    "    from statsmodels.stats.libqsturng import psturng\n",
    "    _HAVE_PSTURNG = True\n",
    "except ImportError:\n",
    "    _HAVE_PSTURNG = False\n",
    "    \n",
    "print(\"EMM dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7798b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementation of estimated marginal means (EMMs) computation and contrasts,\n",
    "adapted from the provided CODEBASE. This module defines the `emmeans` function\n",
    "along with its supporting utilities. The code is lifted directly from the\n",
    "original snippet to facilitate testing and debugging in a standalone module.\n",
    "\n",
    "Note: This file was automatically generated during validation of the\n",
    "emmeans function. Any changes or bug fixes should be documented in the\n",
    "appropriate section of the validation report.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Union, List, Optional, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "from itertools import product, combinations\n",
    "from scipy.stats import norm, t as tdist\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf  # noqa: F401  (kept for user parity)\n",
    "import re\n",
    "\n",
    "try:\n",
    "    # statsmodels >= 0.14\n",
    "    from statsmodels.stats.libqsturng import psturng\n",
    "    _HAVE_PSTURNG = True\n",
    "except Exception:\n",
    "    _HAVE_PSTURNG = False\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "\n",
    "# ----------------------------- Utilities -----------------------------\n",
    "\n",
    "def _groupby(df: pd.DataFrame, by_cols: List[str], **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper that (a) avoids passing duplicate 'dropna' and\n",
    "    (b) gracefully supports pandas < 1.1 where 'dropna' is unsupported.\n",
    "    \"\"\"\n",
    "    dropna_kw = kwargs.pop(\"dropna\", None)\n",
    "    try:\n",
    "        if dropna_kw is not None:\n",
    "            return df.groupby(by_cols, dropna=dropna_kw, **kwargs)\n",
    "        else:\n",
    "            # default to dropna=False for stable marginalization behavior\n",
    "            return df.groupby(by_cols, dropna=False, **kwargs)\n",
    "    except TypeError:\n",
    "        # pandas < 1.1: retry without 'dropna'\n",
    "        return df.groupby(by_cols, **kwargs)\n",
    "\n",
    "\n",
    "def _base_name(patsy_name: str) -> str:\n",
    "    n = patsy_name.strip()\n",
    "    if n.startswith(\"C(\") and n.endswith(\")\"):\n",
    "        return n[2:-1].strip()\n",
    "    return n\n",
    "\n",
    "\n",
    "def _extract_dep_vars(expr: str, data_cols: pd.Index) -> List[str]:\n",
    "    \"\"\"\n",
    "    Heuristic: pull candidate symbols from an EvalFactor's name,\n",
    "    keep only those that are actual columns in `data`.\n",
    "    \"\"\"\n",
    "    tokens = set(re.findall(r\"[A-Za-z_]\\w*\", expr))\n",
    "    ignore = {\"C\", \"I\", \"np\", \"pd\", \"math\", \"sin\", \"cos\", \"tan\", \"exp\", \"log\", \"sqrt\"}\n",
    "    return [t for t in tokens if (t not in ignore and t in data_cols)]\n",
    "\n",
    "\n",
    "def _get_design_info_or_raise(result):\n",
    "    try:\n",
    "        return result.model.data.design_info\n",
    "    except AttributeError:\n",
    "        raise ValueError(\"Model must be fitted with a Patsy formula to have design_info.\")\n",
    "\n",
    "\n",
    "def _get_model_params_and_vcov(result, vcov: Optional[np.ndarray]) -> Tuple[np.ndarray, List[str], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Handles MixedLM vs others and aligns covariance to fixed-effect parameter order.\n",
    "    \"\"\"\n",
    "    if hasattr(result, \"fe_params\"):  # MixedLM\n",
    "        beta = result.fe_params.values\n",
    "        param_names = list(result.fe_params.index)\n",
    "        if vcov is not None:\n",
    "            V = np.asarray(vcov)\n",
    "        else:\n",
    "            V_full = result.cov_params()\n",
    "            if hasattr(V_full, \"loc\"):  # DataFrame\n",
    "                V = V_full.loc[param_names, param_names].to_numpy()\n",
    "            else:\n",
    "                # ndarray fallback: assume order matches params; slice by position\n",
    "                all_names = list(getattr(result, \"params\").index)\n",
    "                idx = [all_names.index(n) for n in param_names]\n",
    "                V = np.asarray(V_full)[np.ix_(idx, idx)]\n",
    "    else:\n",
    "        beta = result.params.values\n",
    "        param_names = list(result.params.index)\n",
    "        V = np.asarray(vcov) if vcov is not None else np.asarray(result.cov_params())\n",
    "    return beta, param_names, V\n",
    "\n",
    "\n",
    "def _get_link_and_deriv(result) -> Tuple[Callable[[np.ndarray], np.ndarray], Callable[[np.ndarray], np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Returns (invlink, deriv) where 'deriv' is derivative of inverse link wrt eta.\n",
    "    Falls back to identity if not a GLM.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        link = result.model.family.link\n",
    "        invlink = link.inverse\n",
    "        def deriv(eta):\n",
    "            if hasattr(link, \"inverse_deriv\"):\n",
    "                return link.inverse_deriv(eta)\n",
    "            # symmetric numerical derivative, stable enough for scalar/vector\n",
    "            eps = 1e-6\n",
    "            return (invlink(eta + eps) - invlink(eta - eps)) / (2 * eps)\n",
    "    except AttributeError:\n",
    "        invlink = lambda x: x\n",
    "        deriv = lambda x: np.ones_like(np.asarray(x), dtype=float)\n",
    "    return invlink, deriv\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FactorSpec:\n",
    "    kind: str                           # \"cat\" or \"num\"\n",
    "    levels: Optional[List] = None       # for categorical\n",
    "    depends_on: Optional[List[str]] = None  # raw variable deps for transformed factors\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FactorExtraction:\n",
    "    factors: Dict[str, FactorSpec]\n",
    "    name_map: Dict[str, str]\n",
    "    deps_map: Dict[str, List[str]]\n",
    "\n",
    "\n",
    "def _extract_factors(di, data: pd.DataFrame) -> FactorExtraction:\n",
    "    factors: Dict[str, FactorSpec] = {}\n",
    "    name_map: Dict[str, str] = {}\n",
    "    deps_map: Dict[str, List[str]] = {}\n",
    "\n",
    "    for fac, info in di.factor_infos.items():\n",
    "        raw_name = fac.name() if hasattr(fac, \"name\") else str(fac)\n",
    "        base = _base_name(raw_name)\n",
    "        name_map[base] = raw_name\n",
    "\n",
    "        state = getattr(info, \"state\", {}) or {}\n",
    "        levels = [lv for lv in list(state.get(\"levels\", [])) if pd.notna(lv)]\n",
    "\n",
    "        if levels:\n",
    "            # Patsy categorical with known levels\n",
    "            factors[base] = FactorSpec(kind=\"cat\", levels=levels, depends_on=[])\n",
    "            continue\n",
    "\n",
    "        if base in data.columns:\n",
    "            s = data[base]\n",
    "            if isinstance(s.dtype, CategoricalDtype):\n",
    "                factors[base] = FactorSpec(kind=\"cat\", levels=list(s.cat.categories), depends_on=[])\n",
    "            elif not pd.api.types.is_numeric_dtype(s):\n",
    "                factors[base] = FactorSpec(kind=\"cat\", levels=list(pd.unique(s.dropna())), depends_on=[])\n",
    "            else:\n",
    "                factors[base] = FactorSpec(kind=\"num\", levels=None, depends_on=[])\n",
    "        else:\n",
    "            # Transformed / EvalFactor (e.g., I(x**2), np.log(x), etc.)\n",
    "            deps = _extract_dep_vars(raw_name, data.columns)\n",
    "            factors[base] = FactorSpec(kind=\"num\", levels=None, depends_on=deps)\n",
    "            deps_map[base] = deps\n",
    "\n",
    "    return FactorExtraction(factors=factors, name_map=name_map, deps_map=deps_map)\n",
    "\n",
    "\n",
    "def _validate_at_levels(at: Dict[str, Union[float, str, List[Union[float, str]]]],\n",
    "                        factors: Dict[str, FactorSpec]):\n",
    "    for k, v in (at or {}).items():\n",
    "        spec = factors[k]\n",
    "        if spec.kind == \"cat\":\n",
    "            vals = list(v) if isinstance(v, (list, tuple, np.ndarray, pd.Series)) else [v]\n",
    "            bad = [x for x in vals if x not in (spec.levels or [])]\n",
    "            if bad:\n",
    "                raise ValueError(\n",
    "                    f\"at['{k}'] contains levels not in the model: {bad}. \"\n",
    "                    f\"Allowed: {spec.levels}\"\n",
    "                )\n",
    "\n",
    "\n",
    "def _determine_used_index_and_weights(result, data: pd.DataFrame) -> Tuple[Optional[pd.Index], Optional[pd.Series]]:\n",
    "    \"\"\"\n",
    "    Attempts to recover the actual analysis sample index and (if present) model weights.\n",
    "    \"\"\"\n",
    "    used_idx = None\n",
    "    weights = None\n",
    "    try:\n",
    "        used_idx = getattr(result.model.data, \"row_labels\", None)\n",
    "        if used_idx is None and len(getattr(result.model, \"endog\", [])) == len(data):\n",
    "            used_idx = data.index\n",
    "        if used_idx is not None:\n",
    "            used_idx = pd.Index(used_idx).intersection(data.index)\n",
    "    except Exception:\n",
    "        used_idx = None\n",
    "\n",
    "    try:\n",
    "        weights = getattr(result.model, \"weights\", None)\n",
    "        if weights is not None and used_idx is not None:\n",
    "            weights = pd.Series(np.asarray(weights).reshape(-1), index=used_idx)\n",
    "    except Exception:\n",
    "        weights = None\n",
    "\n",
    "    return used_idx, weights\n",
    "\n",
    "\n",
    "def _build_reference_grid(\n",
    "    data: pd.DataFrame,\n",
    "    factors: Dict[str, FactorSpec],\n",
    "    deps_map: Dict[str, List[str]],\n",
    "    focal_set: set,\n",
    "    at: Dict[str, Union[float, str, List[Union[float, str]]]],\n",
    "    di,\n",
    "    param_names: List[str],\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    # Levels per factor (respect `at` first)\n",
    "    grid_levels: Dict[str, List] = {}\n",
    "    for name, meta in factors.items():\n",
    "        if name in at:\n",
    "            val = at[name]\n",
    "            grid_levels[name] = list(val) if isinstance(val, (list, tuple, np.ndarray, pd.Series)) else [val]\n",
    "        elif name in focal_set:\n",
    "            if meta.kind == \"cat\":\n",
    "                grid_levels[name] = meta.levels or []\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Numeric focal variable '{name}' requires explicit levels via at={{'{name}':[...]}}\"\n",
    "                )\n",
    "        else:\n",
    "            if meta.kind == \"cat\":\n",
    "                grid_levels[name] = meta.levels or []\n",
    "            else:\n",
    "                if name in data.columns:\n",
    "                    grid_levels[name] = [float(pd.to_numeric(data[name], errors=\"coerce\").mean())]\n",
    "                else:\n",
    "                    # transformed numeric factor: inject raw dependencies later\n",
    "                    pass\n",
    "\n",
    "    if deps_map:\n",
    "        needed = set(v for deps in deps_map.values() for v in deps)\n",
    "        missing = [v for v in needed if v not in grid_levels]\n",
    "        for v in missing:\n",
    "            if v not in data.columns:\n",
    "                continue\n",
    "            s = data[v]\n",
    "            if isinstance(s.dtype, CategoricalDtype):\n",
    "                grid_levels[v] = list(s.cat.categories)\n",
    "            elif not pd.api.types.is_numeric_dtype(s):\n",
    "                grid_levels[v] = list(pd.unique(s.dropna()))\n",
    "            else:\n",
    "                grid_levels[v] = [float(pd.to_numeric(s, errors=\"coerce\").mean())]\n",
    "\n",
    "    # Cartesian grid\n",
    "    keys = list(grid_levels.keys())\n",
    "    values = [grid_levels[k] for k in keys]\n",
    "    grid_raw = pd.DataFrame([dict(zip(keys, tup)) for tup in product(*values)])\n",
    "\n",
    "    # Design matrix aligned to param order\n",
    "    X_grid = patsy.build_design_matrices([di], grid_raw, return_type=\"dataframe\")[0]\n",
    "    Xg = X_grid.reindex(columns=param_names, fill_value=0.0)\n",
    "    return grid_raw, Xg\n",
    "\n",
    "\n",
    "def _apply_marginal_weights(\n",
    "    grid_raw: pd.DataFrame,\n",
    "    data: pd.DataFrame,\n",
    "    used_idx: Optional[pd.Index],\n",
    "    weight: str,\n",
    "    focal_set: set,\n",
    "    at: Dict[str, Union[float, str, List[Union[float, str]]]],\n",
    "    factors: Dict[str, FactorSpec],\n",
    "    drop_unseen: bool\n",
    ") -> pd.DataFrame:\n",
    "    grid_raw = grid_raw.copy()\n",
    "    grid_raw[\"_weight\"] = 1.0\n",
    "\n",
    "    if weight == \"proportional\":\n",
    "        nonfocal_cats = [\n",
    "            nm for nm, m in factors.items()\n",
    "            if (nm not in focal_set) and (nm not in at) and (m.kind == \"cat\")\n",
    "        ]\n",
    "        if nonfocal_cats:\n",
    "            source_df = data.loc[used_idx] if used_idx is not None else data\n",
    "            # Avoid pandas warning by passing a single column name instead of a list\n",
    "            grouper = nonfocal_cats[0] if len(nonfocal_cats) == 1 else nonfocal_cats\n",
    "            grp = _groupby(source_df[nonfocal_cats], grouper, dropna=False).size()\n",
    "            total = grp.sum()\n",
    "            joint_props = (grp / total).to_dict()\n",
    "\n",
    "            def _row_prop(row):\n",
    "                key = tuple(row[c] for c in nonfocal_cats)\n",
    "                return float(joint_props.get(key, 0.0))\n",
    "\n",
    "            grid_raw[\"_weight\"] = grid_raw.apply(\n",
    "                (lambda r: _row_prop(r) if nonfocal_cats else 1.0), axis=1\n",
    "            )\n",
    "\n",
    "            if drop_unseen:\n",
    "                grid_raw = grid_raw.loc[grid_raw[\"_weight\"] > 0].copy()\n",
    "\n",
    "            if np.allclose(grid_raw[\"_weight\"].values.sum(), 0.0):\n",
    "                grid_raw[\"_weight\"] = 1.0\n",
    "\n",
    "    return grid_raw\n",
    "\n",
    "\n",
    "def _normalize_weights_by_cell(grid_raw: pd.DataFrame, cell_keys: List[str]) -> pd.DataFrame:\n",
    "    grid_raw = grid_raw.copy()\n",
    "    if len(cell_keys) > 0:\n",
    "        sums = _groupby(grid_raw, cell_keys, sort=False)[\"_weight\"].transform(\"sum\")\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            grid_raw[\"_weight_norm_by_cell\"] = np.where(sums > 0, grid_raw[\"_weight\"] / sums, 0.0)\n",
    "    else:\n",
    "        grid_raw[\"_weight_norm_by_cell\"] = 1.0\n",
    "    return grid_raw\n",
    "\n",
    "\n",
    "def _label_for_spec_tuple(specs: List[str], tup: Tuple) -> str:\n",
    "    if len(specs) == 1:\n",
    "        return str(tup[0])\n",
    "    parts = [f\"{nm}={val}\" for nm, val in zip(specs, tup)]\n",
    "    return \" × \".join(parts)\n",
    "\n",
    "\n",
    "# ---------------------- Core computational blocks ----------------------\n",
    "\n",
    "def _compute_emms_per_cell(\n",
    "    grid_raw: pd.DataFrame,\n",
    "    Xg: pd.DataFrame,\n",
    "    beta: np.ndarray,\n",
    "    V: np.ndarray,\n",
    "    invlink: Callable,\n",
    "    deriv: Callable,\n",
    "    transform: str,\n",
    "    level: float,\n",
    "    df_global: float,\n",
    "    specs: List[str],\n",
    "    by: List[str],\n",
    ") -> Tuple[pd.DataFrame, Dict[Tuple, List[Tuple[Tuple, np.ndarray, float, float]]]]:\n",
    "    cell_keys = specs + by\n",
    "    # Avoid pandas FutureWarning by not passing a list of length 1 as the grouper\n",
    "    if cell_keys:\n",
    "        grouper = cell_keys[0] if len(cell_keys) == 1 else cell_keys\n",
    "        grouped = _groupby(grid_raw, grouper, sort=False)\n",
    "    else:\n",
    "        grouped = [((), grid_raw)]\n",
    "\n",
    "    emm_rows = []\n",
    "    by_slices: Dict[Tuple, List[Tuple[Tuple, np.ndarray, float, float]]] = {}\n",
    "\n",
    "    for key_vals, subgrid in grouped:\n",
    "        if subgrid.shape[0] == 0:\n",
    "            continue\n",
    "        w = subgrid[\"_weight\"].values.astype(float)\n",
    "        if w.size == 0:\n",
    "            continue\n",
    "        total_w = w.sum()\n",
    "        w = (w / total_w) if total_w > 0 else np.full_like(w, 1.0 / float(w.size))\n",
    "\n",
    "        L = (Xg.loc[subgrid.index].values.T @ w).reshape(1, -1)\n",
    "\n",
    "        eta = float((L @ beta).item())\n",
    "        var_eta = float((L @ V @ L.T).item())\n",
    "        se_eta = float(np.sqrt(max(var_eta, 0.0)))\n",
    "\n",
    "        if transform == \"response\":\n",
    "            mu = float(invlink(eta))\n",
    "            se_mu = float(abs(deriv(eta)) * se_eta)\n",
    "        elif transform == \"link\":\n",
    "            mu, se_mu = eta, se_eta\n",
    "        else:\n",
    "            raise ValueError(\"transform must be 'response' or 'link'\")\n",
    "\n",
    "        df_use = df_global\n",
    "        crit = norm.ppf(0.5 + level / 2) if np.isinf(df_use) else tdist.ppf(0.5 + level / 2, df_use)\n",
    "\n",
    "        lo_eta, hi_eta = eta - crit * se_eta, eta + crit * se_eta\n",
    "        if transform == \"response\":\n",
    "            lo, hi = float(invlink(lo_eta)), float(invlink(hi_eta))\n",
    "        else:\n",
    "            lo, hi = float(lo_eta), float(hi_eta)\n",
    "\n",
    "        row = {}\n",
    "        if cell_keys:\n",
    "            if not isinstance(key_vals, tuple):\n",
    "                key_vals = (key_vals,)\n",
    "            for k, v in zip(cell_keys, key_vals):\n",
    "                row[k] = v\n",
    "\n",
    "        row.update({\n",
    "            \"emmean\": mu,\n",
    "            \"SE\": se_mu,\n",
    "            \"df\": df_use,\n",
    "            \"lower.CL\": lo,\n",
    "            \"upper.CL\": hi\n",
    "        })\n",
    "        emm_rows.append(row)\n",
    "\n",
    "        if by:\n",
    "            by_vals = tuple(row[bk] for bk in by)\n",
    "            spec_vals = tuple(row[sk] for sk in specs)\n",
    "        else:\n",
    "            by_vals = ()\n",
    "            spec_vals = tuple(row[sk] for sk in specs) if specs else (\"grand\",)\n",
    "\n",
    "        by_slices.setdefault(by_vals, []).append((spec_vals, L, eta, se_eta))\n",
    "\n",
    "    return pd.DataFrame(emm_rows), by_slices\n",
    "\n",
    "\n",
    "def _pairwise_contrasts_for_slice(\n",
    "    entries: List[Tuple[Tuple, np.ndarray, float, float]],\n",
    "    specs: List[str],\n",
    "    by_vals: Tuple,\n",
    "    beta: np.ndarray,\n",
    "    V: np.ndarray,\n",
    "    invlink: Callable,\n",
    "    deriv: Callable,\n",
    "    contrast_transform: str,\n",
    "    df_global: float,\n",
    "    df_provider: Optional[Callable[[np.ndarray], float]],\n",
    "    by: List[str],\n",
    ") -> List[Dict]:\n",
    "    rows = []\n",
    "    spec_keys = [e[0] for e in entries]\n",
    "    L_rows = [e[1] for e in entries]\n",
    "    k_groups = len(entries)\n",
    "    if k_groups < 2:\n",
    "        return rows\n",
    "\n",
    "    for (i, j) in combinations(range(k_groups), 2):\n",
    "        name_i = _label_for_spec_tuple(specs, spec_keys[i])\n",
    "        name_j = _label_for_spec_tuple(specs, spec_keys[j])\n",
    "        level_i_raw = spec_keys[i][0] if len(specs) == 1 else spec_keys[i]\n",
    "        level_j_raw = spec_keys[j][0] if len(specs) == 1 else spec_keys[j]\n",
    "        Li = L_rows[i]\n",
    "        Lj = L_rows[j]\n",
    "        Lc = Li - Lj\n",
    "\n",
    "        # Link-scale\n",
    "        delta_link = float((Lc @ beta).item())\n",
    "        var_link   = float((Lc @ V @ Lc.T).item())\n",
    "        se_link    = float(np.sqrt(max(var_link, 0.0)))\n",
    "\n",
    "        # Response-scale (delta method) if requested\n",
    "        if contrast_transform == \"response\":\n",
    "            eta_i = float((Li @ beta).item())\n",
    "            eta_j = float((Lj @ beta).item())\n",
    "            mu_i  = float(invlink(eta_i))\n",
    "            mu_j  = float(invlink(eta_j))\n",
    "            delta_resp = mu_i - mu_j\n",
    "\n",
    "            dgi = float(np.squeeze(deriv(eta_i)))\n",
    "            dgj = float(np.squeeze(deriv(eta_j)))\n",
    "            var_eta_i = float((Li @ V @ Li.T).item())\n",
    "            var_eta_j = float((Lj @ V @ Lj.T).item())\n",
    "            cov_ij    = float((Li @ V @ Lj.T).item())\n",
    "            var_resp  = max(dgi*dgi*var_eta_i + dgj*dgj*var_eta_j - 2*dgi*dgj*cov_ij, 0.0)\n",
    "            se_resp   = float(np.sqrt(var_resp))\n",
    "\n",
    "            delta_out = delta_resp\n",
    "            se_out    = se_resp\n",
    "        else:\n",
    "            delta_out = delta_link\n",
    "            se_out    = se_link\n",
    "\n",
    "        if df_provider is not None:\n",
    "            try:\n",
    "                df_c = float(df_provider(Lc))\n",
    "            except Exception:\n",
    "                df_c = df_global\n",
    "            if not np.isfinite(df_c):\n",
    "                df_c = df_global\n",
    "        else:\n",
    "            df_c = df_global\n",
    "\n",
    "        stat = delta_out / se_out if se_out > 0 else np.nan\n",
    "        if np.isinf(df_c):\n",
    "            p_raw = 2 * (1 - norm.cdf(abs(stat))) if np.isfinite(stat) else np.nan\n",
    "        else:\n",
    "            p_raw = 2 * (1 - tdist.cdf(abs(stat), df_c)) if np.isfinite(stat) else np.nan\n",
    "\n",
    "        row = {\n",
    "            \"contrast\": f\"{name_i} - {name_j}\",\n",
    "            (\"estimate_link\" if contrast_transform == \"link\" else \"estimate\"): delta_out,\n",
    "            \"SE\": se_out,\n",
    "            \"df\": df_c,\n",
    "            \"stat\": stat,\n",
    "            \"p.value\": p_raw,\n",
    "            \"__delta_link\": delta_link,\n",
    "            \"__se_link\": se_link,\n",
    "            \"__i\": i,\n",
    "            \"__j\": j,\n",
    "            \"__name_i\": name_i,\n",
    "            \"__name_j\": name_j,\n",
    "            \"__level_i\": level_i_raw,\n",
    "            \"__level_j\": level_j_raw,\n",
    "        }\n",
    "        for idx, bname in enumerate(by):\n",
    "            row[bname] = by_vals[idx]\n",
    "        rows.append(row)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def _custom_contrasts_for_slice(\n",
    "    entries: List[Tuple[Tuple, np.ndarray, float, float]],\n",
    "    contrasts: List[Tuple[str, np.ndarray]],\n",
    "    specs: List[str],\n",
    "    by_vals: Tuple,\n",
    "    beta: np.ndarray,\n",
    "    V: np.ndarray,\n",
    "    invlink: Callable,\n",
    "    deriv: Callable,\n",
    "    contrast_transform: str,\n",
    "    df_global: float,\n",
    "    df_provider: Optional[Callable[[np.ndarray], float]],\n",
    "    by: List[str],\n",
    ") -> List[Dict]:\n",
    "    rows = []\n",
    "    L_rows = [e[1] for e in entries]\n",
    "    k_groups = len(entries)\n",
    "\n",
    "    # Precompute for response-scale delta method\n",
    "    etas = [float((L_rows[g] @ beta).item()) for g in range(k_groups)]\n",
    "    mus  = [float(invlink(etas[g])) for g in range(k_groups)]\n",
    "    dgs  = [float(np.squeeze(deriv(etas[g]))) for g in range(k_groups)]\n",
    "    cov_eta = np.empty((k_groups, k_groups), dtype=float)\n",
    "    for g in range(k_groups):\n",
    "        for h in range(k_groups):\n",
    "            cov_eta[g, h] = float((L_rows[g] @ V @ L_rows[h].T).item())\n",
    "\n",
    "    for label, wvec in contrasts:\n",
    "        w = np.asarray(wvec, dtype=float).reshape(-1)\n",
    "        if w.shape[0] != k_groups:\n",
    "            raise ValueError(\n",
    "                f\"Custom contrast '{label}' length {w.shape[0]} != number of groups {k_groups} \"\n",
    "                f\"in BY-slice {by_vals}.\"\n",
    "            )\n",
    "\n",
    "        # Link-scale linear combination\n",
    "        Lc = sum(w[g] * L_rows[g] for g in range(k_groups))\n",
    "        delta_link = float((Lc @ beta).item())\n",
    "        var_link   = float((Lc @ V @ Lc.T).item())\n",
    "        se_link    = float(np.sqrt(max(var_link, 0.0)))\n",
    "\n",
    "        if contrast_transform == \"response\":\n",
    "            delta_resp = float(np.dot(w, mus))\n",
    "            Gw = np.outer(w, w) * np.outer(dgs, dgs)\n",
    "            var_resp = float(np.sum(Gw * cov_eta))\n",
    "            se_resp  = float(np.sqrt(max(var_resp, 0.0)))\n",
    "            delta_out, se_out = delta_resp, se_resp\n",
    "            est_key = \"estimate\"\n",
    "        else:\n",
    "            delta_out, se_out = delta_link, se_link\n",
    "            est_key = \"estimate_link\"\n",
    "\n",
    "        if df_provider is not None:\n",
    "            try:\n",
    "                df_c = float(df_provider(Lc))\n",
    "            except Exception:\n",
    "                df_c = df_global\n",
    "            if not np.isfinite(df_c):\n",
    "                df_c = df_global\n",
    "        else:\n",
    "            df_c = df_global\n",
    "\n",
    "        stat = delta_out / se_out if se_out > 0 else np.nan\n",
    "        if np.isinf(df_c):\n",
    "            p_raw = 2 * (1 - norm.cdf(abs(stat))) if np.isfinite(stat) else np.nan\n",
    "        else:\n",
    "            p_raw = 2 * (1 - tdist.cdf(abs(stat), df_c)) if np.isfinite(stat) else np.nan\n",
    "\n",
    "        row = {\n",
    "            \"contrast\": str(label),\n",
    "            est_key: delta_out,\n",
    "            \"SE\": se_out,\n",
    "            \"df\": df_c,\n",
    "            \"stat\": stat,\n",
    "            \"p.value\": p_raw\n",
    "        }\n",
    "        for idx, bname in enumerate(by):\n",
    "            row[bname] = by_vals[idx]\n",
    "        rows.append(row)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def _adjust_pvalues_per_slice(\n",
    "    contrasts_df: pd.DataFrame,\n",
    "    method: str,\n",
    "    result,\n",
    "    data: pd.DataFrame,\n",
    "    specs: List[str],\n",
    "    by: List[str],\n",
    "    used_idx: Optional[pd.Index],\n",
    "    model_weights: Optional[pd.Series],\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns a Series aligned to contrasts_df.index with adjusted p-values.\n",
    "    Implements strict Tukey/Tukey–Kramer when valid; otherwise falls back to\n",
    "    Holm/Bonferroni/Sidak/FDR as requested (with 'tukey' aliasing to Holm).\n",
    "    \"\"\"\n",
    "    if by:\n",
    "        # Avoid passing a single-element list as the grouper to avoid pandas warnings\n",
    "        grouper = by[0] if isinstance(by, list) and len(by) == 1 else by\n",
    "        slice_iter = contrasts_df.groupby(grouper, dropna=False, sort=False)\n",
    "    else:\n",
    "        slice_iter = [((), contrasts_df)]\n",
    "\n",
    "    # conditions for exact Tukey:\n",
    "    is_ols = isinstance(getattr(result, \"model\", None), sm.OLS)\n",
    "    strict_oneway = is_ols and (method == \"tukey\") and (len(specs) == 1)\n",
    "    no_weights = (model_weights is None)\n",
    "\n",
    "    use_real_tukey_global = (method == \"tukey\" and _HAVE_PSTURNG and strict_oneway and no_weights)\n",
    "\n",
    "    p_adj_chunks = []\n",
    "    for by_vals, subdf in slice_iter:\n",
    "        if use_real_tukey_global:\n",
    "            factor = specs[0]\n",
    "            if used_idx is None:\n",
    "                p_adj_chunks.append(_holm_chunk(subdf))\n",
    "                continue\n",
    "\n",
    "            # filter analysis rows by BY levels if any\n",
    "            if by:\n",
    "                mask = pd.Series(True, index=used_idx)\n",
    "                for bname, bval in zip(by, by_vals if isinstance(by_vals, tuple) else (by_vals,)):\n",
    "                    mask &= (data.loc[used_idx, bname] == bval)\n",
    "                used_in_slice = used_idx[mask]\n",
    "            else:\n",
    "                used_in_slice = used_idx\n",
    "\n",
    "            data_slice = data.loc[used_in_slice]\n",
    "\n",
    "            if factor not in data_slice.columns:\n",
    "                p_adj_chunks.append(_holm_chunk(subdf))\n",
    "                continue\n",
    "\n",
    "            # group sizes per level\n",
    "            # Use single-column grouper when the factor list has length 1 to avoid pandas warnings\n",
    "            level_counts = (\n",
    "                _groupby(data_slice[[factor]], factor, dropna=False)\n",
    "                .size().astype(float)\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                mse = float(result.mse_resid)\n",
    "                df_tukey = int(result.df_resid)\n",
    "            except Exception:\n",
    "                p_adj_chunks.append(_holm_chunk(subdf))\n",
    "                continue\n",
    "\n",
    "            # Tukey–Kramer q statistics using LINK-scale deltas\n",
    "            q_vals = []\n",
    "            for _, r in subdf.iterrows():\n",
    "                key_i = r[\"__level_i\"] if \"__level_i\" in r else r[\"__name_i\"]\n",
    "                key_j = r[\"__level_j\"] if \"__level_j\" in r else r[\"__name_j\"]\n",
    "\n",
    "                ni = float(level_counts.get(key_i, np.nan))\n",
    "                nj = float(level_counts.get(key_j, np.nan))\n",
    "                if not np.isfinite(ni) or not np.isfinite(nj) or ni <= 1 or nj <= 1:\n",
    "                    q_vals.append(np.nan)\n",
    "                    continue\n",
    "\n",
    "                if \"__delta_link\" in r and np.isfinite(r[\"__delta_link\"]):\n",
    "                    delta_link_here = float(r[\"__delta_link\"])\n",
    "                else:\n",
    "                    delta_link_here = float(r[\"estimate_link\"])\n",
    "\n",
    "                denom = np.sqrt(mse * 0.5 * (1.0/ni + 1.0/nj))\n",
    "                q_vals.append(abs(delta_link_here) / denom if denom > 0 else np.nan)\n",
    "\n",
    "            k = int(level_counts.shape[0])\n",
    "            padj = [1 - psturng(q, k, df_tukey) if np.isfinite(q) else np.nan for q in q_vals]\n",
    "            p_adj_chunks.append(pd.Series(padj, index=subdf.index))\n",
    "        else:\n",
    "            # General models or 'tukey' fallback → Holm\n",
    "            eff = \"holm\" if method == \"tukey\" else method\n",
    "            p = subdf[\"p.value\"].to_numpy(dtype=float)\n",
    "            mask = np.isfinite(p)\n",
    "            p_adj = np.full_like(p, np.nan, dtype=float)\n",
    "            if mask.any():\n",
    "                _, padj_valid, _, _ = multipletests(p[mask], method=eff)\n",
    "                p_adj[mask] = padj_valid\n",
    "            p_adj_chunks.append(pd.Series(p_adj, index=subdf.index))\n",
    "\n",
    "    return pd.concat(p_adj_chunks).sort_index()\n",
    "\n",
    "\n",
    "def _holm_chunk(subdf: pd.DataFrame) -> pd.Series:\n",
    "    p = subdf[\"p.value\"].to_numpy(dtype=float)\n",
    "    mask = np.isfinite(p)\n",
    "    p_adj = np.full_like(p, np.nan, dtype=float)\n",
    "    if mask.any():\n",
    "        _, padj_valid, _, _ = multipletests(p[mask], method=\"holm\")\n",
    "        p_adj[mask] = padj_valid\n",
    "    return pd.Series(p_adj, index=subdf.index)\n",
    "\n",
    "\n",
    "def _finalize_contrasts_df(contrasts_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = contrasts_df.copy()\n",
    "    df_vals = out[\"df\"].astype(float).to_numpy()\n",
    "    stat_vals = out[\"stat\"].astype(float).to_numpy()\n",
    "    out[\"t.ratio\"] = np.where(np.isfinite(df_vals), stat_vals, np.nan)\n",
    "    out[\"z.ratio\"] = np.where(~np.isfinite(df_vals), stat_vals, np.nan)\n",
    "\n",
    "    for _aux in [\"__i\", \"__j\", \"__name_i\", \"__name_j\", \"__level_i\", \"__level_j\", \"__delta_link\", \"__se_link\"]:\n",
    "        if _aux in out.columns:\n",
    "            out.drop(columns=[_aux], inplace=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ------------------------------ Public API ------------------------------\n",
    "\n",
    "def emmeans(\n",
    "    result,\n",
    "    data: pd.DataFrame,\n",
    "    specs: Union[str, List[str]],\n",
    "    *,\n",
    "    by: Optional[Union[str, List[str]]] = None,\n",
    "    at: Optional[Dict[str, Union[float, str, List[Union[float, str]]]]] = None,\n",
    "    weight: str = \"equal\",\n",
    "    transform: str = \"response\",\n",
    "    level: float = 0.95,\n",
    "    contrasts: Union[str, List[Tuple[str, np.ndarray]]] = \"pairwise\",\n",
    "    contrast_transform: str = \"link\",\n",
    "    adjust: Optional[str] = \"tukey\",\n",
    "    df_method: str = \"resid\",\n",
    "    vcov: Optional[np.ndarray] = None,\n",
    "    return_grid: bool = False,\n",
    "    # ---- extended knobs ----\n",
    "    df_provider: Optional[Callable[[np.ndarray], float]] = None,\n",
    "    drop_unseen: bool = False,\n",
    ") -> Dict[str, Optional[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Compute estimated marginal means (EMMs) and (within-BY) contrasts for statsmodels results.\n",
    "\n",
    "    Refactored for clarity/DRY while preserving computations and outputs.\n",
    "    \"\"\"\n",
    "    # ---------------- A. Parse/validate inputs ----------------\n",
    "    specs = [specs] if isinstance(specs, str) else list(specs)\n",
    "    by = [by] if isinstance(by, str) and by is not None else (list(by) if by else [])\n",
    "\n",
    "    if weight not in {\"equal\", \"proportional\"}:\n",
    "        raise ValueError(\"weight must be 'equal' or 'proportional'\")\n",
    "\n",
    "    at = at or {}\n",
    "    focal_set = set(specs) | set(by)\n",
    "\n",
    "    beta, param_names, V = _get_model_params_and_vcov(result, vcov)\n",
    "    invlink, deriv = _get_link_and_deriv(result)\n",
    "\n",
    "    if contrast_transform not in {\"link\", \"response\"}:\n",
    "        raise ValueError(\"contrast_transform must be 'link' or 'response'\")\n",
    "\n",
    "    di = _get_design_info_or_raise(result)\n",
    "\n",
    "    # Degrees of freedom for EMM CIs (global default; per-contrast handled with df_provider)\n",
    "    df_global = np.inf if df_method == \"wald\" else getattr(result, \"df_resid\", np.inf)\n",
    "\n",
    "    # ---------------- B. Extract factors & validate 'at' ----------------\n",
    "    fx = _extract_factors(di, data)\n",
    "    for nm in (set(specs) | set(by) | set(at.keys())):\n",
    "        if nm not in fx.factors:\n",
    "            raise ValueError(\n",
    "                f\"'{nm}' is not a recognized model factor. \"\n",
    "                f\"Known factors (by base name): {list(fx.factors.keys())}\"\n",
    "            )\n",
    "    _validate_at_levels(at, fx.factors)\n",
    "\n",
    "    # ---------------- C. Build reference grid & design ----------------\n",
    "    grid_raw, Xg = _build_reference_grid(\n",
    "        data=data,\n",
    "        factors=fx.factors,\n",
    "        deps_map=fx.deps_map,\n",
    "        focal_set=focal_set,\n",
    "        at=at,\n",
    "        di=di,\n",
    "        param_names=param_names,\n",
    "    )\n",
    "\n",
    "    # ---------------- D. Analysis index/weights for Tukey conditions ----------------\n",
    "    used_idx, model_weights = _determine_used_index_and_weights(result, data)\n",
    "\n",
    "    # ---------------- E. Marginalization weights ----------------\n",
    "    grid_raw = _apply_marginal_weights(\n",
    "        grid_raw=grid_raw,\n",
    "        data=data,\n",
    "        used_idx=used_idx,\n",
    "        weight=weight,\n",
    "        focal_set=focal_set,\n",
    "        at=at,\n",
    "        factors=fx.factors,\n",
    "        drop_unseen=drop_unseen\n",
    "    )\n",
    "    # Keep Xg aligned to current grid rows if we dropped unseen\n",
    "    Xg = Xg.loc[grid_raw.index]\n",
    "\n",
    "    cell_keys = specs + by\n",
    "    grid_raw = _normalize_weights_by_cell(grid_raw, cell_keys)\n",
    "\n",
    "    # ---------------- F. EMMs ----------------\n",
    "    emm_df, by_slices = _compute_emms_per_cell(\n",
    "        grid_raw=grid_raw,\n",
    "        Xg=Xg,\n",
    "        beta=beta,\n",
    "        V=V,\n",
    "        invlink=invlink,\n",
    "        deriv=deriv,\n",
    "        transform=transform,\n",
    "        level=level,\n",
    "        df_global=df_global,\n",
    "        specs=specs,\n",
    "        by=by\n",
    "    )\n",
    "\n",
    "    # ---------------- G. Contrasts ----------------\n",
    "    contrasts_df = None\n",
    "    if (contrasts == \"pairwise\" or isinstance(contrasts, list)) and len(emm_df) > 0 and len(specs) > 0:\n",
    "        all_rows = []\n",
    "        for by_vals, entries in by_slices.items():\n",
    "            if contrasts == \"pairwise\":\n",
    "                all_rows.extend(\n",
    "                    _pairwise_contrasts_for_slice(\n",
    "                        entries=entries,\n",
    "                        specs=specs,\n",
    "                        by_vals=by_vals,\n",
    "                        beta=beta,\n",
    "                        V=V,\n",
    "                        invlink=invlink,\n",
    "                        deriv=deriv,\n",
    "                        contrast_transform=contrast_transform,\n",
    "                        df_global=df_global,\n",
    "                        df_provider=df_provider,\n",
    "                        by=by\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                all_rows.extend(\n",
    "                    _custom_contrasts_for_slice(\n",
    "                        entries=entries,\n",
    "                        contrasts=contrasts,  # type: ignore[arg-type]\n",
    "                        specs=specs,\n",
    "                        by_vals=by_vals,\n",
    "                        beta=beta,\n",
    "                        V=V,\n",
    "                        invlink=invlink,\n",
    "                        deriv=deriv,\n",
    "                        contrast_transform=contrast_transform,\n",
    "                        df_global=df_global,\n",
    "                        df_provider=df_provider,\n",
    "                        by=by\n",
    "                    )\n",
    "                )\n",
    "        if all_rows:\n",
    "            contrasts_df = pd.DataFrame(all_rows)\n",
    "\n",
    "            if adjust:\n",
    "                method = (adjust or \"\").lower()\n",
    "                contrasts_df[\"p.value.adj\"] = _adjust_pvalues_per_slice(\n",
    "                    contrasts_df=contrasts_df,\n",
    "                    method=method,\n",
    "                    result=result,\n",
    "                    data=data,\n",
    "                    specs=specs,\n",
    "                    by=by,\n",
    "                    used_idx=used_idx,\n",
    "                    model_weights=model_weights,\n",
    "                )\n",
    "\n",
    "            contrasts_df = _finalize_contrasts_df(contrasts_df)\n",
    "\n",
    "    out: Dict[str, Optional[pd.DataFrame]] = {\"emm\": emm_df, \"contrasts\": contrasts_df}\n",
    "    if return_grid:\n",
    "        out[\"grid\"] = grid_raw\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfacf8c",
   "metadata": {},
   "source": [
    "### Example Usage: Post-hoc Tests for model_1\n",
    "\n",
    "Now let's apply the `emmeans` function to perform post-hoc pairwise comparisons for our mixed linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a0882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL 1: Planning Stage (BL vs MAIN baseline vs MAIN adaptation)\n",
      "======================================================================\n",
      "                  Mixed Linear Model Regression Results\n",
      "=========================================================================\n",
      "Model:                  MixedLM       Dependent Variable:       pac_value\n",
      "No. Observations:       69            Method:                   REML     \n",
      "No. Groups:             23            Scale:                    0.0000   \n",
      "Min. group size:        3             Log-Likelihood:           598.5126 \n",
      "Max. group size:        3             Converged:                Yes      \n",
      "Mean group size:        3.0                                              \n",
      "-------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------------------\n",
      "Intercept                       0.000    0.000 22.546 0.000  0.000  0.000\n",
      "condition[T._MAIN__adaptation] -0.000    0.000 -3.250 0.001 -0.000 -0.000\n",
      "condition[T._MAIN__baseline]    0.000    0.000 24.023 0.000  0.000  0.000\n",
      "Group Var                       0.000    0.000                           \n",
      "=========================================================================\n",
      "\n",
      "Random Effect Variance: 3.68e-10\n",
      "\n",
      "======================================================================\n",
      "PAIRWISE COMPARISONS (adjusted)\n",
      "======================================================================\n",
      "                           contrast  estimate_link       SE    t.ratio  p.value  p.value.adj\n",
      "          _BL_N/A - _MAIN__baseline      -0.000149 0.000006 -24.023316 0.000000     0.000000\n",
      "        _BL_N/A - _MAIN__adaptation       0.000020 0.000006   3.249992 0.001818     0.001818\n",
      "_MAIN__baseline - _MAIN__adaptation       0.000170 0.000006  27.273308 0.000000     0.000000\n",
      "\n",
      "======================================================================\n",
      "SIGNIFICANT COMPARISONS (p < 0.05): 3/3\n",
      "======================================================================\n",
      "                           contrast  estimate_link       SE  p.value.adj\n",
      "          _BL_N/A - _MAIN__baseline      -0.000149 0.000006     0.000000\n",
      "        _BL_N/A - _MAIN__adaptation       0.000020 0.000006     0.001818\n",
      "_MAIN__baseline - _MAIN__adaptation       0.000170 0.000006     0.000000\n"
     ]
    }
   ],
   "source": [
    "model_1 = smf.mixedlm(\n",
    "    \"pac_value ~ condition\",\n",
    "    data=df_plan,\n",
    "    groups=df_plan[\"sub\"]\n",
    ").fit(reml=True)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 1: Planning Stage (BL vs MAIN baseline vs MAIN adaptation)\")\n",
    "print(\"=\"*70)\n",
    "print(model_1.summary().as_text())\n",
    "print(f\"Random Effect Variance: {model_1.cov_re.iloc[0, 0]:.2e}\")\n",
    "\n",
    "# Compute EMMs and post-hoc comparisons for model_1\n",
    "# Using df_method=\"resid\" (default) for conservative small-sample inference\n",
    "results_model1 = emmeans(\n",
    "    result=model_1,\n",
    "    data=df_plan,\n",
    "    specs=\"condition\",\n",
    "    adjust=\"tukey\",\n",
    "    level=0.95,\n",
    "    return_grid=True\n",
    ")\n",
    "# Display Pairwise Contrasts\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PAIRWISE COMPARISONS (adjusted)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ctr = results_model1['contrasts']\n",
    "if ctr is not None:\n",
    "    # Show whatever stat column exists\n",
    "    stat_col = 't.ratio' if 't.ratio' in ctr.columns else ('z.ratio' if 'z.ratio' in ctr.columns else 'stat')\n",
    "    cols = ['contrast', 'estimate_link', 'SE', stat_col, 'p.value', 'p.value.adj']\n",
    "    cols = [c for c in cols if c in ctr.columns]  # keep only existing\n",
    "    print(ctr[cols].to_string(index=False))\n",
    "\n",
    "    # Significant comparisons\n",
    "    sig = ctr[ctr['p.value.adj'] < 0.05] if 'p.value.adj' in ctr.columns else ctr[ctr['p.value'] < 0.05]\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"SIGNIFICANT COMPARISONS (p < 0.05): {len(sig)}/{len(ctr)}\")\n",
    "    print(\"=\"*70)\n",
    "    if len(sig) > 0:\n",
    "        sig_cols = ['contrast', 'estimate_link', 'SE', 'p.value.adj'] if 'p.value.adj' in ctr.columns else ['contrast', 'estimate_link', 'SE', 'p.value']\n",
    "        sig_cols = [c for c in sig_cols if c in sig.columns]\n",
    "        print(sig[sig_cols].to_string(index=False))\n",
    "    else:\n",
    "        print(\"No significant pairwise differences found.\")\n",
    "else:\n",
    "    print(\"No contrasts computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5487581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PAIRWISE COMPARISONS (adjusted)\n",
      "======================================================================\n",
      "                  Mixed Linear Model Regression Results\n",
      "==========================================================================\n",
      "Model:                   MixedLM       Dependent Variable:       pac_value\n",
      "No. Observations:        69            Method:                   REML     \n",
      "No. Groups:              23            Scale:                    0.0000   \n",
      "Min. group size:         3             Log-Likelihood:           612.4956 \n",
      "Max. group size:         3             Converged:                Yes      \n",
      "Mean group size:         3.0                                              \n",
      "--------------------------------------------------------------------------\n",
      "                               Coef.  Std.Err.    z    P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------------------------\n",
      "Intercept                       0.000    0.000  33.875 0.000  0.000  0.000\n",
      "condition[T._MAIN__adaptation] -0.000    0.000 -17.066 0.000 -0.000 -0.000\n",
      "condition[T._MAIN__baseline]    0.000    0.000   2.883 0.004  0.000  0.000\n",
      "Group Var                       0.000    0.000                            \n",
      "==========================================================================\n",
      "\n",
      "Random Effect Variance: 1.45e-10\n",
      "                           contrast  estimate_link       SE   t.ratio  p.value  p.value.adj\n",
      "          _BL_N/A - _MAIN__baseline      -0.000016 0.000005 -2.883186 0.005309     0.005309\n",
      "        _BL_N/A - _MAIN__adaptation       0.000092 0.000005 17.065634 0.000000     0.000000\n",
      "_MAIN__baseline - _MAIN__adaptation       0.000108 0.000005 19.948820 0.000000     0.000000\n",
      "\n",
      "======================================================================\n",
      "SIGNIFICANT COMPARISONS (p < 0.05): 3/3\n",
      "======================================================================\n",
      "                           contrast  estimate_link       SE  p.value.adj\n",
      "          _BL_N/A - _MAIN__baseline      -0.000016 0.000005     0.005309\n",
      "        _BL_N/A - _MAIN__adaptation       0.000092 0.000005     0.000000\n",
      "_MAIN__baseline - _MAIN__adaptation       0.000108 0.000005     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Compute EMMs and post-hoc comparisons for model_1\n",
    "# Using df_method=\"resid\" (default) for conservative small-sample inference\n",
    "results_model1 = emmeans(\n",
    "    result=model_2,\n",
    "    data=df_go,\n",
    "    specs=\"condition\",\n",
    "    adjust=\"tukey\",\n",
    "    level=0.95,\n",
    "    return_grid=True\n",
    ")\n",
    "# Display Pairwise Contrasts\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PAIRWISE COMPARISONS (adjusted)\")\n",
    "print(\"=\"*70)\n",
    "print(model_2.summary().as_text())\n",
    "print(f\"Random Effect Variance: {model_2.cov_re.iloc[0, 0]:.2e}\")\n",
    "\n",
    "ctr = results_model1['contrasts']\n",
    "if ctr is not None:\n",
    "    # Show whatever stat column exists\n",
    "    stat_col = 't.ratio' if 't.ratio' in ctr.columns else ('z.ratio' if 'z.ratio' in ctr.columns else 'stat')\n",
    "    cols = ['contrast', 'estimate_link', 'SE', stat_col, 'p.value', 'p.value.adj']\n",
    "    cols = [c for c in cols if c in ctr.columns]  # keep only existing\n",
    "    print(ctr[cols].to_string(index=False))\n",
    "\n",
    "    # Significant comparisons\n",
    "    sig = ctr[ctr['p.value.adj'] < 0.05] if 'p.value.adj' in ctr.columns else ctr[ctr['p.value'] < 0.05]\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"SIGNIFICANT COMPARISONS (p < 0.05): {len(sig)}/{len(ctr)}\")\n",
    "    print(\"=\"*70)\n",
    "    if len(sig) > 0:\n",
    "        sig_cols = ['contrast', 'estimate_link', 'SE', 'p.value.adj'] if 'p.value.adj' in ctr.columns else ['contrast', 'estimate_link', 'SE', 'p.value']\n",
    "        sig_cols = [c for c in sig_cols if c in sig.columns]\n",
    "        print(sig[sig_cols].to_string(index=False))\n",
    "    else:\n",
    "        print(\"No significant pairwise differences found.\")\n",
    "else:\n",
    "    print(\"No contrasts computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c85aba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                         0.000155\n",
       "condition[T._MAIN__adaptation]   -0.000092\n",
       "condition[T._MAIN__baseline]      0.000016\n",
       "Group Var                         0.433510\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d0411dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PAIRWISE COMPARISONS (adjusted)\n",
      "======================================================================\n",
      "               contrast  estimate_link       SE   t.ratio  p.value  p.value.adj\n",
      "_baseline - _adaptation        0.00017 0.000006 27.877833      0.0          0.0\n",
      "\n",
      "======================================================================\n",
      "SIGNIFICANT COMPARISONS (p < 0.05): 1/1\n",
      "======================================================================\n",
      "               contrast  estimate_link       SE  p.value.adj\n",
      "_baseline - _adaptation        0.00017 0.000006          0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute EMMs and post-hoc comparisons for model_1\n",
    "# Using df_method=\"resid\" (default) for conservative small-sample inference\n",
    "results_model1 = emmeans(\n",
    "    result=model_3,\n",
    "    data=df_plan_main,\n",
    "    specs=\"block\",\n",
    "    adjust=\"tukey\",\n",
    "    level=0.95,\n",
    "    return_grid=True\n",
    ")\n",
    "# Display Pairwise Contrasts\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PAIRWISE COMPARISONS (adjusted)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ctr = results_model1['contrasts']\n",
    "if ctr is not None:\n",
    "    # Show whatever stat column exists\n",
    "    stat_col = 't.ratio' if 't.ratio' in ctr.columns else ('z.ratio' if 'z.ratio' in ctr.columns else 'stat')\n",
    "    cols = ['contrast', 'estimate_link', 'SE', stat_col, 'p.value', 'p.value.adj']\n",
    "    cols = [c for c in cols if c in ctr.columns]  # keep only existing\n",
    "    print(ctr[cols].to_string(index=False))\n",
    "\n",
    "    # Significant comparisons\n",
    "    sig = ctr[ctr['p.value.adj'] < 0.05] if 'p.value.adj' in ctr.columns else ctr[ctr['p.value'] < 0.05]\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"SIGNIFICANT COMPARISONS (p < 0.05): {len(sig)}/{len(ctr)}\")\n",
    "    print(\"=\"*70)\n",
    "    if len(sig) > 0:\n",
    "        sig_cols = ['contrast', 'estimate_link', 'SE', 'p.value.adj'] if 'p.value.adj' in ctr.columns else ['contrast', 'estimate_link', 'SE', 'p.value']\n",
    "        sig_cols = [c for c in sig_cols if c in sig.columns]\n",
    "        print(sig[sig_cols].to_string(index=False))\n",
    "    else:\n",
    "        print(\"No significant pairwise differences found.\")\n",
    "else:\n",
    "    print(\"No contrasts computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec12be05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PAIRWISE COMPARISONS (adjusted)\n",
      "======================================================================\n",
      "               contrast  estimate_link       SE   t.ratio  p.value  p.value.adj\n",
      "_baseline - _adaptation       0.000108 0.000004 25.774454      0.0          0.0\n",
      "\n",
      "======================================================================\n",
      "SIGNIFICANT COMPARISONS (p < 0.05): 1/1\n",
      "======================================================================\n",
      "               contrast  estimate_link       SE  p.value.adj\n",
      "_baseline - _adaptation       0.000108 0.000004          0.0\n"
     ]
    }
   ],
   "source": [
    "# Compute EMMs and post-hoc comparisons for model_1\n",
    "# Using df_method=\"resid\" (default) for conservative small-sample inference\n",
    "results_model1 = emmeans(\n",
    "    result=model_4,\n",
    "    data=df_go_main,\n",
    "    specs=\"block\",\n",
    "    adjust=\"tukey\",\n",
    "    level=0.95,\n",
    "    return_grid=True\n",
    ")\n",
    "# Display Pairwise Contrasts\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PAIRWISE COMPARISONS (adjusted)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "ctr = results_model1['contrasts']\n",
    "if ctr is not None:\n",
    "    # Show whatever stat column exists\n",
    "    stat_col = 't.ratio' if 't.ratio' in ctr.columns else ('z.ratio' if 'z.ratio' in ctr.columns else 'stat')\n",
    "    cols = ['contrast', 'estimate_link', 'SE', stat_col, 'p.value', 'p.value.adj']\n",
    "    cols = [c for c in cols if c in ctr.columns]  # keep only existing\n",
    "    print(ctr[cols].to_string(index=False))\n",
    "\n",
    "    # Significant comparisons\n",
    "    sig = ctr[ctr['p.value.adj'] < 0.05] if 'p.value.adj' in ctr.columns else ctr[ctr['p.value'] < 0.05]\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"SIGNIFICANT COMPARISONS (p < 0.05): {len(sig)}/{len(ctr)}\")\n",
    "    print(\"=\"*70)\n",
    "    if len(sig) > 0:\n",
    "        sig_cols = ['contrast', 'estimate_link', 'SE', 'p.value.adj'] if 'p.value.adj' in ctr.columns else ['contrast', 'estimate_link', 'SE', 'p.value']\n",
    "        sig_cols = [c for c in sig_cols if c in sig.columns]\n",
    "        print(sig[sig_cols].to_string(index=False))\n",
    "    else:\n",
    "        print(\"No significant pairwise differences found.\")\n",
    "else:\n",
    "    print(\"No contrasts computed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
