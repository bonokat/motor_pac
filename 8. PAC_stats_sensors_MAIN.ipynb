{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from utils import check_paths\n",
    "\n",
    "import mne\n",
    "from mne.stats import permutation_cluster_1samp_test\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import zscore\n",
    "from scipy.sparse import coo_matrix, save_npz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretaion of z-scored PAC stats:**\n",
    "Negative z-scores don’t mean “negative PAC,” just “PAC lower than the group mean.”\n",
    "\n",
    "**Significant cluster interpretaition:**\n",
    "Talking about “significant clusters” can be convenient, but you must be aware of all associated caveats! For example, it is invalid to interpret the cluster p value as being spatially or temporally specific. A cluster with sufficiently low (for example < 0.05) p value at specific location does not allow you to say that the significant effect is at that particular location. The p value only tells you about the probability of obtaining similar or stronger/larger cluster anywhere in the data if there were no differences between the compared conditions. So it only allows you to draw conclusions about the differences in the data “in general”, not at specific locations.\n",
    "\n",
    "**How NOT to interpret results from a cluster-based permutation test:**\n",
    "https://www.fieldtriptoolbox.org/faq/stats/clusterstats_interpretation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_dir = 'D:\\\\BonoKat\\\\research project\\\\# study 1\\\\eeg_data\\\\set'\n",
    "\n",
    "groups = ['Y', 'O']\n",
    "task = '_MAIN' # ['_BL', '_MAIN']\n",
    "task_stages = ['_plan', '_go']\n",
    "block_names = ['_baseline', '_adaptation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\Y\\s1_pac_sub01\\preproc\\analysis\\s1_pac_sub01_MAIN_epochs_plan_baseline-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 15 columns\n",
      "50 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "(24, 60, 20, 20)\n",
      "(24, 60, 20, 20)\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 60\n",
      "(24000, 24000)\n",
      "stat_fun(H1): min=-8.746169828510352 max=3.267540114221343\n",
      "Running initial clustering …\n",
      "Found 73 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| Permuting : 9999/9999 [13:45<00:00,   12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_thresh = 2.8073356837675227\n",
      "T_obs_mean = -0.1795172628423524\n",
      "cluster_p_values = [9.928e-01 1.000e+00 1.000e+00 1.000e+00 9.976e-01 1.000e+00 1.000e+00\n",
      " 1.000e+00 1.000e+00 1.000e+00 8.693e-01 1.400e-03 8.536e-01 1.000e+00\n",
      " 2.000e-04 9.348e-01 9.996e-01 1.000e+00 1.000e+00 1.000e+00 4.868e-01\n",
      " 1.000e+00 9.663e-01 9.876e-01 4.430e-02 1.000e+00 9.674e-01 9.994e-01\n",
      " 5.400e-03 9.653e-01 1.000e+00 9.996e-01 1.000e+00 1.000e+00 1.000e+00\n",
      " 9.623e-01 1.910e-01 9.999e-01 1.600e-02 1.000e+00 1.000e+00 7.275e-01\n",
      " 1.000e+00 1.000e+00 8.920e-01 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      " 1.000e+00 1.000e+00 1.000e+00 9.994e-01 6.964e-01 1.000e+00 1.000e+00\n",
      " 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      " 1.000e+00 1.000e+00 9.993e-01 1.000e+00 9.999e-01 1.000e+00 6.936e-01\n",
      " 9.931e-01 1.000e+00 1.000e+00]\n",
      "Found 5 significant clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1902989\\AppData\\Local\\Temp\\ipykernel_31932\\3434439688.py:137: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(6, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading D:\\BonoKat\\research project\\# study 1\\eeg_data\\set\\Y\\s1_pac_sub01\\preproc\\analysis\\s1_pac_sub01_MAIN_epochs_plan_adaptation-epo.fif ...\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Adding metadata with 15 columns\n",
      "135 matching events found\n",
      "No baseline correction applied\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "(24, 60, 20, 20)\n",
      "(24, 60, 20, 20)\n",
      "Could not find a adjacency matrix for the data. Computing adjacency based on Delaunay triangulations.\n",
      "-- number of adjacent vertices : 60\n",
      "(24000, 24000)\n",
      "stat_fun(H1): min=-10.14524048806355 max=4.509423663389078\n",
      "Running initial clustering …\n",
      "Found 90 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | Permuting : 3410/9999 [05:16<10:05,   10.88it/s]"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    group_save_path = os.path.join(eeg_data_dir, f'{group} group')\n",
    "    pac_stats_save_path = os.path.join(group_save_path, 'pac_stats')\n",
    "    check_paths(pac_stats_save_path)\n",
    "\n",
    "    subs = os.listdir(os.path.join(eeg_data_dir, group))\n",
    "\n",
    "    for task_stage in task_stages:\n",
    "        for block_name in block_names:\n",
    "\n",
    "            print(f'Processing {group} group, {task} task, {task_stage} stage, {block_name} block...')\n",
    "\n",
    "            ############# STACK PAC DATA OF INDIVIDUAL PARTICIPANTS #############\n",
    "\n",
    "            # Create a list to store the PAC data for each subject\n",
    "            pac_list = []\n",
    "            pac_zscore_list = []\n",
    "\n",
    "            for sub_name in subs:\n",
    "\n",
    "                sub_dir = os.path.join(eeg_data_dir, group, sub_name)\n",
    "                pac_dir = os.path.join(sub_dir, 'pac_results')\n",
    "                \n",
    "                # Get info about chnnals from one participant for adjacency matrix\n",
    "                if sub_name == subs[0]: # read one epochs file to extract info\n",
    "                    # Load EEG data\n",
    "                    epochs_path = os.path.join(eeg_data_dir, group, sub_name, 'preproc', 'analysis') \n",
    "                    epochs = mne.read_epochs(os.path.join(epochs_path, f\"{sub_name}{task}_epochs{task_stage}{block_name}-epo.fif\"), preload=True)\n",
    "                    eeg_channel_names = epochs.copy().pick(\"eeg\").ch_names\n",
    "                    epochs.pick(eeg_channel_names)\n",
    "                    # info = epochs.info\n",
    "                    # epochs.pick(choi)\n",
    "\n",
    "                # Load PAC data\n",
    "                pac = np.load(os.path.join(pac_dir, f\"pac_mi_TOPO_{sub_name[-5:]}{task}{task_stage}{block_name}.npy\"))\n",
    "                pac_t = np.transpose(pac, (1, 0, 2))\n",
    "                pac_list.append(pac_t)\n",
    "                pac_zscore_list.append(zscore(pac_t))\n",
    "            \n",
    "            # Stack them along a new first axis (subject axis)\n",
    "            pac_all = np.stack(pac_list, axis=0)\n",
    "\n",
    "            # Z-score the PAC data across subjects\n",
    "            pac_zscore_all = np.stack(pac_zscore_list, axis=0)\n",
    "            print(pac_all.shape) # (24, 60, 20, 20) subs x electrodes x ph_freqs x amp_freqs\n",
    "            print(pac_zscore_all.shape)\n",
    "\n",
    "            # Average z-scored PAC over subjects\n",
    "            pac_zscore_mean = pac_zscore_all.mean(axis=0)  # shape: (60, 20, 20)\n",
    "\n",
    "            # Save the PAC data\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}{block_name}_RAW.npy\"), pac_all)\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}{block_name}_ZSCORE.npy\"), pac_zscore_all)\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}{block_name}_ZSCORE_MEAN.npy\"), pac_zscore_mean)\n",
    "\n",
    "            ############### CREATE ADJACENCY MATRIX FOR STATISTICAL TEST #############\n",
    "            # find_ch_adjacency first attempts to find an existing \"neighbor\"\n",
    "            # (adjacency) file for given sensor layout.\n",
    "            # If such a file doesn't exist, an adjacency matrix is computed on the fly,\n",
    "            # using Delaunay triangulations.\n",
    "            sensor_adjacency, ch_names = mne.channels.find_ch_adjacency(epochs.info, \"eeg\")\n",
    "            adjacency = mne.stats.combine_adjacency(\n",
    "                                                    sensor_adjacency,\n",
    "                                                    pac_zscore_all.shape[2],\n",
    "                                                    pac_zscore_all.shape[3]\n",
    "                                                    )\n",
    "            print(adjacency.shape)\n",
    "\n",
    "            # Save adjacency matrix\n",
    "            adjacency_matrix = coo_matrix(adjacency)\n",
    "            save_npz(f\"{group}{task}{task_stage}{block_name}_adjacency_matrix.npz\", adjacency_matrix)\n",
    "\n",
    "            ############# RUN CLUSTER-BASED PERMUTATION TEST #############\n",
    "\n",
    "            tail = 0 # two-tailed test\n",
    "\n",
    "            # Set the threshold for including data bins in clusters with t-value corresponding to p=0.01\n",
    "            # Because we conduct a two-tailed test, we divide the p-value by 2 (which means we're making use of both tails of the distribution).\n",
    "            # As the degrees of freedom, we specify the number of observations (here: subjects) minus 1.\n",
    "            # Finally, we subtract 0.01 / 2 from 1, to get the critical t-value on the right tail\n",
    "            degrees_of_freedom = pac_all.shape[0] - 1\n",
    "            t_thresh = scipy.stats.t.ppf(1 - 0.01 / 2, df=degrees_of_freedom)\n",
    "\n",
    "            # Set the number of permutations\n",
    "            n_permutations = 10000\n",
    "\n",
    "            # Run the analysis\n",
    "            T_obs, clusters, cluster_p_values, H0 = permutation_cluster_1samp_test(\n",
    "                pac_zscore_all,\n",
    "                n_permutations=n_permutations,\n",
    "                threshold=t_thresh,\n",
    "                tail=tail,\n",
    "                adjacency=adjacency,\n",
    "                out_type=\"mask\",\n",
    "                max_step=1,\n",
    "                verbose=True,\n",
    "            )\n",
    "\n",
    "            # Save the results\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}{block_name}_T_obs.npy\"), T_obs)\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}{block_name}_clusters.npy\"), np.array(clusters, dtype=object))\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}{block_name}_cluster_p_values.npy\"), cluster_p_values)\n",
    "            np.save(os.path.join(pac_stats_save_path, f\"pac_mi_{group}{task}{task_stage}{block_name}_H0.npy\"), H0)\n",
    "\n",
    "            # SANITY CHECKS\n",
    "            print(f't_thresh = {t_thresh}')\n",
    "            print(f'T_obs_mean = {T_obs.mean()}')\n",
    "            print(f'cluster_p_values = {cluster_p_values}')\n",
    "\n",
    "            alpha = 0.05  # significance threshold\n",
    "            significant_clusters = [i for i, p in enumerate(cluster_p_values) if p < alpha]\n",
    "            print(f\"Found {len(significant_clusters)} significant clusters\")\n",
    "\n",
    "\n",
    "            ####### PLOT THE RESULTS #######\n",
    "            # Create directories for saving figures\n",
    "            fig_group_path = os.path.join(pac_stats_save_path, 'figs')\n",
    "            fig_group_save_path = os.path.join(fig_group_path, group)\n",
    "            fig_task_save_path = os.path.join(fig_group_path, group, task)\n",
    "            check_paths(fig_group_path, fig_group_save_path, fig_task_save_path)\n",
    "\n",
    "            # Reshape the stats results\n",
    "            T_obs_reshaped = T_obs.reshape(pac_zscore_all.shape[1:])  # (30, 20, 20)\n",
    "            sig_mask_reshaped = np.zeros_like(T_obs_reshaped, dtype=bool)\n",
    "\n",
    "            for i in significant_clusters:\n",
    "                sig_mask_reshaped[clusters[i].reshape(pac_zscore_all.shape[1:])] = True\n",
    "\n",
    "\n",
    "            for elec_idx in range(pac_zscore_mean.shape[0]):\n",
    "                # Create masked array: T-values where significant, NaN elsewhere\n",
    "                masked_T = np.where(sig_mask_reshaped[elec_idx], T_obs_reshaped[elec_idx], np.nan)\n",
    "\n",
    "                # # Build a colormap with gray for NaNs\n",
    "                cmap = plt.cm.PiYG.copy()  # try 'RdYlBu' or 'PRGn' (purple-green)\n",
    "                cmap.set_bad(color='lightgray')  # this sets the NaNs to gray\n",
    "\n",
    "                # Plot\n",
    "                plt.figure(figsize=(6, 5))\n",
    "                im = plt.imshow(\n",
    "                    masked_T,\n",
    "                    origin='lower',\n",
    "                    aspect='equal',\n",
    "                    cmap=cmap,\n",
    "                    interpolation='none',\n",
    "                    vmin=-10,\n",
    "                    vmax=10\n",
    "                )\n",
    "                plt.colorbar(im, label='T-value')\n",
    "                plt.title(f'{group}{task}{task_stage}{block_name}: PAC Cluster stats - {eeg_channel_names[elec_idx]}')\n",
    "                plt.xlabel('Amplitude Freq Index')\n",
    "                plt.ylabel('Phase Freq Index')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                plt.savefig(os.path.join(fig_task_save_path, f\"pac_cluster_stats_{group}{task}{task_stage}{block_name}_{eeg_channel_names[elec_idx]}.png\"), dpi=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
